{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "peripheral-backup",
   "metadata": {},
   "source": [
    "# Flask API, CNN Project, Deploy on website\n",
    "model is loaded from weights trained from an external Keras Sequential CNN.<br>\n",
    "Flask returns image and results after classifying image\n",
    "* Date: 02/27/2021\n",
    "* Author: Don Agiro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-corps",
   "metadata": {},
   "source": [
    "# Setup & gpu Activation\n",
    "NB: you can comment out GPU section if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "systematic-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# comment out section below if you do not have a GPU supported device\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-character",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "load your model using keras models. <br>\n",
    "you can use pickle, dill etc or any other package you initially used to save weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weighted-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\n",
    "    \"./mosa\", \n",
    "    custom_objects=None, \n",
    "    compile=True, options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-passion",
   "metadata": {},
   "source": [
    "## Define function for Image\n",
    "this function will be used to `preprocess` images and use loaded weights to classify any images submitted for analysis<br>\n",
    "you can change this part to however you want your images analysed. should work for all binary type clasifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transparent-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    # set constants, use the dimensions as defined in your original model\n",
    "    image_size = (52, 52)\n",
    "    \n",
    "    # load image file using keras preprocessing\n",
    "    img = keras.preprocessing.image.load_img(x, target_size=image_size)\n",
    "\n",
    "    # very low level preprocessing\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # read documentation for \"expand_dims\" on keras\n",
    "\n",
    "    # predict the images class using loaded weights.\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    score = predictions[0]\n",
    "    \n",
    "    # use this conditional statement if you to return human readable output \n",
    "    # not a numerical value.\n",
    "    # else you can comment it out and return score\n",
    "    if score > 0.5:\n",
    "        result = \"Happy :)\"\n",
    "    else:\n",
    "        result = \"Sad :(\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informal-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sad :('"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use an image to test function above before deploying publicly\n",
    "test_img = \"./input/test/sad/PrivateTest_6048665.jpg\"\n",
    "img_class = pred(test_img)\n",
    "img_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-sensitivity",
   "metadata": {},
   "source": [
    "# Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-category",
   "metadata": {},
   "source": [
    "Deploy application to a website using flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imghdr\n",
    "from werkzeug.utils import secure_filename\n",
    "from flask import Flask, render_template, request, redirect, url_for, abort, \\\n",
    "    send_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "checked-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder holding uploaded images is photo which is a subfolder of static\n",
    "POLDER = os.path.join('static', 'photo')\n",
    "\n",
    "# define flask constants \n",
    "app = Flask(__name__)\n",
    "app.config['MAX_CONTENT_LENGTH'] = 1024 * 1024\n",
    "app.config['UPLOAD_EXTENSIONS'] = ['.jpg', '.png', '.jpeg']\n",
    "app.config['UPLOAD_PATH'] = POLDER\n",
    "\n",
    "# this will be used later to empty upload folder before any new analysis\n",
    "mydir = POLDER\n",
    "\n",
    "# validate user uploaded right image type/extension\n",
    "def validate_image(stream):\n",
    "    header = stream.read(512)  # 512 bytes should be enough for a header check\n",
    "    stream.seek(0)  # reset stream pointer\n",
    "    format = imghdr.what(None, header)\n",
    "    if not format:\n",
    "        return None\n",
    "    return '.' + (format if format != 'jpeg' else 'jpg')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    files = os.listdir(app.config['UPLOAD_PATH'])\n",
    "    return render_template('index.html', files=files)\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def upload_files():\n",
    "    \n",
    "    # loop function to empty upload folder before adding new file\n",
    "    for f in os.listdir(mydir):\n",
    "        if not f.endswith(\".jpg\"):\n",
    "            continue\n",
    "        os.remove(os.path.join(mydir, f))\n",
    "    \n",
    "    # now we start the process of uploading image to defined upload foldder\n",
    "    uploaded_file = request.files['file']\n",
    "    filename = secure_filename(uploaded_file.filename)\n",
    "    if filename != '':\n",
    "        file_ext = os.path.splitext(filename)[1]\n",
    "        if file_ext not in app.config['UPLOAD_EXTENSIONS'] or \\\n",
    "                file_ext != validate_image(uploaded_file.stream):\n",
    "            abort(400)\n",
    "        uploaded_file.save(os.path.join(app.config['UPLOAD_PATH'], filename))\n",
    "        \n",
    "        test_img = os.path.join(app.config['UPLOAD_PATH'], filename)\n",
    "        img_class = pred(test_img)\n",
    "        results = img_class\n",
    "        \n",
    "    # generates and saves image file path to be retrieved for display later when sending analysis results\n",
    "    full_filename = os.path.join(app.config['UPLOAD_PATH'], filename)\n",
    "    \n",
    "    # return analysis results and image that was analysed\n",
    "    return render_template(\"index.html\", model_result = results, user_image = full_filename)\n",
    "\n",
    "@app.route('/uploads/<filename>')\n",
    "def upload(filename):\n",
    "    return send_from_directory(app.config['UPLOAD_PATH'], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generic-variation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [27/Feb/2021 12:18:36] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [27/Feb/2021 12:18:42] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_debugger=False, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-clearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-viking",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
