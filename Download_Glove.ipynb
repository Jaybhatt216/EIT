{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Download_Glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDQ6UtBtMGDa"
      },
      "source": [
        "# Analysis and DataFrames\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# Tensorflow\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Visualization\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Misc.\r\n",
        "import re\r\n",
        "import os\r\n",
        "import time\r\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LdLPurTML32"
      },
      "source": [
        "def load_glove_embedding(directory, filename):\r\n",
        "  embeddings_index = {}\r\n",
        "  f = open(os.path.join(directory, filename), encoding = 'utf8')\r\n",
        "  for line in f:\r\n",
        "    if len(line) > 1:\r\n",
        "      values = line.split()\r\n",
        "      word = values[0]\r\n",
        "      coefs = np.asarray(values[1:], dtype = 'float32')\r\n",
        "      embeddings_index[word] = coefs\r\n",
        "  f.close()\r\n",
        "\r\n",
        "  return embeddings_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKX5KxYPLrIR"
      },
      "source": [
        "import os\r\n",
        "import urllib.request\r\n",
        "urllib.request.urlretrieve('http://nlp.stanford.edu/data/glove.6B.zip', 'pretrained_glove.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA3wUoB8LtOR"
      },
      "source": [
        "!apt install unzip\r\n",
        "\r\n",
        "!unzip  pretrained_glove.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_52fejiLtRA"
      },
      "source": [
        "# Create the embedding\r\n",
        "embeddings_index = load_glove_embedding('./', 'glove.6B.300d.txt')\r\n",
        "\r\n",
        "# Verify \r\n",
        "print('Words found:', len(embeddings_index))\r\n",
        "print('Embedding shape for the word \"the\" :', embeddings_index['gradient'].shape)\r\n",
        "print('Embedding dtype for the word \"the\" :', type(embeddings_index['gradient']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwzC3n3ALtTc"
      },
      "source": [
        "# Grab the embedded word\r\n",
        "target_emb = embeddings_index['gradient']\r\n",
        "\r\n",
        "# Normalize the word's embedding\r\n",
        "target_emb_norm = np.linalg.norm(target_emb)\r\n",
        "\r\n",
        "# Cosine Similarity\r\n",
        "similarity = []\r\n",
        "for word in embeddings_index.keys():\r\n",
        "  word_emb = embeddings_index[word]\r\n",
        "  if len(word_emb) == len(target_emb):\r\n",
        "    cos_sim = np.dot(target_emb, word_emb) / (np.linalg.norm(word_emb) * target_emb_norm)\r\n",
        "    similarity.append((word, cos_sim))\r\n",
        "\r\n",
        "# Display\r\n",
        "[ item for item in sorted(similarity, key = lambda x: x[1], reverse=True)[:10]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82cqVkphLtVp"
      },
      "source": [
        "# Identify the words that we want\r\n",
        "words_list = ['man', 'woman', 'king', 'queen', 'emperor', 'empress', 'earl', 'countess']\r\n",
        "\r\n",
        "# Pull the words and the embedding\r\n",
        "ex_emb = []\r\n",
        "for word in words_list:\r\n",
        "  ex_emb.append(embeddings_index[word])\r\n",
        "\r\n",
        "# Error if\r\n",
        "assert np.shape(ex_emb)[0] == len(words_list), 'Word in embedding might not be found'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYOY-vG4LtYG"
      },
      "source": [
        "# Singular Value Decomposition\r\n",
        "U,S,Vt = np.linalg.svd(ex_emb)\r\n",
        "print(np.shape(U))\r\n",
        "print(S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5o518q3Ltai"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure()\r\n",
        "for i in range(len(words_list)):\r\n",
        "  plt.scatter(U[i,0], U[i,1])\r\n",
        "  plt.text(U[i,0], U[i,1], words_list[i])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPUURmCILtdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}