{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaybhatt216/EIT/blob/main/LSTM_pytorch_dino_names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WygBgoleBmk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rsMVRsMeBms"
      },
      "source": [
        "class Layer(torch.nn.Module):\n",
        "    #size in is size before size out is out for this layer\n",
        "    def __init__(self,size_in,size_out,activation):\n",
        "        super(Layer,self).__init__()\n",
        "        self.weights = torch.nn.Parameter(torch.randn(size_in,size_out,requires_grad=True))\n",
        "        self.bias = torch.nn.Parameter(torch.randn(1,size_out,requires_grad=True))\n",
        "        self.activation = activation\n",
        "\n",
        "\n",
        "    def Forward(self, z_in):\n",
        "        return self.activation(z_in @self.weights + self.bias) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgTCXHTXeBmt"
      },
      "source": [
        "forget = Layer(38,15,torch.nn.Sigmoid())\n",
        "loss_func = torch.nn.MSELoss()\n",
        "opt = torch.optim.Adam(forget.parameters())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjtNVIm4eBmu"
      },
      "source": [
        "x_in=torch.randn(1,38)\n",
        "y = torch.rand(1,15)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw2EvdG6eBmu",
        "outputId": "43bd6626-a3e7-4b20-a1bd-a43f7df96acc"
      },
      "source": [
        "print(forget.bias)\n",
        "out = forget.Forward(x_in)\n",
        "loss = loss_func(out,y)\n",
        "loss.backward()\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "print(forget.bias)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1751,  0.4333, -0.1316,  1.4403, -0.2039, -0.4930,  1.7200,  0.7571,\n",
            "         -0.3826, -0.1672, -0.4185,  0.1706,  0.6638, -0.5649,  1.4592]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1741,  0.4323, -0.1306,  1.4393, -0.2049, -0.4940,  1.7190,  0.7561,\n",
            "         -0.3816, -0.1662, -0.4195,  0.1716,  0.6628, -0.5659,  1.4582]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdc7oYpZeBmv"
      },
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, size_in, size_out, size_mem):\n",
        "        super(RNN, self).__init__()\n",
        "        self.size_mem = size_mem\n",
        "        self.mem_layer = Layer(size_in + size_mem, size_mem, torch.tanh)\n",
        "        self.out_layer = Layer(size_mem, size_out, torch.sigmoid)\n",
        "        \n",
        "    def Forward(self, X):\n",
        "        \n",
        "        mem = torch.zeros(1,self.size_mem)\n",
        "        y_hat=[]\n",
        "        for i in range(X.shape[0]):\n",
        "            x_in = X[[i],:]\n",
        "            z_in = torch.cat([x_in,mem], dim=1)\n",
        "            mem = self.mem_layer.Forward(z_in)\n",
        "            y_hat.append(self.out_layer.Forward(mem))\n",
        "            \n",
        "        return torch.cat(y_hat, dim=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IbJCWRleBmw"
      },
      "source": [
        "rnn = RNN(38, 15, 5)\n",
        "loss_func = torch.nn.MSELoss()\n",
        "opt = torch.optim.Adam(rnn.parameters())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yynP-xd7eBmw",
        "outputId": "51bbc894-8b2b-4f15-b2f7-ec5bb7a68a44"
      },
      "source": [
        "print(rnn.mem_layer.bias)\n",
        "y_hat = rnn.Forward(x_in)\n",
        "loss = loss_func(y_hat, y)\n",
        "loss.backward()\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "print()\n",
        "print(rnn.mem_layer.bias)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2850,  0.3023, -0.8575,  2.0131, -0.2946]], requires_grad=True)\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[-0.2840,  0.3033, -0.8585,  2.0141, -0.2936]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSMeFTy2eBmx"
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "    def __init__(self, size_in, size_out, size_long, size_short):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.size_long = size_long\n",
        "        self.size_short = size_short\n",
        "        \n",
        "        size_z = size_in + size_short\n",
        "        \n",
        "        self.forget_gate  = Layer(size_z, size_long, torch.sigmoid)\n",
        "        self.memory_gate  = Layer(size_z, size_long, torch.sigmoid)\n",
        "        self.memory_layer = Layer(size_z, size_long, torch.tanh)\n",
        "        self.recall_gate  = Layer(size_z, size_short, torch.sigmoid)\n",
        "        self.recall_layer = Layer(size_long, size_short, torch.tanh)\n",
        "        self.output_gate  = Layer(size_short, size_out, torch.sigmoid)\n",
        "        \n",
        "    def Forward(self, X):\n",
        "        mem_short = torch.zeros(1, self.size_short)\n",
        "        mem_long = torch.zeros(1, self.size_long)\n",
        "        y_hat = []\n",
        "        \n",
        "        for i in range(X.shape[0]):\n",
        "            x_t = X[[i],:]\n",
        "            z_t = torch.cat([x_t,mem_short], dim=1)\n",
        "            mem_long = mem_long*self.forget_gate.Forward(z_t)\n",
        "            mem_long = mem_long+(self.memory_gate.Forward(z_t)*self.memory_layer.Forward(z_t))\n",
        "            mem_short = self.recall_gate.Forward(z_t)+self.recall_layer.Forward(mem_long)\n",
        "            \n",
        "            y_hat.append(self.output_gate.Forward(mem_short))\n",
        "            \n",
        "        return torch.cat(y_hat, dim=0)\n",
        "    \n",
        "    def Generate(self, start, stop, random_factor):\n",
        "        y_hat = [start]\n",
        "        mem_long = torch.randn([1,self.size_long])*random_factor\n",
        "        mem_short = torch.randn([1, self.size_short])*random_factor\n",
        "        \n",
        "        while(y_hat[-1] != stop).any() and len(y_hat)<30:\n",
        "            x_t = y_hat[-1]\n",
        "            z_t = torch.cat([x_t, mem_short], dim=1)\n",
        "            mem_long = mem_long*self.forget_gate.Forward(z_t)\n",
        "            mem_long = mem_long + (self.memory_gate.Forward(z_t)*self.memory_layer.Forward(z_t))\n",
        "            mem_short = self.recall_gate.Forward(z_t) + self.recall_layer.Forward(mem_long)\n",
        "            out = self.output_gate.Forward(mem_short)\n",
        "            out = torch.argmax(out,dim=1)\n",
        "            \n",
        "            y_hat.append(torch.zeros(stop.shape))\n",
        "            y_hat[-1][0,out]=1\n",
        "            \n",
        "        return torch.cat(y_hat, dim=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC1FeXjOeBmy"
      },
      "source": [
        "data = pd.read_csv('dinosaurs.csv', header=None)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD9zGgg_eBmy"
      },
      "source": [
        "data.columns=['name']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLqDHbPdeBmy"
      },
      "source": [
        "def Process(name):\n",
        "    name=''.join(['{',name,'|'])\n",
        "    out=[]\n",
        "    for letter in name:\n",
        "        row=torch.zeros([1,28])\n",
        "        row[0,ord(letter)-97]=1\n",
        "        out.append(row)\n",
        "    return torch.cat(out)\n",
        "\n",
        "def Decode(y_hat):\n",
        "    out=''\n",
        "    for i in torch.argmax(y_hat,dim=1):\n",
        "        out += chr(i+97)\n",
        "    return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpGqhEYPeBmz"
      },
      "source": [
        "lstm = LSTM(28,28,12,12)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKcuUPRIeBmz"
      },
      "source": [
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "opt = torch.optim.AdamW(lstm.parameters(), lr=4.5e-2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "An6EJSMweBm0",
        "outputId": "8637fc5d-186b-41aa-838d-a2666abdb7f7"
      },
      "source": [
        "iterations = 4600\n",
        "losses=[0]\n",
        "name = '{'\n",
        "\n",
        "for i in range(iterations):\n",
        "    \n",
        "    name = Process(np.random.choice(data.name))\n",
        "    y_hat = lstm.Forward(name)\n",
        "    \n",
        "    print('r\\ Iteration: {} Loss: {} | {}'.format(i, loss-1,Decode(y_hat))+' ')\n",
        "    \n",
        "    loss = loss_func(y_hat[:-1],torch.argmax(name,dim=1)[1:])\n",
        "    loss.backward()\n",
        "    losses.append(loss.detach())\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "plt.plot(losses)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r\\ Iteration: 0 Loss: -0.7636379599571228 | {l|hl{zzz{zzz \n",
            "r\\ Iteration: 1 Loss: 2.2463362216949463 | {ls{zsz{z{{{{{ \n",
            "r\\ Iteration: 2 Loss: 2.1493022441864014 | {ls{llllllllllllll \n",
            "r\\ Iteration: 3 Loss: 2.552077293395996 | {lzleeslllllll \n",
            "r\\ Iteration: 4 Loss: 2.5400233268737793 | {lsllllxxil||ellxl \n",
            "r\\ Iteration: 5 Loss: 2.5765037536621094 | {l{leel \n",
            "r\\ Iteration: 6 Loss: 2.4012691974639893 | {{|llllllllll \n",
            "r\\ Iteration: 7 Loss: 2.4050838947296143 | {{|elll|llll| \n",
            "r\\ Iteration: 8 Loss: 2.54931640625 | {{allll|lllxxeli \n",
            "r\\ Iteration: 9 Loss: 2.546480655670166 | {{|llll|ll|raa \n",
            "r\\ Iteration: 10 Loss: 2.2507517337799072 | r{a|ll||ll|rsasra \n",
            "r\\ Iteration: 11 Loss: 2.3109920024871826 | rl|l|l|llsssraa \n",
            "r\\ Iteration: 12 Loss: 2.302211284637451 | r{aasa||||ll|| \n",
            "r\\ Iteration: 13 Loss: 2.1436259746551514 | r{a||lll||aa \n",
            "r\\ Iteration: 14 Loss: 2.2620351314544678 | r{|||l||llaraa \n",
            "r\\ Iteration: 15 Loss: 2.260436534881592 | rraara||l|ll \n",
            "r\\ Iteration: 16 Loss: 2.1513044834136963 | rarrrrrrrrrrr \n",
            "r\\ Iteration: 17 Loss: 2.3696775436401367 | rarrrrrrrrrrrr \n",
            "r\\ Iteration: 18 Loss: 2.1419460773468018 | rarrrrrrrrrrrr \n",
            "r\\ Iteration: 19 Loss: 2.1833279132843018 | rarrrrrrrrrrsrrrrrr \n",
            "r\\ Iteration: 20 Loss: 2.2487058639526367 | rrrrrrrrrrrrrssrr \n",
            "r\\ Iteration: 21 Loss: 2.1439919471740723 | rrrrrrrrrrrrrrsrr \n",
            "r\\ Iteration: 22 Loss: 2.117255210876465 | rrrrrrrrrrrrrrrr \n",
            "r\\ Iteration: 23 Loss: 2.281189441680908 | rarrrrrrrrrrrr \n",
            "r\\ Iteration: 24 Loss: 2.0519940853118896 | rrrrrrrrrrrrrrrrr \n",
            "r\\ Iteration: 25 Loss: 2.138683557510376 | rarrrrrrrrrssssrr \n",
            "r\\ Iteration: 26 Loss: 2.213247299194336 | |rrrrrrrrrrrrrr \n",
            "r\\ Iteration: 27 Loss: 2.3279216289520264 | |arrrrrrrrass \n",
            "r\\ Iteration: 28 Loss: 2.036146402359009 | |arrrrrrrrrrrrs \n",
            "r\\ Iteration: 29 Loss: 2.137683391571045 | |rrarssarssr \n",
            "r\\ Iteration: 30 Loss: 2.1988205909729004 | |arrrsssrsssar \n",
            "r\\ Iteration: 31 Loss: 2.0420289039611816 | |ararss|rsss \n",
            "r\\ Iteration: 32 Loss: 2.192042589187622 | |aarrrssrsssasss \n",
            "r\\ Iteration: 33 Loss: 2.1545143127441406 | |arrrrsssssss \n",
            "r\\ Iteration: 34 Loss: 2.0218913555145264 | |aa|rsssssssss \n",
            "r\\ Iteration: 35 Loss: 2.059694528579712 | |aar|rssrsssssss \n",
            "r\\ Iteration: 36 Loss: 2.1056008338928223 | |a||rsssssss \n",
            "r\\ Iteration: 37 Loss: 1.958636999130249 | |ao|rsssrssssrrss \n",
            "r\\ Iteration: 38 Loss: 2.0057597160339355 | |a||rsrssss \n",
            "r\\ Iteration: 39 Loss: 2.3648903369903564 | ||orssssssssssss \n",
            "r\\ Iteration: 40 Loss: 2.132526159286499 | |ao|ssssssss \n",
            "r\\ Iteration: 41 Loss: 2.238922119140625 | ||oossssssss \n",
            "r\\ Iteration: 42 Loss: 2.1991841793060303 | |oo||sss \n",
            "r\\ Iteration: 43 Loss: 2.2301249504089355 | ||rrssssssssss \n",
            "r\\ Iteration: 44 Loss: 1.9614217281341553 | |oo|rssssssssss \n",
            "r\\ Iteration: 45 Loss: 2.0286238193511963 | |||rssssssss \n",
            "r\\ Iteration: 46 Loss: 2.103529214859009 | |oorrssssssssss|sss \n",
            "r\\ Iteration: 47 Loss: 2.133136749267578 | |ooossssssssssss \n",
            "r\\ Iteration: 48 Loss: 2.135362148284912 | |oorssssssssss \n",
            "r\\ Iteration: 49 Loss: 2.1664927005767822 | |oo|sssssssssss \n",
            "r\\ Iteration: 50 Loss: 2.1068572998046875 | |o|rrsssssss \n",
            "r\\ Iteration: 51 Loss: 2.2119696140289307 | |ooo|sssss \n",
            "r\\ Iteration: 52 Loss: 2.3568716049194336 | |oorsrsssss \n",
            "r\\ Iteration: 53 Loss: 2.048640727996826 | |oo||rssss \n",
            "r\\ Iteration: 54 Loss: 2.007347822189331 | |oorrsssssssss \n",
            "r\\ Iteration: 55 Loss: 2.144505023956299 | |ooorsssssss \n",
            "r\\ Iteration: 56 Loss: 2.012519121170044 | |oo|rsssssssss \n",
            "r\\ Iteration: 57 Loss: 2.2232236862182617 | |oo|rssssssss \n",
            "r\\ Iteration: 58 Loss: 1.9999845027923584 | |ooo|rsssssss \n",
            "r\\ Iteration: 59 Loss: 2.320106267929077 | |o|rs||sssssssss \n",
            "r\\ Iteration: 60 Loss: 2.1182024478912354 | |ooorssssssss \n",
            "r\\ Iteration: 61 Loss: 2.061042547225952 | |oo|rrsssssssss \n",
            "r\\ Iteration: 62 Loss: 2.029695749282837 | |ooors|sssss \n",
            "r\\ Iteration: 63 Loss: 1.9312407970428467 | |ooorsssssss \n",
            "r\\ Iteration: 64 Loss: 2.032050132751465 | |ooo|||sssssss \n",
            "r\\ Iteration: 65 Loss: 2.124056577682495 | |ooo|rsrsssss|ssss \n",
            "r\\ Iteration: 66 Loss: 2.091566801071167 | |oo|rrrsssrrrss \n",
            "r\\ Iteration: 67 Loss: 2.1567535400390625 | |oo|||r|s||sr \n",
            "r\\ Iteration: 68 Loss: 2.1933348178863525 | |ooo||ssrssrrr \n",
            "r\\ Iteration: 69 Loss: 2.197925329208374 | |oo||||||ssr||ss \n",
            "r\\ Iteration: 70 Loss: 2.1223256587982178 | |oo|||||||||s| \n",
            "r\\ Iteration: 71 Loss: 2.061417579650879 | |ooo|||||s|s| \n",
            "r\\ Iteration: 72 Loss: 1.9592726230621338 | |ooo|||||||||| \n",
            "r\\ Iteration: 73 Loss: 2.0736887454986572 | |oo||||||||||| \n",
            "r\\ Iteration: 74 Loss: 2.1354031562805176 | |ooo||||||||||||| \n",
            "r\\ Iteration: 75 Loss: 2.0950284004211426 | |oooo||||||||||| \n",
            "r\\ Iteration: 76 Loss: 2.1553077697753906 | |oo|||||||| \n",
            "r\\ Iteration: 77 Loss: 2.283957004547119 | |ooo|||||||||||||| \n",
            "r\\ Iteration: 78 Loss: 1.995507001876831 | |oo|||||||| \n",
            "r\\ Iteration: 79 Loss: 2.3073668479919434 | |ooo||||||||| \n",
            "r\\ Iteration: 80 Loss: 2.0498554706573486 | |oo||||||||||| \n",
            "r\\ Iteration: 81 Loss: 2.0596518516540527 | |oooo||||||| \n",
            "r\\ Iteration: 82 Loss: 2.1580705642700195 | |ooo|||||||||||| \n",
            "r\\ Iteration: 83 Loss: 2.1620874404907227 | |ooo||||||||||| \n",
            "r\\ Iteration: 84 Loss: 2.2360472679138184 | |ooo|||||| \n",
            "r\\ Iteration: 85 Loss: 2.28912091255188 | |ooo||||||||||| \n",
            "r\\ Iteration: 86 Loss: 1.814086675643921 | |ooo|||||| \n",
            "r\\ Iteration: 87 Loss: 2.0628089904785156 | |ooo|||||||||||| \n",
            "r\\ Iteration: 88 Loss: 2.1952285766601562 | |oooo|||||||||||| \n",
            "r\\ Iteration: 89 Loss: 1.959728479385376 | |oooo||||| \n",
            "r\\ Iteration: 90 Loss: 2.0412800312042236 | |ooo||||||| \n",
            "r\\ Iteration: 91 Loss: 2.2242119312286377 | |ooo||||||||| \n",
            "r\\ Iteration: 92 Loss: 2.039440155029297 | |ooooo||||||||||| \n",
            "r\\ Iteration: 93 Loss: 2.1646816730499268 | |ooo||||||| \n",
            "r\\ Iteration: 94 Loss: 2.284585475921631 | |ooo||||||||||||| \n",
            "r\\ Iteration: 95 Loss: 1.9508728981018066 | |oooo||||||| \n",
            "r\\ Iteration: 96 Loss: 1.8446681499481201 | |ooo||||||||||||| \n",
            "r\\ Iteration: 97 Loss: 1.8849895000457764 | |ooo||||||||| \n",
            "r\\ Iteration: 98 Loss: 1.9040706157684326 | |oo|||||||||| \n",
            "r\\ Iteration: 99 Loss: 1.843031883239746 | |ooo|||||||||| \n",
            "r\\ Iteration: 100 Loss: 2.028583288192749 | |oooo|||| \n",
            "r\\ Iteration: 101 Loss: 2.120856761932373 | |oooo|||||||||| \n",
            "r\\ Iteration: 102 Loss: 1.8187968730926514 | |ooo||||||||||||| \n",
            "r\\ Iteration: 103 Loss: 2.1484363079071045 | |ooo||||||||||||| \n",
            "r\\ Iteration: 104 Loss: 1.9085383415222168 | |ooou||||||| \n",
            "r\\ Iteration: 105 Loss: 2.077230215072632 | |oou|||||||||||||| \n",
            "r\\ Iteration: 106 Loss: 2.185304641723633 | |oooo|||||||||| \n",
            "r\\ Iteration: 107 Loss: 2.0055949687957764 | |oo|||||||||||| \n",
            "r\\ Iteration: 108 Loss: 1.9432013034820557 | |oo|||||||||||| \n",
            "r\\ Iteration: 109 Loss: 2.1409642696380615 | |ooo|||||||| \n",
            "r\\ Iteration: 110 Loss: 1.8333072662353516 | |oo|||||||||| \n",
            "r\\ Iteration: 111 Loss: 2.1083974838256836 | |ooo||||||||||| \n",
            "r\\ Iteration: 112 Loss: 1.9347116947174072 | |ooo||||||||| \n",
            "r\\ Iteration: 113 Loss: 1.9359190464019775 | |ooou||||| \n",
            "r\\ Iteration: 114 Loss: 2.1794331073760986 | |oo||||||||| \n",
            "r\\ Iteration: 115 Loss: 2.016416311264038 | |oo|||||||||| \n",
            "r\\ Iteration: 116 Loss: 2.051038980484009 | |ooou|||||| \n",
            "r\\ Iteration: 117 Loss: 2.154529094696045 | |ooo||||||||| \n",
            "r\\ Iteration: 118 Loss: 2.084162473678589 | |oou|||o||||| \n",
            "r\\ Iteration: 119 Loss: 1.8706998825073242 | |ooou||||||| \n",
            "r\\ Iteration: 120 Loss: 2.2054970264434814 | |ooou||||o|||||||| \n",
            "r\\ Iteration: 121 Loss: 1.903918743133545 | |oooou|||||| \n",
            "r\\ Iteration: 122 Loss: 2.0668604373931885 | |ooou|| \n",
            "r\\ Iteration: 123 Loss: 2.1146247386932373 | |ooo|||||| \n",
            "r\\ Iteration: 124 Loss: 2.133665084838867 | |oooo||| \n",
            "r\\ Iteration: 125 Loss: 2.213418960571289 | |ooono|||||||| \n",
            "r\\ Iteration: 126 Loss: 2.031423330307007 | |ooo|||u|||oo| \n",
            "r\\ Iteration: 127 Loss: 2.168168067932129 | |oo|||||||| \n",
            "r\\ Iteration: 128 Loss: 2.176682233810425 | |aoou||||||| \n",
            "r\\ Iteration: 129 Loss: 1.8792119026184082 | |oooo||||o||||| \n",
            "r\\ Iteration: 130 Loss: 2.102099657058716 | |ooo|||ou|| \n",
            "r\\ Iteration: 131 Loss: 1.9775080680847168 | |oou||u|||||||| \n",
            "r\\ Iteration: 132 Loss: 2.0423641204833984 | |oooo|||o| \n",
            "r\\ Iteration: 133 Loss: 1.9996507167816162 | |oooo||||||||| \n",
            "r\\ Iteration: 134 Loss: 2.005455255508423 | |ooo|||||||||||||| \n",
            "r\\ Iteration: 135 Loss: 1.9609100818634033 | |oooo||||||| \n",
            "r\\ Iteration: 136 Loss: 2.047482967376709 | |ooo||ooo||| \n",
            "r\\ Iteration: 137 Loss: 2.1337966918945312 | |oou|||||| \n",
            "r\\ Iteration: 138 Loss: 2.0938825607299805 | |oooo||||||| \n",
            "r\\ Iteration: 139 Loss: 1.9358949661254883 | |oo|||||||||||| \n",
            "r\\ Iteration: 140 Loss: 1.9213364124298096 | |oou||||| \n",
            "r\\ Iteration: 141 Loss: 2.383603096008301 | |ooou|||||||||||| \n",
            "r\\ Iteration: 142 Loss: 2.0736751556396484 | |oo||||||||||| \n",
            "r\\ Iteration: 143 Loss: 2.0618808269500732 | |oou|||||||||||| \n",
            "r\\ Iteration: 144 Loss: 2.0922276973724365 | |oo||||||||| \n",
            "r\\ Iteration: 145 Loss: 1.9297683238983154 | |oou||||||| \n",
            "r\\ Iteration: 146 Loss: 2.020921468734741 | ||u||||||||| \n",
            "r\\ Iteration: 147 Loss: 2.087872266769409 | |aou|||||||||| \n",
            "r\\ Iteration: 148 Loss: 1.935102939605713 | |aou|||||||||| \n",
            "r\\ Iteration: 149 Loss: 1.9679009914398193 | |ooouu||||||||| \n",
            "r\\ Iteration: 150 Loss: 2.136152744293213 | |a|u||||||||||| \n",
            "r\\ Iteration: 151 Loss: 2.220752716064453 | |aoou|u|||||| \n",
            "r\\ Iteration: 152 Loss: 2.209688425064087 | |oou||||||||| \n",
            "r\\ Iteration: 153 Loss: 2.080683469772339 | |ao||| \n",
            "r\\ Iteration: 154 Loss: 2.1680359840393066 | |aou|||| \n",
            "r\\ Iteration: 155 Loss: 2.2461094856262207 | |a||||||||||||| \n",
            "r\\ Iteration: 156 Loss: 2.0338528156280518 | |aoou|||||||||| \n",
            "r\\ Iteration: 157 Loss: 2.151782274246216 | |aouu||||||||||| \n",
            "r\\ Iteration: 158 Loss: 1.9720327854156494 | |oouu|||||||| \n",
            "r\\ Iteration: 159 Loss: 2.180208921432495 | |aou|||||||||| \n",
            "r\\ Iteration: 160 Loss: 2.041809558868408 | |aou|||||||| \n",
            "r\\ Iteration: 161 Loss: 2.056546688079834 | |a||||||||||| \n",
            "r\\ Iteration: 162 Loss: 1.9580440521240234 | |aoo|||||||||| \n",
            "r\\ Iteration: 163 Loss: 1.9380061626434326 | |aoou|||| \n",
            "r\\ Iteration: 164 Loss: 2.1180317401885986 | |aou|||||||| \n",
            "r\\ Iteration: 165 Loss: 1.9400713443756104 | |aoouu|||||| \n",
            "r\\ Iteration: 166 Loss: 2.3392388820648193 | |ao||||||||| \n",
            "r\\ Iteration: 167 Loss: 2.1694223880767822 | |aoo|||||||||| \n",
            "r\\ Iteration: 168 Loss: 2.03493332862854 | |aou|||||||| \n",
            "r\\ Iteration: 169 Loss: 2.127934217453003 | |aoo|||||||||||||| \n",
            "r\\ Iteration: 170 Loss: 2.0903568267822266 | |aoo|||||||||||||| \n",
            "r\\ Iteration: 171 Loss: 2.0304105281829834 | |aoo|||||||| \n",
            "r\\ Iteration: 172 Loss: 1.9863340854644775 | |ooo||||||||||||| \n",
            "r\\ Iteration: 173 Loss: 2.1055595874786377 | |aou||||||||||| \n",
            "r\\ Iteration: 174 Loss: 1.9993598461151123 | |aoo|||||||| \n",
            "r\\ Iteration: 175 Loss: 1.9726331233978271 | |aoo|||||||||| \n",
            "r\\ Iteration: 176 Loss: 1.9290850162506104 | |ooo||||||||||| \n",
            "r\\ Iteration: 177 Loss: 1.8802211284637451 | |aooo|||||||||| \n",
            "r\\ Iteration: 178 Loss: 1.8057734966278076 | |aoo|||a||||a|| \n",
            "r\\ Iteration: 179 Loss: 1.9605145454406738 | |aoo||||||||||| \n",
            "r\\ Iteration: 180 Loss: 2.0275352001190186 | |aooo||||||||| \n",
            "r\\ Iteration: 181 Loss: 2.1665992736816406 | |ao|||||||| \n",
            "r\\ Iteration: 182 Loss: 2.283496856689453 | |aoo|||||||| \n",
            "r\\ Iteration: 183 Loss: 1.9832727909088135 | |aou||||||||||| \n",
            "r\\ Iteration: 184 Loss: 1.8836722373962402 | |aoou||||||||| \n",
            "r\\ Iteration: 185 Loss: 1.9568777084350586 | |aoo||||||||||||| \n",
            "r\\ Iteration: 186 Loss: 1.979306697845459 | |aoo|||||||| \n",
            "r\\ Iteration: 187 Loss: 1.8936002254486084 | |aooo||||| \n",
            "r\\ Iteration: 188 Loss: 2.058011293411255 | |aoo|||||||||||| \n",
            "r\\ Iteration: 189 Loss: 2.0463790893554688 | |ao|||||||||||| \n",
            "r\\ Iteration: 190 Loss: 1.8906078338623047 | |ao|||||||||||| \n",
            "r\\ Iteration: 191 Loss: 2.033456325531006 | |eo|||||||| \n",
            "r\\ Iteration: 192 Loss: 2.0999975204467773 | |aou||||||||||| \n",
            "r\\ Iteration: 193 Loss: 1.982567310333252 | ||a|||||||||||||| \n",
            "r\\ Iteration: 194 Loss: 2.0833823680877686 | ||||||||||||a| \n",
            "r\\ Iteration: 195 Loss: 1.9202020168304443 | |a||||||||||| \n",
            "r\\ Iteration: 196 Loss: 1.933089017868042 | |eoo|||||||||||||| \n",
            "r\\ Iteration: 197 Loss: 2.0289552211761475 | |a||||||||||| \n",
            "r\\ Iteration: 198 Loss: 2.0218560695648193 | |ao|||||||||||| \n",
            "r\\ Iteration: 199 Loss: 1.9129676818847656 | |a||||||||||| \n",
            "r\\ Iteration: 200 Loss: 1.9858276844024658 | |aoo|||||||||||| \n",
            "r\\ Iteration: 201 Loss: 2.1576144695281982 | |ae|||||||||||| \n",
            "r\\ Iteration: 202 Loss: 2.020185708999634 | |eoe|||||||||||| \n",
            "r\\ Iteration: 203 Loss: 2.125244140625 | |ao||||||| \n",
            "r\\ Iteration: 204 Loss: 2.187708854675293 | |ae|||||||||||||| \n",
            "r\\ Iteration: 205 Loss: 1.9527482986450195 | |eo|||||||||| \n",
            "r\\ Iteration: 206 Loss: 2.244892120361328 | |ee|||||||| \n",
            "r\\ Iteration: 207 Loss: 2.0916965007781982 | seoe|||| \n",
            "r\\ Iteration: 208 Loss: 1.9743194580078125 | seo|||||||||||||||| \n",
            "r\\ Iteration: 209 Loss: 2.0688095092773438 | see|||||||||||| \n",
            "r\\ Iteration: 210 Loss: 1.9118387699127197 | sa|||||||||| \n",
            "r\\ Iteration: 211 Loss: 2.02095103263855 | s||||||||||||| \n",
            "r\\ Iteration: 212 Loss: 2.054292917251587 | sa||||||| \n",
            "r\\ Iteration: 213 Loss: 2.212627649307251 | sae|||||||| \n",
            "r\\ Iteration: 214 Loss: 1.9431064128875732 | sae||||||||||| \n",
            "r\\ Iteration: 215 Loss: 1.9134278297424316 | sea||||||||||| \n",
            "r\\ Iteration: 216 Loss: 2.052370309829712 | sa||||||| \n",
            "r\\ Iteration: 217 Loss: 2.05600643157959 | se|||||||||||||| \n",
            "r\\ Iteration: 218 Loss: 1.9550909996032715 | s|||||||||||| \n",
            "r\\ Iteration: 219 Loss: 1.9863882064819336 | ses||||||| \n",
            "r\\ Iteration: 220 Loss: 2.0528688430786133 | s|||||||||||||| \n",
            "r\\ Iteration: 221 Loss: 1.917445421218872 | sas||||||s|| \n",
            "r\\ Iteration: 222 Loss: 2.1248083114624023 | s|||||||||||| \n",
            "r\\ Iteration: 223 Loss: 1.8993027210235596 | se|s|||||||s||||| \n",
            "r\\ Iteration: 224 Loss: 1.9230146408081055 | ses||||||||||| \n",
            "r\\ Iteration: 225 Loss: 2.090667247772217 | s|s|||||s||||| \n",
            "r\\ Iteration: 226 Loss: 1.966123342514038 | sa||s|s||||| \n",
            "r\\ Iteration: 227 Loss: 1.9126927852630615 | ses|||||||||| \n",
            "r\\ Iteration: 228 Loss: 2.100019693374634 | ses|s|s|s|||||s||||| \n",
            "r\\ Iteration: 229 Loss: 2.011378288269043 | s|as|||s||||s||||| \n",
            "r\\ Iteration: 230 Loss: 1.9228715896606445 | sas|||||||||s||||| \n",
            "r\\ Iteration: 231 Loss: 2.122197151184082 | s|ss|s|||| \n",
            "r\\ Iteration: 232 Loss: 2.087407350540161 | s|s|s|||||s|ss|| \n",
            "r\\ Iteration: 233 Loss: 2.2296605110168457 | seos|s|s||||| \n",
            "r\\ Iteration: 234 Loss: 1.9271841049194336 | seoss|||||s|ss|| \n",
            "r\\ Iteration: 235 Loss: 2.2333223819732666 | s|s|s||s|ss| \n",
            "r\\ Iteration: 236 Loss: 1.8611631393432617 | saoss||s||||s|| \n",
            "r\\ Iteration: 237 Loss: 2.1394526958465576 | s|ss|s|s|| \n",
            "r\\ Iteration: 238 Loss: 2.060991048812866 | s||||s||s|| \n",
            "r\\ Iteration: 239 Loss: 1.9628500938415527 | s|s|||s|s||||| \n",
            "r\\ Iteration: 240 Loss: 1.9191980361938477 | sas|s||s|s||||| \n",
            "r\\ Iteration: 241 Loss: 1.9102225303649902 | s|s|||s|s|s|| \n",
            "r\\ Iteration: 242 Loss: 1.9280259609222412 | sa|s||ss| \n",
            "r\\ Iteration: 243 Loss: 2.2144484519958496 | ses|ssss|s||||| \n",
            "r\\ Iteration: 244 Loss: 1.9817862510681152 | saes|||sss|ss|s| \n",
            "r\\ Iteration: 245 Loss: 2.2485549449920654 | sae|||||s||s|| \n",
            "r\\ Iteration: 246 Loss: 2.230848550796509 | sass|s|ss| \n",
            "r\\ Iteration: 247 Loss: 1.949234962463379 | sass||s|s|s|| \n",
            "r\\ Iteration: 248 Loss: 2.0199496746063232 | ses|s|ss|ss|ss|| \n",
            "r\\ Iteration: 249 Loss: 2.1081793308258057 | saas|s|s||| \n",
            "r\\ Iteration: 250 Loss: 1.8610970973968506 | sas||ss||s||| \n",
            "r\\ Iteration: 251 Loss: 1.9179866313934326 | saess|ss|ss||s| \n",
            "r\\ Iteration: 252 Loss: 2.1423144340515137 | ssss||s||s|| \n",
            "r\\ Iteration: 253 Loss: 2.115490198135376 | s|sss|s||s|s||| \n",
            "r\\ Iteration: 254 Loss: 1.9839274883270264 | s||s||s|s|s||| \n",
            "r\\ Iteration: 255 Loss: 1.8475151062011719 | s|s|s|||s|ss| \n",
            "r\\ Iteration: 256 Loss: 2.094780683517456 | ssssss|s|s||| \n",
            "r\\ Iteration: 257 Loss: 1.9268856048583984 | sss|s|s|s|||| \n",
            "r\\ Iteration: 258 Loss: 2.176546096801758 | s|s|ss|ss|ss|| \n",
            "r\\ Iteration: 259 Loss: 2.073444366455078 | ss|ssssss|s|| \n",
            "r\\ Iteration: 260 Loss: 2.0935471057891846 | ss|s|s||s|s|s||| \n",
            "r\\ Iteration: 261 Loss: 1.9125392436981201 | s|s|sss|s|s||| \n",
            "r\\ Iteration: 262 Loss: 1.9209821224212646 | sasssss|||s|ss| \n",
            "r\\ Iteration: 263 Loss: 2.1165199279785156 | s|s|ss|s|||| \n",
            "r\\ Iteration: 264 Loss: 2.0215489864349365 | sas||s||s||| \n",
            "r\\ Iteration: 265 Loss: 2.0247983932495117 | s|s||||ss| \n",
            "r\\ Iteration: 266 Loss: 2.284508228302002 | sass|ss|s||s|ss| \n",
            "r\\ Iteration: 267 Loss: 2.045785427093506 | s|ss|sss|s|s|s||| \n",
            "r\\ Iteration: 268 Loss: 2.009331703186035 | ssss|s|ss| \n",
            "r\\ Iteration: 269 Loss: 2.173672676086426 | sas||||s|s|s||| \n",
            "r\\ Iteration: 270 Loss: 1.9847712516784668 | s|ss|sss|s|s||| \n",
            "r\\ Iteration: 271 Loss: 1.9891867637634277 | sasssssss|||ss| \n",
            "r\\ Iteration: 272 Loss: 2.063032627105713 | ssss|||s|s|s|s||| \n",
            "r\\ Iteration: 273 Loss: 1.9065847396850586 | sas|s||s|s|ss|s|| \n",
            "r\\ Iteration: 274 Loss: 2.0917551517486572 | s|ss|s||ss||| \n",
            "r\\ Iteration: 275 Loss: 2.1027135848999023 | sasss|s|s|s||| \n",
            "r\\ Iteration: 276 Loss: 2.002117395401001 | sas|ss|ss|ss|| \n",
            "r\\ Iteration: 277 Loss: 2.140786647796631 | s|ss|s|s|s||| \n",
            "r\\ Iteration: 278 Loss: 1.921485185623169 | sas||s|s|s|s||| \n",
            "r\\ Iteration: 279 Loss: 1.9811246395111084 | s|s|sss|s|| \n",
            "r\\ Iteration: 280 Loss: 2.1533584594726562 | s|sssss|sssss| \n",
            "r\\ Iteration: 281 Loss: 2.1141512393951416 | s|ss|s||s|s||||| \n",
            "r\\ Iteration: 282 Loss: 2.0806543827056885 | s||ss|s||ss| \n",
            "r\\ Iteration: 283 Loss: 2.1453773975372314 | s|ss|s||ss||| \n",
            "r\\ Iteration: 284 Loss: 2.107776641845703 | ss|sss|s|s|s||| \n",
            "r\\ Iteration: 285 Loss: 1.9812006950378418 | ssssss|s|ssss \n",
            "r\\ Iteration: 286 Loss: 1.8504631519317627 | sasss|s|s||| \n",
            "r\\ Iteration: 287 Loss: 1.9276390075683594 | ss||ss|ss|sss| \n",
            "r\\ Iteration: 288 Loss: 2.129204034805298 | s|||s||s||ss|s|| \n",
            "r\\ Iteration: 289 Loss: 1.9741034507751465 | sss|s|s|s|ssss \n",
            "r\\ Iteration: 290 Loss: 1.8446004390716553 | sss||sssss||ss|| \n",
            "r\\ Iteration: 291 Loss: 1.999901294708252 | s|s|s|ss|| \n",
            "r\\ Iteration: 292 Loss: 2.1865856647491455 | s||s|||s|s|s||| \n",
            "r\\ Iteration: 293 Loss: 1.9822099208831787 | saasss|s|s|s|| \n",
            "r\\ Iteration: 294 Loss: 2.1515088081359863 | ss|s|s|||| \n",
            "r\\ Iteration: 295 Loss: 2.170793294906616 | sss|||s|s|s||s \n",
            "r\\ Iteration: 296 Loss: 1.9441423416137695 | s|sss|s|s|| \n",
            "r\\ Iteration: 297 Loss: 1.981410264968872 | sss|s|s|ssssss \n",
            "r\\ Iteration: 298 Loss: 1.8557534217834473 | s|s||sss||ss| \n",
            "r\\ Iteration: 299 Loss: 2.143527030944824 | sss||||s|ssss \n",
            "r\\ Iteration: 300 Loss: 1.8449592590332031 | ss|s||||s|s||||s \n",
            "r\\ Iteration: 301 Loss: 1.98069167137146 | s||s|||s|s|s||| \n",
            "r\\ Iteration: 302 Loss: 2.0652592182159424 | s|s|ssss|s|| \n",
            "r\\ Iteration: 303 Loss: 2.2485463619232178 | sasss|s||s|ss|ss \n",
            "r\\ Iteration: 304 Loss: 2.0021655559539795 | s|sss|||sss||s|ss|| \n",
            "r\\ Iteration: 305 Loss: 2.1925880908966064 | s|s|s| \n",
            "r\\ Iteration: 306 Loss: 2.2458279132843018 | s|s|ss|ss|ssssss \n",
            "r\\ Iteration: 307 Loss: 2.0881166458129883 | sss|s|s|ssss \n",
            "r\\ Iteration: 308 Loss: 1.947455644607544 | s|ss|ss|ss|ssssss \n",
            "r\\ Iteration: 309 Loss: 2.064051389694214 | s|ss|||s| \n",
            "r\\ Iteration: 310 Loss: 2.1309733390808105 | s||s|s|s|ssss \n",
            "r\\ Iteration: 311 Loss: 1.9570302963256836 | s||sss||ss|s||||| \n",
            "r\\ Iteration: 312 Loss: 1.9749259948730469 | ss|||||s|s|s|ssss \n",
            "r\\ Iteration: 313 Loss: 1.9490532875061035 | sass||s|s||||| \n",
            "r\\ Iteration: 314 Loss: 1.9755525588989258 | ssss|sss|s|s|||ss \n",
            "r\\ Iteration: 315 Loss: 2.0051040649414062 | sas||s||ss| \n",
            "r\\ Iteration: 316 Loss: 1.8908116817474365 | s|sss|ss||ss| \n",
            "r\\ Iteration: 317 Loss: 2.2990810871124268 | s|sss||ss| \n",
            "r\\ Iteration: 318 Loss: 2.1245360374450684 | s|ss|||||| \n",
            "r\\ Iteration: 319 Loss: 2.100754737854004 | s|sss||s|||s|| \n",
            "r\\ Iteration: 320 Loss: 2.135751247406006 | sass|||||s||||| \n",
            "r\\ Iteration: 321 Loss: 1.949460506439209 | sss||||s|||| \n",
            "r\\ Iteration: 322 Loss: 2.0808370113372803 | s|ss||s||s|s|| \n",
            "r\\ Iteration: 323 Loss: 2.0303544998168945 | s|as||s|| \n",
            "r\\ Iteration: 324 Loss: 2.061063766479492 | s|||s|||||||||| \n",
            "r\\ Iteration: 325 Loss: 2.1090855598449707 | sas||||||s||||| \n",
            "r\\ Iteration: 326 Loss: 1.928558111190796 | s||||||s||||| \n",
            "r\\ Iteration: 327 Loss: 2.0097599029541016 | sass|||s||||| \n",
            "r\\ Iteration: 328 Loss: 1.8542368412017822 | s|s||||||||||| \n",
            "r\\ Iteration: 329 Loss: 2.120044231414795 | ss||s||||s||||| \n",
            "r\\ Iteration: 330 Loss: 1.987205982208252 | sas||||s|||s|ssss \n",
            "r\\ Iteration: 331 Loss: 1.9087483882904053 | s||s||||s||sss \n",
            "r\\ Iteration: 332 Loss: 1.9885377883911133 | s||||||||s|ss||| \n",
            "r\\ Iteration: 333 Loss: 2.002269983291626 | s||||||||s|ssss \n",
            "r\\ Iteration: 334 Loss: 2.0261635780334473 | s|||s||s|s||sss \n",
            "r\\ Iteration: 335 Loss: 2.026397943496704 | s|s||||| \n",
            "r\\ Iteration: 336 Loss: 2.091168165206909 | s||s|||||s||||| \n",
            "r\\ Iteration: 337 Loss: 1.9444730281829834 | s|||||ss||s||||| \n",
            "r\\ Iteration: 338 Loss: 1.994560956954956 | ss|||s||||||s|||||| \n",
            "r\\ Iteration: 339 Loss: 2.0944693088531494 | s|s||||s|||||||| \n",
            "r\\ Iteration: 340 Loss: 2.140049934387207 | ss|||||ss|||| \n",
            "r\\ Iteration: 341 Loss: 2.004169464111328 | s|||||||||s||||| \n",
            "r\\ Iteration: 342 Loss: 1.9419233798980713 | s||s|||||s||||| \n",
            "r\\ Iteration: 343 Loss: 1.9943091869354248 | ss|s||||s||||| \n",
            "r\\ Iteration: 344 Loss: 1.8617188930511475 | ss||||s||||| \n",
            "r\\ Iteration: 345 Loss: 1.9038052558898926 | s||||s|s|s||||| \n",
            "r\\ Iteration: 346 Loss: 1.89141845703125 | s|||||s|s||||| \n",
            "r\\ Iteration: 347 Loss: 1.9758427143096924 | s|||sasss|ss|||||| \n",
            "r\\ Iteration: 348 Loss: 2.195859909057617 | s||s||s||s||||| \n",
            "r\\ Iteration: 349 Loss: 2.0377819538116455 | s||||s|s||||| \n",
            "r\\ Iteration: 350 Loss: 1.852370262145996 | ss||sas|ss| \n",
            "r\\ Iteration: 351 Loss: 2.0722508430480957 | s|||s||s|s|| \n",
            "r\\ Iteration: 352 Loss: 2.0599746704101562 | s||s|||s||||| \n",
            "r\\ Iteration: 353 Loss: 1.8709754943847656 | s|s|s|sa||||||| \n",
            "r\\ Iteration: 354 Loss: 1.8968489170074463 | sas|sas||s||| \n",
            "r\\ Iteration: 355 Loss: 2.0449907779693604 | sss|s||||as||s||||| \n",
            "r\\ Iteration: 356 Loss: 1.9267230033874512 | s|||s||s|s||||| \n",
            "r\\ Iteration: 357 Loss: 1.879108190536499 | s|s|s||s|||| \n",
            "r\\ Iteration: 358 Loss: 2.149784803390503 | s||s|s|||| \n",
            "r\\ Iteration: 359 Loss: 2.095890998840332 | s|||||||s||s||||| \n",
            "r\\ Iteration: 360 Loss: 2.0467073917388916 | s||as|s||||| \n",
            "r\\ Iteration: 361 Loss: 1.893512487411499 | s|s||||s|||||||| \n",
            "r\\ Iteration: 362 Loss: 2.050797462463379 | saas|s||s||||| \n",
            "r\\ Iteration: 363 Loss: 1.993516206741333 | s||a|s||||s|||| \n",
            "r\\ Iteration: 364 Loss: 2.047424077987671 | s|a||ss||s||||| \n",
            "r\\ Iteration: 365 Loss: 1.9525322914123535 | s||a||||||s||||| \n",
            "r\\ Iteration: 366 Loss: 1.903026819229126 | saaa|||s|a||||| \n",
            "r\\ Iteration: 367 Loss: 1.9719679355621338 | saaaas|saas| \n",
            "r\\ Iteration: 368 Loss: 2.130751132965088 | s||||a|aa| \n",
            "r\\ Iteration: 369 Loss: 2.271266460418701 | saaaaaasaa||||| \n",
            "r\\ Iteration: 370 Loss: 1.9865868091583252 | s|aa||aaasa| \n",
            "r\\ Iteration: 371 Loss: 1.9933526515960693 | sa|aaaaaa||| \n",
            "r\\ Iteration: 372 Loss: 2.0446889400482178 | saaaaa|aaasa \n",
            "r\\ Iteration: 373 Loss: 2.0281336307525635 | saaa|aaaaaaaaaa \n",
            "r\\ Iteration: 374 Loss: 2.076874256134033 | saaa|aaa|a \n",
            "r\\ Iteration: 375 Loss: 2.042569875717163 | saaaaaaaaaaa \n",
            "r\\ Iteration: 376 Loss: 2.0695648193359375 | s|aaaaaaaaaaa \n",
            "r\\ Iteration: 377 Loss: 1.8985016345977783 | saaaaaaaaa \n",
            "r\\ Iteration: 378 Loss: 2.074887275695801 | saaaaa|aaaaaaa \n",
            "r\\ Iteration: 379 Loss: 2.0726912021636963 | saaaaaaaaaa \n",
            "r\\ Iteration: 380 Loss: 1.9332995414733887 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 381 Loss: 1.9349801540374756 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 382 Loss: 1.9011824131011963 | saaaaaaaaaaa \n",
            "r\\ Iteration: 383 Loss: 2.0449700355529785 | saaaaaaaaaaa \n",
            "r\\ Iteration: 384 Loss: 2.0313844680786133 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 385 Loss: 2.0780866146087646 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 386 Loss: 1.968050241470337 | saa|aaaaaaaaaa \n",
            "r\\ Iteration: 387 Loss: 1.9843308925628662 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 388 Loss: 2.0033137798309326 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 389 Loss: 1.9637060165405273 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 390 Loss: 2.027172803878784 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 391 Loss: 2.040709972381592 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 392 Loss: 2.148470878601074 | saaaaaaaaaaa \n",
            "r\\ Iteration: 393 Loss: 2.0268354415893555 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 394 Loss: 1.941455364227295 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 395 Loss: 1.8342368602752686 | saaaaaaa \n",
            "r\\ Iteration: 396 Loss: 2.0270800590515137 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 397 Loss: 1.9885931015014648 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 398 Loss: 1.9392762184143066 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 399 Loss: 2.10003924369812 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 400 Loss: 2.014211654663086 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 401 Loss: 1.9806885719299316 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 402 Loss: 2.1064233779907227 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 403 Loss: 1.9632618427276611 | saaaaaaaaa \n",
            "r\\ Iteration: 404 Loss: 2.069424867630005 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 405 Loss: 1.9567224979400635 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 406 Loss: 2.0590484142303467 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 407 Loss: 1.966238260269165 | saaaaaaaaaa \n",
            "r\\ Iteration: 408 Loss: 1.9175596237182617 | saaaaaaaaaaa \n",
            "r\\ Iteration: 409 Loss: 1.963474988937378 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 410 Loss: 1.881065845489502 | saaaaaaaaaaa \n",
            "r\\ Iteration: 411 Loss: 1.9787285327911377 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 412 Loss: 2.0770304203033447 | saaaaaaaaa \n",
            "r\\ Iteration: 413 Loss: 1.961690902709961 | saaaaaaaaaa \n",
            "r\\ Iteration: 414 Loss: 2.038867950439453 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 415 Loss: 1.9486217498779297 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 416 Loss: 1.8536877632141113 | saaaaaaaaaaa \n",
            "r\\ Iteration: 417 Loss: 1.9101965427398682 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 418 Loss: 2.0153846740722656 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 419 Loss: 1.9545207023620605 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 420 Loss: 2.169822931289673 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 421 Loss: 1.9462616443634033 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 422 Loss: 2.0238683223724365 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 423 Loss: 2.1437442302703857 | saaaaaaaaaaa \n",
            "r\\ Iteration: 424 Loss: 1.8510854244232178 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 425 Loss: 1.9671671390533447 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 426 Loss: 1.9230847358703613 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 427 Loss: 2.1722848415374756 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 428 Loss: 1.914264440536499 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 429 Loss: 1.9691364765167236 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 430 Loss: 2.1033530235290527 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 431 Loss: 1.9782764911651611 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 432 Loss: 1.9577033519744873 | saaaaaaaaaaa \n",
            "r\\ Iteration: 433 Loss: 1.89453125 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 434 Loss: 1.91306471824646 | saaaaaaaaa \n",
            "r\\ Iteration: 435 Loss: 2.1469955444335938 | saaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 436 Loss: 1.9786999225616455 | saaaaaaaaaaa \n",
            "r\\ Iteration: 437 Loss: 2.109116554260254 | saaaaaaaaaaa \n",
            "r\\ Iteration: 438 Loss: 2.014918327331543 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 439 Loss: 2.0014047622680664 | saaaaaaaaaaa \n",
            "r\\ Iteration: 440 Loss: 1.8892593383789062 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 441 Loss: 1.9691622257232666 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 442 Loss: 2.09983229637146 | saaaaaaaaa \n",
            "r\\ Iteration: 443 Loss: 2.217581272125244 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 444 Loss: 2.0183236598968506 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 445 Loss: 2.0542593002319336 | saaaaaaaaaaa \n",
            "r\\ Iteration: 446 Loss: 1.8594934940338135 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 447 Loss: 2.068458318710327 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 448 Loss: 1.969026803970337 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 449 Loss: 1.9959423542022705 | saaaaaaaaaa \n",
            "r\\ Iteration: 450 Loss: 2.0103061199188232 | saaaaaaa \n",
            "r\\ Iteration: 451 Loss: 1.799689531326294 | saaaaaaaaaaa \n",
            "r\\ Iteration: 452 Loss: 2.169921636581421 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 453 Loss: 2.0019125938415527 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 454 Loss: 1.8618853092193604 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 455 Loss: 1.9122016429901123 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 456 Loss: 2.124516487121582 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 457 Loss: 2.14251708984375 | saaaaaaaaa \n",
            "r\\ Iteration: 458 Loss: 2.108854055404663 | saaaaaaaa \n",
            "r\\ Iteration: 459 Loss: 1.8922157287597656 | saaaaaaaaa \n",
            "r\\ Iteration: 460 Loss: 2.0197741985321045 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 461 Loss: 1.9443223476409912 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 462 Loss: 1.8807778358459473 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 463 Loss: 1.8855457305908203 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 464 Loss: 2.1051926612854004 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 465 Loss: 1.9516122341156006 | saaaaaaaaa \n",
            "r\\ Iteration: 466 Loss: 2.0954220294952393 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 467 Loss: 1.953113317489624 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 468 Loss: 1.904273509979248 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 469 Loss: 2.197382926940918 | saaaaaaaaaaa \n",
            "r\\ Iteration: 470 Loss: 2.0167489051818848 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 471 Loss: 2.0221192836761475 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 472 Loss: 2.0128228664398193 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 473 Loss: 1.982349157333374 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 474 Loss: 1.9438228607177734 | saaaaaaaaa \n",
            "r\\ Iteration: 475 Loss: 2.0334224700927734 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 476 Loss: 1.9000749588012695 | saaaaaaaaaaa \n",
            "r\\ Iteration: 477 Loss: 2.0866079330444336 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 478 Loss: 2.1330149173736572 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 479 Loss: 2.0263848304748535 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 480 Loss: 1.864931583404541 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 481 Loss: 1.9384665489196777 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 482 Loss: 2.014549970626831 | saaaaaaaa \n",
            "r\\ Iteration: 483 Loss: 2.0574758052825928 | saaaaa \n",
            "r\\ Iteration: 484 Loss: 1.9935851097106934 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 485 Loss: 2.1333045959472656 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 486 Loss: 1.8501605987548828 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 487 Loss: 1.8463046550750732 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 488 Loss: 2.123746633529663 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 489 Loss: 1.9374406337738037 | saaaaaaaaa \n",
            "r\\ Iteration: 490 Loss: 2.0163893699645996 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 491 Loss: 1.9792819023132324 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 492 Loss: 1.8037729263305664 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 493 Loss: 2.0334742069244385 | saaaaaaaaaaa \n",
            "r\\ Iteration: 494 Loss: 2.062068223953247 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 495 Loss: 1.8900096416473389 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 496 Loss: 1.8944387435913086 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 497 Loss: 1.9968163967132568 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 498 Loss: 2.0911662578582764 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 499 Loss: 2.1519269943237305 | saaaaaaaaa \n",
            "r\\ Iteration: 500 Loss: 2.0497679710388184 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 501 Loss: 2.104889392852783 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 502 Loss: 2.0064663887023926 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 503 Loss: 2.067963123321533 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 504 Loss: 1.8723700046539307 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 505 Loss: 1.9643402099609375 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 506 Loss: 1.9260497093200684 | saaaaaaaaaa \n",
            "r\\ Iteration: 507 Loss: 2.106811285018921 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 508 Loss: 1.9760830402374268 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 509 Loss: 2.0689711570739746 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 510 Loss: 1.9086308479309082 | saaaaaaaaaa \n",
            "r\\ Iteration: 511 Loss: 1.8647098541259766 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 512 Loss: 1.9314134120941162 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 513 Loss: 2.0334722995758057 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 514 Loss: 1.936927080154419 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 515 Loss: 2.0528814792633057 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 516 Loss: 2.029130697250366 | saaaaaaaa \n",
            "r\\ Iteration: 517 Loss: 2.0618388652801514 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 518 Loss: 2.0733437538146973 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 519 Loss: 1.8663651943206787 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 520 Loss: 1.8666253089904785 | saaaaaaaaa \n",
            "r\\ Iteration: 521 Loss: 1.9985134601593018 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 522 Loss: 1.936619758605957 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 523 Loss: 2.0954689979553223 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 524 Loss: 2.13482928276062 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 525 Loss: 1.9075038433074951 | saaaaaaaaaa \n",
            "r\\ Iteration: 526 Loss: 2.0792555809020996 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 527 Loss: 2.1579177379608154 | saaaaaaaaaa \n",
            "r\\ Iteration: 528 Loss: 1.8349556922912598 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 529 Loss: 1.9151785373687744 | saaaaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 530 Loss: 1.918855905532837 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 531 Loss: 1.8232231140136719 | saaaaaaaaaaa \n",
            "r\\ Iteration: 532 Loss: 1.865849256515503 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 533 Loss: 1.9529428482055664 | saaaaaaaaaaa \n",
            "r\\ Iteration: 534 Loss: 1.8092405796051025 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 535 Loss: 2.053126573562622 | saaaaaaaa \n",
            "r\\ Iteration: 536 Loss: 1.9222311973571777 | saaaaaaa \n",
            "r\\ Iteration: 537 Loss: 2.2019195556640625 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 538 Loss: 1.9741942882537842 | saaaaaaaaaa \n",
            "r\\ Iteration: 539 Loss: 1.932579517364502 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 540 Loss: 2.022099018096924 | saaaaaaaaaa \n",
            "r\\ Iteration: 541 Loss: 2.106536388397217 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 542 Loss: 2.0449912548065186 | saaaaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 543 Loss: 2.0033392906188965 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 544 Loss: 1.8248624801635742 | saaaaaaaaaaa \n",
            "r\\ Iteration: 545 Loss: 1.931288719177246 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 546 Loss: 2.0564374923706055 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 547 Loss: 1.9569244384765625 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 548 Loss: 2.2546722888946533 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 549 Loss: 1.9958062171936035 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 550 Loss: 2.187441349029541 | saaaaaaaaaaa \n",
            "r\\ Iteration: 551 Loss: 1.825305700302124 | saaaaaaaaaaa \n",
            "r\\ Iteration: 552 Loss: 1.9963867664337158 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 553 Loss: 1.8788878917694092 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 554 Loss: 2.022986650466919 | saaaaaaaaa \n",
            "r\\ Iteration: 555 Loss: 1.9590277671813965 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 556 Loss: 1.816845178604126 | saaaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 557 Loss: 1.914402723312378 | saaaaaaaaa \n",
            "r\\ Iteration: 558 Loss: 2.222531795501709 | saaaaaaaaaaa \n",
            "r\\ Iteration: 559 Loss: 1.82021164894104 | saaaaaaaaaa \n",
            "r\\ Iteration: 560 Loss: 2.0590643882751465 | saaaaaaaaaaa \n",
            "r\\ Iteration: 561 Loss: 2.1039681434631348 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 562 Loss: 2.0584940910339355 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 563 Loss: 2.0466549396514893 | saaaaaaaaaaa \n",
            "r\\ Iteration: 564 Loss: 1.9237382411956787 | saaaaaaaaaaa \n",
            "r\\ Iteration: 565 Loss: 2.0380935668945312 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 566 Loss: 2.052731990814209 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 567 Loss: 1.9413466453552246 | saaaaaaaaaa \n",
            "r\\ Iteration: 568 Loss: 2.064652442932129 | saaaaaaaaaaa \n",
            "r\\ Iteration: 569 Loss: 1.7865533828735352 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 570 Loss: 1.9151830673217773 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 571 Loss: 2.0642306804656982 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 572 Loss: 1.8549506664276123 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 573 Loss: 1.8678500652313232 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 574 Loss: 1.9134578704833984 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 575 Loss: 2.2095248699188232 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 576 Loss: 1.9312012195587158 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 577 Loss: 1.8388843536376953 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 578 Loss: 1.8455190658569336 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 579 Loss: 1.919795274734497 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 580 Loss: 1.9813215732574463 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 581 Loss: 2.180878162384033 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 582 Loss: 1.8270573616027832 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 583 Loss: 1.8901755809783936 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 584 Loss: 1.898749828338623 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 585 Loss: 2.1726715564727783 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 586 Loss: 1.8278987407684326 | saaaaaaaaa \n",
            "r\\ Iteration: 587 Loss: 1.9768872261047363 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 588 Loss: 2.0028555393218994 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 589 Loss: 1.8579881191253662 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 590 Loss: 1.8702528476715088 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 591 Loss: 2.1778998374938965 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 592 Loss: 1.8952083587646484 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 593 Loss: 1.8890793323516846 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 594 Loss: 2.1336231231689453 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 595 Loss: 2.0350775718688965 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 596 Loss: 1.972278118133545 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 597 Loss: 2.0709221363067627 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 598 Loss: 2.0806095600128174 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 599 Loss: 1.8741073608398438 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 600 Loss: 2.037410020828247 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 601 Loss: 1.956411361694336 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 602 Loss: 1.875603437423706 | saaaaaaaaaaa \n",
            "r\\ Iteration: 603 Loss: 2.0756027698516846 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 604 Loss: 1.89821457862854 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 605 Loss: 1.8460290431976318 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 606 Loss: 1.8026018142700195 | saaaaaa \n",
            "r\\ Iteration: 607 Loss: 1.8689568042755127 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 608 Loss: 2.0052778720855713 | saaaaaa \n",
            "r\\ Iteration: 609 Loss: 1.738236665725708 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 610 Loss: 1.968416452407837 | saaaaaaaaaa \n",
            "r\\ Iteration: 611 Loss: 1.8332734107971191 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 612 Loss: 2.0155253410339355 | saaaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 613 Loss: 2.1185529232025146 | saaaaaaaaaa \n",
            "r\\ Iteration: 614 Loss: 1.9717929363250732 | saaaaaaaaaaa \n",
            "r\\ Iteration: 615 Loss: 2.1449477672576904 | saaaaaaaaaaa \n",
            "r\\ Iteration: 616 Loss: 2.090843915939331 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 617 Loss: 2.0545084476470947 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 618 Loss: 1.9711227416992188 | saaaaaaaaaaa \n",
            "r\\ Iteration: 619 Loss: 2.1314117908477783 | saaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 620 Loss: 1.955045461654663 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 621 Loss: 2.2181997299194336 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 622 Loss: 1.9478282928466797 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 623 Loss: 2.1778738498687744 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 624 Loss: 2.062187433242798 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 625 Loss: 1.8256499767303467 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 626 Loss: 1.8256924152374268 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 627 Loss: 1.9984745979309082 | saaaaaaaaaaa \n",
            "r\\ Iteration: 628 Loss: 2.2334861755371094 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 629 Loss: 1.911517858505249 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 630 Loss: 1.9007577896118164 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 631 Loss: 1.9530103206634521 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 632 Loss: 1.8865392208099365 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 633 Loss: 2.0871570110321045 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 634 Loss: 1.8255693912506104 | saaaaaaaaa \n",
            "r\\ Iteration: 635 Loss: 2.218916893005371 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 636 Loss: 1.8275463581085205 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 637 Loss: 1.9381203651428223 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 638 Loss: 1.8878328800201416 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 639 Loss: 2.0815603733062744 | saaaaaaaaaaa \n",
            "r\\ Iteration: 640 Loss: 2.097454786300659 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 641 Loss: 1.8647828102111816 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 642 Loss: 1.9115040302276611 | saaaaaaaaaaa \n",
            "r\\ Iteration: 643 Loss: 1.9768462181091309 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 644 Loss: 1.809798002243042 | saaaaaaaaaaa \n",
            "r\\ Iteration: 645 Loss: 1.8084454536437988 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 646 Loss: 1.9747328758239746 | saaaaaaaaaaa \n",
            "r\\ Iteration: 647 Loss: 1.9799284934997559 | saaaaaaaaaaa \n",
            "r\\ Iteration: 648 Loss: 1.7997331619262695 | saaaaaaaaaaa \n",
            "r\\ Iteration: 649 Loss: 1.8870725631713867 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 650 Loss: 1.811553716659546 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 651 Loss: 1.9350090026855469 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 652 Loss: 2.1017074584960938 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 653 Loss: 2.00763201713562 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 654 Loss: 2.1066181659698486 | saaaaaaaaaa \n",
            "r\\ Iteration: 655 Loss: 2.0999765396118164 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 656 Loss: 2.0199289321899414 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 657 Loss: 2.077688217163086 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 658 Loss: 2.2151498794555664 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 659 Loss: 2.023529052734375 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 660 Loss: 1.8850479125976562 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 661 Loss: 1.9526567459106445 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 662 Loss: 2.1502842903137207 | saaaa \n",
            "r\\ Iteration: 663 Loss: 2.2522873878479004 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 664 Loss: 1.8150227069854736 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 665 Loss: 1.909975528717041 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 666 Loss: 1.9583775997161865 | saaaaaaaaa \n",
            "r\\ Iteration: 667 Loss: 1.994445562362671 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 668 Loss: 1.8876655101776123 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 669 Loss: 2.10203218460083 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 670 Loss: 1.8803520202636719 | saaaaaaaaaa \n",
            "r\\ Iteration: 671 Loss: 2.1191067695617676 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 672 Loss: 2.139641761779785 | saaaaaaaaaaa \n",
            "r\\ Iteration: 673 Loss: 2.0520334243774414 | saaaaaaaaa \n",
            "r\\ Iteration: 674 Loss: 2.205083131790161 | saaaaaaaaaaa \n",
            "r\\ Iteration: 675 Loss: 2.020967960357666 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 676 Loss: 1.9748351573944092 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 677 Loss: 1.8814880847930908 | saaaaaaaaaaa \n",
            "r\\ Iteration: 678 Loss: 2.0848684310913086 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 679 Loss: 2.054680109024048 | saaaaaaaaaa \n",
            "r\\ Iteration: 680 Loss: 2.0650784969329834 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 681 Loss: 2.0675384998321533 | saaaaaaaaaaa \n",
            "r\\ Iteration: 682 Loss: 1.926757574081421 | saaaaaaaaaaa \n",
            "r\\ Iteration: 683 Loss: 2.0551772117614746 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 684 Loss: 2.169128179550171 | saaaaaaaaa \n",
            "r\\ Iteration: 685 Loss: 1.954279899597168 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 686 Loss: 1.9196240901947021 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 687 Loss: 1.9152710437774658 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 688 Loss: 1.8132927417755127 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 689 Loss: 1.9317798614501953 | saaaaaaaaaaa \n",
            "r\\ Iteration: 690 Loss: 2.075249671936035 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 691 Loss: 1.8011460304260254 | saaaaaaaaaa \n",
            "r\\ Iteration: 692 Loss: 2.0278799533843994 | saaaaaaaaaaa \n",
            "r\\ Iteration: 693 Loss: 1.8026354312896729 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 694 Loss: 1.9855480194091797 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 695 Loss: 1.8106286525726318 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 696 Loss: 1.9180347919464111 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 697 Loss: 1.795267105102539 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 698 Loss: 1.9765033721923828 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 699 Loss: 1.9313061237335205 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 700 Loss: 1.7819538116455078 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 701 Loss: 2.0952348709106445 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 702 Loss: 1.9768145084381104 | saaaaaaaaaa \n",
            "r\\ Iteration: 703 Loss: 2.115941286087036 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 704 Loss: 2.0480852127075195 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 705 Loss: 2.1616382598876953 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 706 Loss: 1.8749098777770996 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 707 Loss: 1.8040223121643066 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 708 Loss: 2.0737521648406982 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 709 Loss: 1.863046407699585 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 710 Loss: 1.9738075733184814 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 711 Loss: 1.7664902210235596 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 712 Loss: 2.0600879192352295 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 713 Loss: 1.9634990692138672 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 714 Loss: 1.8759276866912842 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 715 Loss: 2.1443793773651123 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 716 Loss: 1.8168418407440186 | saaaaaaaaa \n",
            "r\\ Iteration: 717 Loss: 1.9623587131500244 | saaaaaaaaaaa \n",
            "r\\ Iteration: 718 Loss: 2.0707590579986572 | saaaaaaaaa \n",
            "r\\ Iteration: 719 Loss: 1.8605542182922363 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 720 Loss: 2.038459062576294 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 721 Loss: 2.032456636428833 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 722 Loss: 2.029125213623047 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 723 Loss: 1.9822940826416016 | saaaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 724 Loss: 2.0760488510131836 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 725 Loss: 1.8559026718139648 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 726 Loss: 1.9505658149719238 | saaaaaaaaaaa \n",
            "r\\ Iteration: 727 Loss: 1.7902157306671143 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 728 Loss: 1.8227207660675049 | saaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 729 Loss: 1.925920009613037 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 730 Loss: 2.1257095336914062 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 731 Loss: 1.868537425994873 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 732 Loss: 1.8866119384765625 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 733 Loss: 1.8749473094940186 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 734 Loss: 1.9740879535675049 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 735 Loss: 1.8272700309753418 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 736 Loss: 2.0170938968658447 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 737 Loss: 1.990309476852417 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 738 Loss: 1.8808157444000244 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 739 Loss: 1.953120231628418 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 740 Loss: 2.0385959148406982 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 741 Loss: 1.819350004196167 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 742 Loss: 2.110445737838745 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 743 Loss: 1.9417524337768555 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 744 Loss: 1.9298789501190186 | saaaaaaaaaaa \n",
            "r\\ Iteration: 745 Loss: 2.139437198638916 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 746 Loss: 2.0161919593811035 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 747 Loss: 2.026702642440796 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 748 Loss: 1.8673224449157715 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 749 Loss: 1.94911789894104 | saaaaaaaaaa \n",
            "r\\ Iteration: 750 Loss: 2.1546027660369873 | saaaaaaaaaaa \n",
            "r\\ Iteration: 751 Loss: 1.9870491027832031 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 752 Loss: 1.9690847396850586 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 753 Loss: 1.8432042598724365 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 754 Loss: 1.9599723815917969 | sauaaaaaaaaaaaaa \n",
            "r\\ Iteration: 755 Loss: 2.017972469329834 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 756 Loss: 2.061081647872925 | sauuuuaeuuaau \n",
            "r\\ Iteration: 757 Loss: 2.0539932250976562 | suaeuaueeeuuaau \n",
            "r\\ Iteration: 758 Loss: 2.156005859375 | seuuaueeeeu \n",
            "r\\ Iteration: 759 Loss: 2.020530939102173 | seueeueeeee \n",
            "r\\ Iteration: 760 Loss: 2.0264334678649902 | seeeeeeeeeeaau \n",
            "r\\ Iteration: 761 Loss: 1.9685251712799072 | seeeeeeeaeaeaae \n",
            "r\\ Iteration: 762 Loss: 1.9023187160491943 | seaeeeeeeeeaeeee \n",
            "r\\ Iteration: 763 Loss: 2.0526511669158936 | seeeeeeeeeeeeae \n",
            "r\\ Iteration: 764 Loss: 2.1373884677886963 | seeeeaeeeeeaeaeaae \n",
            "r\\ Iteration: 765 Loss: 2.035989761352539 | seeeeeaeaeaee \n",
            "r\\ Iteration: 766 Loss: 1.9410135746002197 | seeeeeeeaeaeaee \n",
            "r\\ Iteration: 767 Loss: 1.919893503189087 | seeeeeeee \n",
            "r\\ Iteration: 768 Loss: 1.9923593997955322 | seeeeeeeeeee \n",
            "r\\ Iteration: 769 Loss: 2.061671495437622 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 770 Loss: 1.9349994659423828 | seeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 771 Loss: 1.8883814811706543 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 772 Loss: 2.120807647705078 | seeeeeeeeeeee \n",
            "r\\ Iteration: 773 Loss: 1.856292724609375 | seeeeeeeee \n",
            "r\\ Iteration: 774 Loss: 1.9131441116333008 | seeeeeee \n",
            "r\\ Iteration: 775 Loss: 2.024885654449463 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 776 Loss: 1.9063971042633057 | seeeeeeeeeee \n",
            "r\\ Iteration: 777 Loss: 1.9610319137573242 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 778 Loss: 1.9761021137237549 | seeeeeeeeeeee \n",
            "r\\ Iteration: 779 Loss: 2.0116472244262695 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 780 Loss: 1.9551470279693604 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 781 Loss: 2.022425889968872 | seeeeeeeeeee \n",
            "r\\ Iteration: 782 Loss: 2.1666336059570312 | seeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 783 Loss: 2.045525312423706 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 784 Loss: 1.966437816619873 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 785 Loss: 1.8821017742156982 | seeeeeeeeeee \n",
            "r\\ Iteration: 786 Loss: 1.9948174953460693 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 787 Loss: 1.9707810878753662 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 788 Loss: 2.042745351791382 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 789 Loss: 2.0953567028045654 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 790 Loss: 1.8828115463256836 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 791 Loss: 1.952599048614502 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 792 Loss: 2.072641134262085 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 793 Loss: 1.8328709602355957 | seeeeeeeeeeee \n",
            "r\\ Iteration: 794 Loss: 1.9019644260406494 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 795 Loss: 1.8013222217559814 | seeeeeeeeeeee \n",
            "r\\ Iteration: 796 Loss: 2.1623599529266357 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 797 Loss: 2.1194748878479004 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 798 Loss: 1.7599422931671143 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 799 Loss: 1.943690299987793 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 800 Loss: 1.9344298839569092 | seeeeeeeeeee \n",
            "r\\ Iteration: 801 Loss: 2.1811583042144775 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 802 Loss: 1.8075251579284668 | seeeeeee \n",
            "r\\ Iteration: 803 Loss: 1.8617122173309326 | seeeeeeeeeeee \n",
            "r\\ Iteration: 804 Loss: 2.230059862136841 | seeeeeeeeeee \n",
            "r\\ Iteration: 805 Loss: 2.0912904739379883 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 806 Loss: 2.0950353145599365 | seeeeeeeeeeee \n",
            "r\\ Iteration: 807 Loss: 1.9609901905059814 | seeeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 808 Loss: 2.0464279651641846 | seeeeeeeeeeee \n",
            "r\\ Iteration: 809 Loss: 1.95686936378479 | seeeeeeeeeee \n",
            "r\\ Iteration: 810 Loss: 1.814077377319336 | seeeeeeeeeeee \n",
            "r\\ Iteration: 811 Loss: 1.9150192737579346 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 812 Loss: 2.0648252964019775 | seeeeeeeeeeee \n",
            "r\\ Iteration: 813 Loss: 1.9118564128875732 | seeeeeeeeeeee \n",
            "r\\ Iteration: 814 Loss: 1.9047067165374756 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 815 Loss: 2.0747880935668945 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 816 Loss: 1.8065180778503418 | seeeeeeeeeeee \n",
            "r\\ Iteration: 817 Loss: 1.9407222270965576 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 818 Loss: 1.8788626194000244 | seeeeeeeeeee \n",
            "r\\ Iteration: 819 Loss: 1.9124464988708496 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 820 Loss: 1.8745357990264893 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 821 Loss: 1.8285119533538818 | seeeeeeeeeee \n",
            "r\\ Iteration: 822 Loss: 1.9406447410583496 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 823 Loss: 2.087289810180664 | seeeeeeee \n",
            "r\\ Iteration: 824 Loss: 2.2363460063934326 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 825 Loss: 2.0961968898773193 | seeeeeeeeeee \n",
            "r\\ Iteration: 826 Loss: 2.1350035667419434 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 827 Loss: 2.0527939796447754 | seeeeeeeeeee \n",
            "r\\ Iteration: 828 Loss: 1.8902246952056885 | seeeeeeee \n",
            "r\\ Iteration: 829 Loss: 1.9227094650268555 | seeeeeeeeeee \n",
            "r\\ Iteration: 830 Loss: 1.7669947147369385 | seeeeeeeeeee \n",
            "r\\ Iteration: 831 Loss: 2.0333359241485596 | seeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 832 Loss: 2.015812397003174 | seeeeeeeeeeee \n",
            "r\\ Iteration: 833 Loss: 2.001953363418579 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 834 Loss: 2.0140109062194824 | seeeeeeeeeeee \n",
            "r\\ Iteration: 835 Loss: 2.0112597942352295 | seeeeeeeeeee \n",
            "r\\ Iteration: 836 Loss: 1.8916511535644531 | seeeeeeeeee \n",
            "r\\ Iteration: 837 Loss: 2.0744481086730957 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 838 Loss: 2.023651599884033 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 839 Loss: 2.1046864986419678 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 840 Loss: 1.897890567779541 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 841 Loss: 2.0237839221954346 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 842 Loss: 2.059347629547119 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 843 Loss: 2.0568430423736572 | seeeeeeeeeee \n",
            "r\\ Iteration: 844 Loss: 1.906769037246704 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 845 Loss: 1.930131435394287 | seeeeeeee \n",
            "r\\ Iteration: 846 Loss: 2.0790302753448486 | seeeeeeeeeee \n",
            "r\\ Iteration: 847 Loss: 2.176010847091675 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 848 Loss: 2.003523111343384 | seeeeeeeeeee \n",
            "r\\ Iteration: 849 Loss: 2.246314764022827 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 850 Loss: 1.9156057834625244 | seeeeeeeee \n",
            "r\\ Iteration: 851 Loss: 2.077502727508545 | seeeeeeeeeeee \n",
            "r\\ Iteration: 852 Loss: 1.9480922222137451 | seeeeeeeeeee \n",
            "r\\ Iteration: 853 Loss: 2.037043571472168 | seeeeeeeeee \n",
            "r\\ Iteration: 854 Loss: 2.0622525215148926 | seeeeeeeeeeee \n",
            "r\\ Iteration: 855 Loss: 1.914830207824707 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 856 Loss: 1.980851650238037 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 857 Loss: 1.9742403030395508 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 858 Loss: 1.9895586967468262 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 859 Loss: 1.8727977275848389 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 860 Loss: 1.905095100402832 | seeeeeeeeeee \n",
            "r\\ Iteration: 861 Loss: 2.0950546264648438 | seeeeeeeee \n",
            "r\\ Iteration: 862 Loss: 1.9984502792358398 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 863 Loss: 1.903916597366333 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 864 Loss: 2.051520347595215 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 865 Loss: 2.0020952224731445 | seeeeeee \n",
            "r\\ Iteration: 866 Loss: 2.0828890800476074 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 867 Loss: 1.8468599319458008 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 868 Loss: 1.9230132102966309 | seeeeeeeeee \n",
            "r\\ Iteration: 869 Loss: 2.0704665184020996 | seeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 870 Loss: 2.0160868167877197 | seeeeeeeeeee \n",
            "r\\ Iteration: 871 Loss: 2.0660057067871094 | seeeeeeee \n",
            "r\\ Iteration: 872 Loss: 2.0590991973876953 | seeeeeeeeeeee \n",
            "r\\ Iteration: 873 Loss: 2.0956592559814453 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 874 Loss: 2.0994763374328613 | seeeeeeeeeeee \n",
            "r\\ Iteration: 875 Loss: 1.874671220779419 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 876 Loss: 1.9545366764068604 | seeeeeeeeeeee \n",
            "r\\ Iteration: 877 Loss: 1.7692899703979492 | seeeeeeeee \n",
            "r\\ Iteration: 878 Loss: 2.01931095123291 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 879 Loss: 2.1229729652404785 | seeeeeeee \n",
            "r\\ Iteration: 880 Loss: 2.2045767307281494 | seeeeeeeeeeee \n",
            "r\\ Iteration: 881 Loss: 1.9406335353851318 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 882 Loss: 1.9059689044952393 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 883 Loss: 1.911280870437622 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 884 Loss: 1.9613037109375 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 885 Loss: 1.9606704711914062 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 886 Loss: 1.9739515781402588 | seeeeeeeee \n",
            "r\\ Iteration: 887 Loss: 1.991055965423584 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 888 Loss: 1.9615671634674072 | seeeeeeeeee \n",
            "r\\ Iteration: 889 Loss: 1.9833645820617676 | seeeeeeeeeeee \n",
            "r\\ Iteration: 890 Loss: 1.9644925594329834 | seeeeeeeeeee \n",
            "r\\ Iteration: 891 Loss: 2.024306535720825 | seeeeeeeeeeee \n",
            "r\\ Iteration: 892 Loss: 1.9309518337249756 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 893 Loss: 1.9572522640228271 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 894 Loss: 2.06406831741333 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 895 Loss: 2.034721851348877 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 896 Loss: 1.9910931587219238 | seeeeeeeeeeee \n",
            "r\\ Iteration: 897 Loss: 2.1528217792510986 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 898 Loss: 1.883361577987671 | seeeeeeeee \n",
            "r\\ Iteration: 899 Loss: 2.2202773094177246 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 900 Loss: 1.8339855670928955 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 901 Loss: 1.8354830741882324 | seeeeeeeeeee \n",
            "r\\ Iteration: 902 Loss: 2.0278878211975098 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 903 Loss: 1.9372808933258057 | seeeeeeeeeee \n",
            "r\\ Iteration: 904 Loss: 2.070723056793213 | seeeeeeeee \n",
            "r\\ Iteration: 905 Loss: 1.9826345443725586 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 906 Loss: 1.8877592086791992 | seeeeeeeeee \n",
            "r\\ Iteration: 907 Loss: 1.9429523944854736 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 908 Loss: 1.9102258682250977 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 909 Loss: 1.8710861206054688 | seeeeeeeeeee \n",
            "r\\ Iteration: 910 Loss: 2.0705606937408447 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 911 Loss: 1.9116456508636475 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 912 Loss: 2.0144121646881104 | seeeeeeeeee \n",
            "r\\ Iteration: 913 Loss: 1.8423330783843994 | seeeeeee \n",
            "r\\ Iteration: 914 Loss: 2.053657054901123 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 915 Loss: 2.18984317779541 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 916 Loss: 1.9572062492370605 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 917 Loss: 1.9126255512237549 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 918 Loss: 1.8609652519226074 | seeeeeeeeeeee \n",
            "r\\ Iteration: 919 Loss: 1.9802589416503906 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 920 Loss: 1.8365931510925293 | seeeeeeeeeeee \n",
            "r\\ Iteration: 921 Loss: 2.065659284591675 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 922 Loss: 1.9781947135925293 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 923 Loss: 2.189666748046875 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 924 Loss: 1.9095277786254883 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 925 Loss: 1.983280897140503 | seeeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 926 Loss: 1.95823073387146 | seeeeeeeeeeee \n",
            "r\\ Iteration: 927 Loss: 1.9198472499847412 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 928 Loss: 1.955413579940796 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 929 Loss: 1.9759140014648438 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 930 Loss: 2.031423330307007 | seeeeeeeeeeee \n",
            "r\\ Iteration: 931 Loss: 1.8352305889129639 | seeeeeeeeeeee \n",
            "r\\ Iteration: 932 Loss: 1.9840211868286133 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 933 Loss: 1.889448642730713 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 934 Loss: 2.0364291667938232 | seeeeeeeee \n",
            "r\\ Iteration: 935 Loss: 1.9650208950042725 | seeeeeeeeeeee \n",
            "r\\ Iteration: 936 Loss: 1.8521335124969482 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 937 Loss: 1.753767728805542 | seeeeeeeee \n",
            "r\\ Iteration: 938 Loss: 2.2328786849975586 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 939 Loss: 1.8804738521575928 | seeeeeeeeeee \n",
            "r\\ Iteration: 940 Loss: 2.0117735862731934 | seeeeee \n",
            "r\\ Iteration: 941 Loss: 1.7602832317352295 | seeeeeeeee \n",
            "r\\ Iteration: 942 Loss: 2.089930534362793 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 943 Loss: 1.9905691146850586 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 944 Loss: 2.2172138690948486 | seeeeeeeeeee \n",
            "r\\ Iteration: 945 Loss: 2.1192610263824463 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 946 Loss: 1.907564640045166 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 947 Loss: 2.078019618988037 | seeeeeeeeeee \n",
            "r\\ Iteration: 948 Loss: 2.0645217895507812 | seeeeeeeee \n",
            "r\\ Iteration: 949 Loss: 2.1516823768615723 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 950 Loss: 1.8561816215515137 | seeeeeeeeee \n",
            "r\\ Iteration: 951 Loss: 1.9402637481689453 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 952 Loss: 1.8275904655456543 | seeeeeeeeeee \n",
            "r\\ Iteration: 953 Loss: 2.089442491531372 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 954 Loss: 1.8626058101654053 | seeeeeeeeeeee \n",
            "r\\ Iteration: 955 Loss: 1.820389986038208 | seeeeeeeeee \n",
            "r\\ Iteration: 956 Loss: 2.0927581787109375 | seeeheeeee \n",
            "r\\ Iteration: 957 Loss: 2.211190700531006 | seeeeeeeee \n",
            "r\\ Iteration: 958 Loss: 2.1151700019836426 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 959 Loss: 1.9368646144866943 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 960 Loss: 1.9539210796356201 | seeheeeeeeeeeeeee \n",
            "r\\ Iteration: 961 Loss: 1.9623534679412842 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 962 Loss: 2.0365755558013916 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 963 Loss: 1.8136377334594727 | seeeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 964 Loss: 1.8937962055206299 | seehehheeheeeee \n",
            "r\\ Iteration: 965 Loss: 1.9564878940582275 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 966 Loss: 1.9873216152191162 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 967 Loss: 1.8395566940307617 | seeeeeeeheeeee \n",
            "r\\ Iteration: 968 Loss: 1.9177484512329102 | seeeeeeee \n",
            "r\\ Iteration: 969 Loss: 1.9747767448425293 | seeeeeeeeeeee \n",
            "r\\ Iteration: 970 Loss: 1.7505266666412354 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 971 Loss: 2.060115337371826 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 972 Loss: 1.9936637878417969 | seeeeeeeeeeee \n",
            "r\\ Iteration: 973 Loss: 1.891463041305542 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 974 Loss: 1.907346487045288 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 975 Loss: 1.9114880561828613 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 976 Loss: 1.9069712162017822 | seeeeeeeee \n",
            "r\\ Iteration: 977 Loss: 2.2091012001037598 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 978 Loss: 2.0394740104675293 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 979 Loss: 1.9678070545196533 | seeeeeeeeeee \n",
            "r\\ Iteration: 980 Loss: 1.9848532676696777 | seeeeee \n",
            "r\\ Iteration: 981 Loss: 1.971022367477417 | seneeeeeeeeeeeee \n",
            "r\\ Iteration: 982 Loss: 1.9362428188323975 | seeeeeeeeee \n",
            "r\\ Iteration: 983 Loss: 1.851038932800293 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 984 Loss: 1.7566280364990234 | seeeeeeeeeee \n",
            "r\\ Iteration: 985 Loss: 1.871800422668457 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 986 Loss: 2.004507064819336 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 987 Loss: 2.010113477706909 | seeeeeeeeeeee \n",
            "r\\ Iteration: 988 Loss: 1.8134291172027588 | seeeeeeeeeee \n",
            "r\\ Iteration: 989 Loss: 1.832657814025879 | seeeeeeeeeeee \n",
            "r\\ Iteration: 990 Loss: 1.9118435382843018 | seeeeeeeeeee \n",
            "r\\ Iteration: 991 Loss: 1.9021155834197998 | seeeeeeeeee \n",
            "r\\ Iteration: 992 Loss: 1.9311244487762451 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 993 Loss: 2.060866117477417 | seeeeeeeeeeee \n",
            "r\\ Iteration: 994 Loss: 1.7336866855621338 | seneeeeeeeeee \n",
            "r\\ Iteration: 995 Loss: 1.8177919387817383 | seeeneeeeeeeee \n",
            "r\\ Iteration: 996 Loss: 1.9340236186981201 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 997 Loss: 2.159473419189453 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 998 Loss: 1.8607239723205566 | seeeeeeeeeee \n",
            "r\\ Iteration: 999 Loss: 1.9918889999389648 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1000 Loss: 1.8660154342651367 | seheeheeeeeeeee \n",
            "r\\ Iteration: 1001 Loss: 2.0270020961761475 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 1002 Loss: 1.961359977722168 | seeeeeeeeeeee \n",
            "r\\ Iteration: 1003 Loss: 1.8833332061767578 | seeheeeeeeee \n",
            "r\\ Iteration: 1004 Loss: 1.8888213634490967 | seeheeheeeeeeeee \n",
            "r\\ Iteration: 1005 Loss: 1.8639781475067139 | seheheheeheeeeeee \n",
            "r\\ Iteration: 1006 Loss: 1.845815896987915 | seheeeeeeeeeeee \n",
            "r\\ Iteration: 1007 Loss: 1.8697876930236816 | seeeheeeeeeeee \n",
            "r\\ Iteration: 1008 Loss: 1.9584555625915527 | seheeeeeeeeee \n",
            "r\\ Iteration: 1009 Loss: 2.103289842605591 | seeeheeeeeeee \n",
            "r\\ Iteration: 1010 Loss: 1.9297921657562256 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 1011 Loss: 1.806499719619751 | seeeeeeeeeeee \n",
            "r\\ Iteration: 1012 Loss: 1.8931386470794678 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 1013 Loss: 1.8746883869171143 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1014 Loss: 2.0025475025177 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 1015 Loss: 1.8572773933410645 | seeeeeeee \n",
            "r\\ Iteration: 1016 Loss: 1.9139909744262695 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1017 Loss: 2.1601524353027344 | seheeeeeeeeeee \n",
            "r\\ Iteration: 1018 Loss: 2.020934820175171 | seheeeeeeeeeeee \n",
            "r\\ Iteration: 1019 Loss: 1.904479742050171 | seeeeeeeeeee \n",
            "r\\ Iteration: 1020 Loss: 2.021240234375 | seheeeeeeeeee \n",
            "r\\ Iteration: 1021 Loss: 1.7224702835083008 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 1022 Loss: 2.036052942276001 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 1023 Loss: 1.9038305282592773 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1024 Loss: 1.9270176887512207 | seeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1025 Loss: 1.8404541015625 | seheeeeeeeeeee \n",
            "r\\ Iteration: 1026 Loss: 1.9953575134277344 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1027 Loss: 1.9270098209381104 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1028 Loss: 1.9165408611297607 | seheeeeeeeeee \n",
            "r\\ Iteration: 1029 Loss: 1.9066112041473389 | seheeeeeeeeeee \n",
            "r\\ Iteration: 1030 Loss: 1.8017284870147705 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 1031 Loss: 1.8026509284973145 | seheeeeeeeeeee \n",
            "r\\ Iteration: 1032 Loss: 1.9687259197235107 | seeeeeeeeeee \n",
            "r\\ Iteration: 1033 Loss: 1.8776895999908447 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 1034 Loss: 1.796616792678833 | seheeeeeeeeeee \n",
            "r\\ Iteration: 1035 Loss: 2.0247559547424316 | seheeeeeeeeeeeee \n",
            "r\\ Iteration: 1036 Loss: 2.1038224697113037 | seeeeeeeeeee \n",
            "r\\ Iteration: 1037 Loss: 1.8003084659576416 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1038 Loss: 1.9585065841674805 | seeeeeeeeee \n",
            "r\\ Iteration: 1039 Loss: 2.1140408515930176 | seeeeeeeeeeee \n",
            "r\\ Iteration: 1040 Loss: 1.8348758220672607 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1041 Loss: 1.9240550994873047 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 1042 Loss: 1.9528536796569824 | seeeeeeeeee \n",
            "r\\ Iteration: 1043 Loss: 2.02541184425354 | seeeeeeeeeeee \n",
            "r\\ Iteration: 1044 Loss: 2.0136003494262695 | seeeeeeeeee \n",
            "r\\ Iteration: 1045 Loss: 1.9797213077545166 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 1046 Loss: 1.851548671722412 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 1047 Loss: 1.8816161155700684 | seeeeeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1048 Loss: 1.9896855354309082 | seheeeeeeeeeeeeee \n",
            "r\\ Iteration: 1049 Loss: 1.8386256694793701 | seeeeeeeeeeeeae \n",
            "r\\ Iteration: 1050 Loss: 1.8867907524108887 | seeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1051 Loss: 2.0999860763549805 | seeeeeeeeeeeeae \n",
            "r\\ Iteration: 1052 Loss: 1.843867540359497 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 1053 Loss: 1.9028081893920898 | seeeeeeeeeeeaae \n",
            "r\\ Iteration: 1054 Loss: 1.9243786334991455 | seeeeeeeeeeeeeeaae \n",
            "r\\ Iteration: 1055 Loss: 1.7896530628204346 | seeeeeeeee \n",
            "r\\ Iteration: 1056 Loss: 2.0057284832000732 | seeeeeeeeeee \n",
            "r\\ Iteration: 1057 Loss: 1.9312143325805664 | seeeeeeeeeeeaae \n",
            "r\\ Iteration: 1058 Loss: 1.8416626453399658 | seeeeeeeeeeeaae \n",
            "r\\ Iteration: 1059 Loss: 2.166630506515503 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1060 Loss: 1.9882678985595703 | seeeeeeeeeee \n",
            "r\\ Iteration: 1061 Loss: 1.9771933555603027 | seeeeeeeeeeeeaae \n",
            "r\\ Iteration: 1062 Loss: 1.772235631942749 | seeeeeeeeeeeeeeee \n",
            "r\\ Iteration: 1063 Loss: 1.9165208339691162 | seeeeeeeeeee \n",
            "r\\ Iteration: 1064 Loss: 2.1231119632720947 | seeeeeeeeee \n",
            "r\\ Iteration: 1065 Loss: 1.9530653953552246 | seeeeeeeeeeeee \n",
            "r\\ Iteration: 1066 Loss: 2.2169063091278076 | seeeeeeeeeeeaae \n",
            "r\\ Iteration: 1067 Loss: 1.8156592845916748 | seeeeeeeeeeeaae \n",
            "r\\ Iteration: 1068 Loss: 2.010256052017212 | seaeeeeeeeeee \n",
            "r\\ Iteration: 1069 Loss: 1.8712217807769775 | seeeeeeeeeeeeeaae \n",
            "r\\ Iteration: 1070 Loss: 1.8532328605651855 | seeeeeeeeeeaae \n",
            "r\\ Iteration: 1071 Loss: 1.9689385890960693 | seeeeeeeeeeeaae \n",
            "r\\ Iteration: 1072 Loss: 1.867945909500122 | seeeeeeeeeeaae \n",
            "r\\ Iteration: 1073 Loss: 1.8687891960144043 | seeeeeeeeeee \n",
            "r\\ Iteration: 1074 Loss: 1.9608685970306396 | seeeeeeeeeeee \n",
            "r\\ Iteration: 1075 Loss: 2.095932722091675 | seeeeeeeeeee \n",
            "r\\ Iteration: 1076 Loss: 1.9500489234924316 | seaeeeeeaeeeaae \n",
            "r\\ Iteration: 1077 Loss: 1.8541984558105469 | seeeeeeeeeeeeaae \n",
            "r\\ Iteration: 1078 Loss: 1.8768904209136963 | seeeeeaeeeaae \n",
            "r\\ Iteration: 1079 Loss: 1.8577382564544678 | seeeeeeee \n",
            "r\\ Iteration: 1080 Loss: 1.9161829948425293 | seeeeeeeee \n",
            "r\\ Iteration: 1081 Loss: 2.2514820098876953 | seeeeereeeeeere \n",
            "r\\ Iteration: 1082 Loss: 1.982015609741211 | seeeeereeereerererre \n",
            "r\\ Iteration: 1083 Loss: 1.879777431488037 | seeeerereee \n",
            "r\\ Iteration: 1084 Loss: 2.0044620037078857 | sereeereeee \n",
            "r\\ Iteration: 1085 Loss: 2.0177910327911377 | serereerrrrerre \n",
            "r\\ Iteration: 1086 Loss: 1.85345458984375 | serereeree \n",
            "r\\ Iteration: 1087 Loss: 2.1084649562835693 | srereerrererre \n",
            "r\\ Iteration: 1088 Loss: 1.8430709838867188 | seeerere \n",
            "r\\ Iteration: 1089 Loss: 2.2051162719726562 | sreereereererre \n",
            "r\\ Iteration: 1090 Loss: 1.9759585857391357 | serereeeererrrrerre \n",
            "r\\ Iteration: 1091 Loss: 1.9777612686157227 | serrererrrrerre \n",
            "r\\ Iteration: 1092 Loss: 1.9008162021636963 | seerrereerrrrerre \n",
            "r\\ Iteration: 1093 Loss: 1.9422545433044434 | sererrerrrrerre \n",
            "r\\ Iteration: 1094 Loss: 1.9672331809997559 | sreeerrrrerre \n",
            "r\\ Iteration: 1095 Loss: 1.9210748672485352 | srererrrerre \n",
            "r\\ Iteration: 1096 Loss: 2.008148193359375 | seereerererrrrerre \n",
            "r\\ Iteration: 1097 Loss: 2.005432367324829 | sererrre \n",
            "r\\ Iteration: 1098 Loss: 1.7604575157165527 | seerrerereree \n",
            "r\\ Iteration: 1099 Loss: 1.9211399555206299 | sreererereererrr \n",
            "r\\ Iteration: 1100 Loss: 2.109834909439087 | sereereerrr \n",
            "r\\ Iteration: 1101 Loss: 2.0841028690338135 | sreereere \n",
            "r\\ Iteration: 1102 Loss: 2.2632217407226562 | senrererrrrrerrr \n",
            "r\\ Iteration: 1103 Loss: 1.8956408500671387 | srrreerereererrr \n",
            "r\\ Iteration: 1104 Loss: 2.0006349086761475 | seereereereerererer \n",
            "r\\ Iteration: 1105 Loss: 2.014188051223755 | sreerereerrrrrerrr \n",
            "r\\ Iteration: 1106 Loss: 1.8539342880249023 | serrrrrerrr \n",
            "r\\ Iteration: 1107 Loss: 1.9054725170135498 | srnereereerrrrerrr \n",
            "r\\ Iteration: 1108 Loss: 1.9093718528747559 | sereerrerreerrrr \n",
            "r\\ Iteration: 1109 Loss: 1.7970640659332275 | srrreerrererererr \n",
            "r\\ Iteration: 1110 Loss: 1.958878517150879 | srrrrererererr \n",
            "r\\ Iteration: 1111 Loss: 1.946164608001709 | srerrerererr \n",
            "r\\ Iteration: 1112 Loss: 2.086652994155884 | srrerrrrrrerrr \n",
            "r\\ Iteration: 1113 Loss: 1.9073851108551025 | seerrerrererr \n",
            "r\\ Iteration: 1114 Loss: 2.138061285018921 | sereerrrerrerrr \n",
            "r\\ Iteration: 1115 Loss: 2.1677825450897217 | serrrerrrrrr \n",
            "r\\ Iteration: 1116 Loss: 1.9961464405059814 | sererrerrrrrrrr \n",
            "r\\ Iteration: 1117 Loss: 1.9293532371520996 | srreerrrreerrr \n",
            "r\\ Iteration: 1118 Loss: 2.063120126724243 | sererrerrrrrrrr \n",
            "r\\ Iteration: 1119 Loss: 1.7251899242401123 | serrrrreerrr \n",
            "r\\ Iteration: 1120 Loss: 1.902756690979004 | srerrerrrrrrr \n",
            "r\\ Iteration: 1121 Loss: 1.9324398040771484 | srrrrrrrrrrrrrrr \n",
            "r\\ Iteration: 1122 Loss: 2.0899999141693115 | srerrrrerrr \n",
            "r\\ Iteration: 1123 Loss: 1.9067094326019287 | sereererrrrr \n",
            "r\\ Iteration: 1124 Loss: 1.995274305343628 | serrerrrrerrr \n",
            "r\\ Iteration: 1125 Loss: 1.8477084636688232 | serereererrr \n",
            "r\\ Iteration: 1126 Loss: 2.018096923828125 | srrereerrr \n",
            "r\\ Iteration: 1127 Loss: 2.007702589035034 | sererrrrrrerrr \n",
            "r\\ Iteration: 1128 Loss: 1.8047826290130615 | serererrrrerrr \n",
            "r\\ Iteration: 1129 Loss: 1.8369314670562744 | srerrrrrerrr \n",
            "r\\ Iteration: 1130 Loss: 1.8819818496704102 | srrrererrr \n",
            "r\\ Iteration: 1131 Loss: 1.967498540878296 | seereererer \n",
            "r\\ Iteration: 1132 Loss: 2.1178979873657227 | srrererrreerrr \n",
            "r\\ Iteration: 1133 Loss: 1.9892816543579102 | srerereerrrr \n",
            "r\\ Iteration: 1134 Loss: 1.983701467514038 | sereerrrrerre \n",
            "r\\ Iteration: 1135 Loss: 1.9815661907196045 | serererrrrerre \n",
            "r\\ Iteration: 1136 Loss: 1.903048038482666 | sreerrereere \n",
            "r\\ Iteration: 1137 Loss: 2.0520644187927246 | seerrerrrrerre \n",
            "r\\ Iteration: 1138 Loss: 1.8357024192810059 | serererererere \n",
            "r\\ Iteration: 1139 Loss: 2.015984535217285 | serrerrereerre \n",
            "r\\ Iteration: 1140 Loss: 1.8115134239196777 | sererrrrerre \n",
            "r\\ Iteration: 1141 Loss: 1.9506418704986572 | srereereererrre \n",
            "r\\ Iteration: 1142 Loss: 2.0858781337738037 | sereeeerrrerre \n",
            "r\\ Iteration: 1143 Loss: 2.125666618347168 | seerrererrrrerre \n",
            "r\\ Iteration: 1144 Loss: 1.8503751754760742 | serererererere \n",
            "r\\ Iteration: 1145 Loss: 2.0025148391723633 | serererrrrerre \n",
            "r\\ Iteration: 1146 Loss: 1.9228994846343994 | seerrrreerrrerre \n",
            "r\\ Iteration: 1147 Loss: 2.02498197555542 | serererrrrerre \n",
            "r\\ Iteration: 1148 Loss: 1.8170456886291504 | serererrrrerre \n",
            "r\\ Iteration: 1149 Loss: 1.7273821830749512 | sereerereree \n",
            "r\\ Iteration: 1150 Loss: 1.9361379146575928 | serererrrrrrerre \n",
            "r\\ Iteration: 1151 Loss: 1.8135850429534912 | seererrerre \n",
            "r\\ Iteration: 1152 Loss: 1.8858394622802734 | serererre \n",
            "r\\ Iteration: 1153 Loss: 2.0076828002929688 | sereereerere \n",
            "r\\ Iteration: 1154 Loss: 2.1678171157836914 | sereererrrrerre \n",
            "r\\ Iteration: 1155 Loss: 1.8881986141204834 | srrereerre \n",
            "r\\ Iteration: 1156 Loss: 2.0293474197387695 | serereerrrrerre \n",
            "r\\ Iteration: 1157 Loss: 1.954962968826294 | serreerrrrrrerre \n",
            "r\\ Iteration: 1158 Loss: 1.885467767715454 | sererrerrrrerre \n",
            "r\\ Iteration: 1159 Loss: 1.849449872970581 | sererere \n",
            "r\\ Iteration: 1160 Loss: 1.9926700592041016 | sereererrrrerre \n",
            "r\\ Iteration: 1161 Loss: 1.8875706195831299 | srererrrrerre \n",
            "r\\ Iteration: 1162 Loss: 1.8209168910980225 | seerererrrerere \n",
            "r\\ Iteration: 1163 Loss: 1.9758923053741455 | sereerererrr \n",
            "r\\ Iteration: 1164 Loss: 2.1584830284118652 | sereeerrrrerre \n",
            "r\\ Iteration: 1165 Loss: 1.941145896911621 | seerrrrrrerrr \n",
            "r\\ Iteration: 1166 Loss: 1.9136724472045898 | srereererrrrerrr \n",
            "r\\ Iteration: 1167 Loss: 1.8325541019439697 | sreerrrrerrr \n",
            "r\\ Iteration: 1168 Loss: 1.8465080261230469 | srerrrrrrerrr \n",
            "r\\ Iteration: 1169 Loss: 2.0432567596435547 | sreeererrrrerrr \n",
            "r\\ Iteration: 1170 Loss: 1.9579813480377197 | srrrrerrrerrr \n",
            "r\\ Iteration: 1171 Loss: 1.8433036804199219 | serrrrreerrrerrr \n",
            "r\\ Iteration: 1172 Loss: 2.016284465789795 | sreerrrerrrerrr \n",
            "r\\ Iteration: 1173 Loss: 1.9294102191925049 | serererrrr \n",
            "r\\ Iteration: 1174 Loss: 2.0490708351135254 | srrrrrrrerrr \n",
            "r\\ Iteration: 1175 Loss: 1.7674353122711182 | serrrrrrerrr \n",
            "r\\ Iteration: 1176 Loss: 1.7474119663238525 | srrerrerrrrerrr \n",
            "r\\ Iteration: 1177 Loss: 1.8559415340423584 | srerrrrrerrrrr \n",
            "r\\ Iteration: 1178 Loss: 2.0638818740844727 | serrrrrrrrerrr \n",
            "r\\ Iteration: 1179 Loss: 1.8104500770568848 | srerrerrrrrrrrrr \n",
            "r\\ Iteration: 1180 Loss: 1.8936262130737305 | sererrerrr \n",
            "r\\ Iteration: 1181 Loss: 2.1056137084960938 | srrerrerrrrrer \n",
            "r\\ Iteration: 1182 Loss: 1.9694786071777344 | sererrrrrrr \n",
            "r\\ Iteration: 1183 Loss: 1.9315361976623535 | serrrrrrrrrrr \n",
            "r\\ Iteration: 1184 Loss: 1.7366721630096436 | seereererer \n",
            "r\\ Iteration: 1185 Loss: 2.0792078971862793 | srrrrrrrrrrr \n",
            "r\\ Iteration: 1186 Loss: 1.835089921951294 | srereerrrrrrrrr \n",
            "r\\ Iteration: 1187 Loss: 1.856447458267212 | srrererrrrer \n",
            "r\\ Iteration: 1188 Loss: 1.8541791439056396 | serererererer \n",
            "r\\ Iteration: 1189 Loss: 1.8121325969696045 | sererrrrrerrr \n",
            "r\\ Iteration: 1190 Loss: 1.748779535293579 | srrrerreerrrrerrr \n",
            "r\\ Iteration: 1191 Loss: 1.943622350692749 | sererrrrerrr \n",
            "r\\ Iteration: 1192 Loss: 1.7575089931488037 | srneerrrrerrr \n",
            "r\\ Iteration: 1193 Loss: 1.8398256301879883 | seheererererer \n",
            "r\\ Iteration: 1194 Loss: 1.9614319801330566 | sereeererereerrrrerrr \n",
            "r\\ Iteration: 1195 Loss: 1.8530783653259277 | sererrreerrr \n",
            "r\\ Iteration: 1196 Loss: 1.9187180995941162 | sererererrrrr \n",
            "r\\ Iteration: 1197 Loss: 1.941922903060913 | serererrrrerrr \n",
            "r\\ Iteration: 1198 Loss: 1.8240816593170166 | srereereererre \n",
            "r\\ Iteration: 1199 Loss: 1.984971284866333 | sererererr \n",
            "r\\ Iteration: 1200 Loss: 1.8974177837371826 | serererrrrrrrr \n",
            "r\\ Iteration: 1201 Loss: 1.8319745063781738 | sererrrrrrre \n",
            "r\\ Iteration: 1202 Loss: 2.000502109527588 | srrererrrrerre \n",
            "r\\ Iteration: 1203 Loss: 1.89668869972229 | sereeerrrrrrrr \n",
            "r\\ Iteration: 1204 Loss: 1.852691650390625 | serrrer \n",
            "r\\ Iteration: 1205 Loss: 2.1607513427734375 | serrerrrrrrrrrr \n",
            "r\\ Iteration: 1206 Loss: 1.9876952171325684 | serrrrerrrrrr \n",
            "r\\ Iteration: 1207 Loss: 1.9561307430267334 | serrrrrrrrrrr \n",
            "r\\ Iteration: 1208 Loss: 1.870595932006836 | serrrrrrrrrrr \n",
            "r\\ Iteration: 1209 Loss: 1.929630994796753 | serrrrrrrrrrrr \n",
            "r\\ Iteration: 1210 Loss: 1.747363805770874 | srrrrerrrrrrrr \n",
            "r\\ Iteration: 1211 Loss: 2.002983570098877 | srrrrerrrr \n",
            "r\\ Iteration: 1212 Loss: 1.9328486919403076 | srrrrrrrrrrrr \n",
            "r\\ Iteration: 1213 Loss: 1.8381102085113525 | serrrrrrerrrr \n",
            "r\\ Iteration: 1214 Loss: 1.8654377460479736 | srrrrrrer \n",
            "r\\ Iteration: 1215 Loss: 1.9372987747192383 | sererrrrrrrrrr \n",
            "r\\ Iteration: 1216 Loss: 1.7622809410095215 | serrererer \n",
            "r\\ Iteration: 1217 Loss: 2.0358619689941406 | srnerrrerer \n",
            "r\\ Iteration: 1218 Loss: 2.0537796020507812 | srerrerrrrr \n",
            "r\\ Iteration: 1219 Loss: 1.8462002277374268 | serererrre \n",
            "r\\ Iteration: 1220 Loss: 1.9843931198120117 | serer \n",
            "r\\ Iteration: 1221 Loss: 2.2813916206359863 | srrerrrrrrrrr \n",
            "r\\ Iteration: 1222 Loss: 1.834228754043579 | srrerrerrr \n",
            "r\\ Iteration: 1223 Loss: 1.846750020980835 | sreererrrrrrrrr \n",
            "r\\ Iteration: 1224 Loss: 1.9176125526428223 | sreererrererrr \n",
            "r\\ Iteration: 1225 Loss: 2.0847878456115723 | sereereererrrrrrrr \n",
            "r\\ Iteration: 1226 Loss: 1.8922841548919678 | srrererrrrrrrr \n",
            "r\\ Iteration: 1227 Loss: 1.927011251449585 | srrrerererererr \n",
            "r\\ Iteration: 1228 Loss: 1.9378163814544678 | srrrerereerrr \n",
            "r\\ Iteration: 1229 Loss: 2.0275604724884033 | srrererrrrr \n",
            "r\\ Iteration: 1230 Loss: 1.978762149810791 | serrrrrererrrrrerr \n",
            "r\\ Iteration: 1231 Loss: 1.9705784320831299 | serrrrrerrrrrrrr \n",
            "r\\ Iteration: 1232 Loss: 1.8461835384368896 | serrrrrrrrrrr \n",
            "r\\ Iteration: 1233 Loss: 1.762289047241211 | srerrrrerrrr \n",
            "r\\ Iteration: 1234 Loss: 2.070016384124756 | srrrerrrerrrrrrrr \n",
            "r\\ Iteration: 1235 Loss: 1.888864517211914 | srrrrrrrerer \n",
            "r\\ Iteration: 1236 Loss: 1.8753304481506348 | srrrrrrerrrrrrr \n",
            "r\\ Iteration: 1237 Loss: 1.932037591934204 | srrrrrerrrrrrrr \n",
            "r\\ Iteration: 1238 Loss: 1.7458674907684326 | srrrrrrree \n",
            "r\\ Iteration: 1239 Loss: 1.9936776161193848 | sereererrree \n",
            "r\\ Iteration: 1240 Loss: 2.1825263500213623 | srreerrrrrrrr \n",
            "r\\ Iteration: 1241 Loss: 1.8454904556274414 | srrerereerrrrrrrrr \n",
            "r\\ Iteration: 1242 Loss: 1.9260504245758057 | srerererrrrrrrrr \n",
            "r\\ Iteration: 1243 Loss: 2.0482468605041504 | srhrrerrrrr \n",
            "r\\ Iteration: 1244 Loss: 1.8008949756622314 | sererrrrrrrr \n",
            "r\\ Iteration: 1245 Loss: 1.7561688423156738 | srereerrrrrrrr \n",
            "r\\ Iteration: 1246 Loss: 1.9324617385864258 | serrrereerrrrrrrr \n",
            "r\\ Iteration: 1247 Loss: 1.798435926437378 | srrererrrrrrrrrr \n",
            "r\\ Iteration: 1248 Loss: 2.0020864009857178 | sererrrrrrrrr \n",
            "r\\ Iteration: 1249 Loss: 1.9239404201507568 | seerrrrerrrreerrrrr \n",
            "r\\ Iteration: 1250 Loss: 1.9420933723449707 | sreererrrrrrrr \n",
            "r\\ Iteration: 1251 Loss: 1.888563632965088 | srerrrrrrrrrrr \n",
            "r\\ Iteration: 1252 Loss: 1.8042242527008057 | sererrrreerrr \n",
            "r\\ Iteration: 1253 Loss: 2.07741379737854 | srererer \n",
            "r\\ Iteration: 1254 Loss: 2.0712802410125732 | srerrrrrerrr \n",
            "r\\ Iteration: 1255 Loss: 2.0834145545959473 | sererrrerr \n",
            "r\\ Iteration: 1256 Loss: 2.0315160751342773 | srrrrrrrrererrerrr \n",
            "r\\ Iteration: 1257 Loss: 2.0862984657287598 | srrrrererrrrrrr \n",
            "r\\ Iteration: 1258 Loss: 1.9153213500976562 | srrrrrreererrr \n",
            "r\\ Iteration: 1259 Loss: 2.1052656173706055 | srrrerrrrrerr \n",
            "r\\ Iteration: 1260 Loss: 2.001671552658081 | srrerrrrr \n",
            "r\\ Iteration: 1261 Loss: 2.3183906078338623 | srerrrrerrrr \n",
            "r\\ Iteration: 1262 Loss: 1.92378830909729 | serrrrrrrrrrrrr \n",
            "r\\ Iteration: 1263 Loss: 1.823340654373169 | serrrerrrr \n",
            "r\\ Iteration: 1264 Loss: 1.9544754028320312 | srrrrrrrrrr \n",
            "r\\ Iteration: 1265 Loss: 1.800612449645996 | serrrrerrrrrr \n",
            "r\\ Iteration: 1266 Loss: 2.02268123626709 | sereerrrrerrr \n",
            "r\\ Iteration: 1267 Loss: 1.8022282123565674 | srerrrrrerrr \n",
            "r\\ Iteration: 1268 Loss: 1.7920746803283691 | srrrrrrrrreerrr \n",
            "r\\ Iteration: 1269 Loss: 1.9495909214019775 | srrrrrrerererr \n",
            "r\\ Iteration: 1270 Loss: 1.9757428169250488 | seereeererrrerrr \n",
            "r\\ Iteration: 1271 Loss: 1.8996236324310303 | sereerereererrrrerre \n",
            "r\\ Iteration: 1272 Loss: 1.9975507259368896 | sreererrrrerre \n",
            "r\\ Iteration: 1273 Loss: 1.9583725929260254 | srreerrrrerre \n",
            "r\\ Iteration: 1274 Loss: 1.9570415019989014 | srreerreerereere \n",
            "r\\ Iteration: 1275 Loss: 2.0962469577789307 | sreerererre \n",
            "r\\ Iteration: 1276 Loss: 2.1149210929870605 | sreerererere \n",
            "r\\ Iteration: 1277 Loss: 1.8396823406219482 | srerererereer \n",
            "r\\ Iteration: 1278 Loss: 2.241133451461792 | srrreerererereree \n",
            "r\\ Iteration: 1279 Loss: 1.9175100326538086 | srrerrrrereererre \n",
            "r\\ Iteration: 1280 Loss: 1.9061954021453857 | srreeerrrrrerre \n",
            "r\\ Iteration: 1281 Loss: 1.914884090423584 | srrrerrrrerre \n",
            "r\\ Iteration: 1282 Loss: 1.808565378189087 | srereeereererre \n",
            "r\\ Iteration: 1283 Loss: 1.9820327758789062 | srreererre \n",
            "r\\ Iteration: 1284 Loss: 1.9946293830871582 | srrereeree \n",
            "r\\ Iteration: 1285 Loss: 1.9943854808807373 | srerreererre \n",
            "r\\ Iteration: 1286 Loss: 2.0967025756835938 | srrereerrerereree \n",
            "r\\ Iteration: 1287 Loss: 1.7960445880889893 | srereereererre \n",
            "r\\ Iteration: 1288 Loss: 1.9938828945159912 | srrerererere \n",
            "r\\ Iteration: 1289 Loss: 2.273578643798828 | srrerreereeree \n",
            "r\\ Iteration: 1290 Loss: 1.880164623260498 | srerrrrerrr \n",
            "r\\ Iteration: 1291 Loss: 1.7797811031341553 | srrereererererererr \n",
            "r\\ Iteration: 1292 Loss: 1.8608200550079346 | srreereereerrrrerrr \n",
            "r\\ Iteration: 1293 Loss: 1.900486946105957 | srereererrrrre \n",
            "r\\ Iteration: 1294 Loss: 2.1470656394958496 | srrreererrrerrr \n",
            "r\\ Iteration: 1295 Loss: 1.9751560688018799 | serererrrrerrr \n",
            "r\\ Iteration: 1296 Loss: 1.7642157077789307 | srrrerrrr \n",
            "r\\ Iteration: 1297 Loss: 2.011911630630493 | srerrerrrrerrr \n",
            "r\\ Iteration: 1298 Loss: 1.913555383682251 | serrrrrrrrerrr \n",
            "r\\ Iteration: 1299 Loss: 1.7631826400756836 | sereererrrrrerr \n",
            "r\\ Iteration: 1300 Loss: 1.825652837753296 | serrrerrrrerrr \n",
            "r\\ Iteration: 1301 Loss: 1.6837396621704102 | srrrerrrerrrrerr \n",
            "r\\ Iteration: 1302 Loss: 1.852776288986206 | sreerererrrrrr \n",
            "r\\ Iteration: 1303 Loss: 1.837519645690918 | sereerrrerrrrr \n",
            "r\\ Iteration: 1304 Loss: 2.129103660583496 | sererrrrrrrerrr \n",
            "r\\ Iteration: 1305 Loss: 1.8335928916931152 | srrrrrerrrerrr \n",
            "r\\ Iteration: 1306 Loss: 1.931183099746704 | sereerrrrrrerrr \n",
            "r\\ Iteration: 1307 Loss: 1.9870638847351074 | serrrrrrrrrerrr \n",
            "r\\ Iteration: 1308 Loss: 1.8625385761260986 | srrrerereerre \n",
            "r\\ Iteration: 1309 Loss: 1.9449069499969482 | sreerrere \n",
            "r\\ Iteration: 1310 Loss: 2.18896746635437 | sereerererre \n",
            "r\\ Iteration: 1311 Loss: 2.1338624954223633 | seerrereerrrrerre \n",
            "r\\ Iteration: 1312 Loss: 1.808906078338623 | sererrerrereerre \n",
            "r\\ Iteration: 1313 Loss: 2.0779478549957275 | sereerereree \n",
            "r\\ Iteration: 1314 Loss: 1.9176809787750244 | srereereree \n",
            "r\\ Iteration: 1315 Loss: 1.9950242042541504 | sereererrrrerre \n",
            "r\\ Iteration: 1316 Loss: 1.7484526634216309 | sreerererre \n",
            "r\\ Iteration: 1317 Loss: 2.064469814300537 | srerrereree \n",
            "r\\ Iteration: 1318 Loss: 2.003864049911499 | sererrerere \n",
            "r\\ Iteration: 1319 Loss: 2.0606606006622314 | srerererre \n",
            "r\\ Iteration: 1320 Loss: 1.979168176651001 | serrrereereee \n",
            "r\\ Iteration: 1321 Loss: 2.0925302505493164 | sreeerereereerererre \n",
            "r\\ Iteration: 1322 Loss: 1.9267022609710693 | srererrrrerre \n",
            "r\\ Iteration: 1323 Loss: 1.7580697536468506 | srerereererrrerre \n",
            "r\\ Iteration: 1324 Loss: 1.8947737216949463 | srrrerereerre \n",
            "r\\ Iteration: 1325 Loss: 1.7943294048309326 | eerererrrrerrerre \n",
            "r\\ Iteration: 1326 Loss: 1.843026876449585 | eereerererre \n",
            "r\\ Iteration: 1327 Loss: 2.119225263595581 | eeererereererre \n",
            "r\\ Iteration: 1328 Loss: 1.9598393440246582 | eeereerrererre \n",
            "r\\ Iteration: 1329 Loss: 1.7821121215820312 | eererrererre \n",
            "r\\ Iteration: 1330 Loss: 1.705476999282837 | ereeereeeere \n",
            "r\\ Iteration: 1331 Loss: 2.040363073348999 | ereerereree \n",
            "r\\ Iteration: 1332 Loss: 1.7495417594909668 | eeerereererererre \n",
            "r\\ Iteration: 1333 Loss: 1.853348731994629 | ererrererre \n",
            "r\\ Iteration: 1334 Loss: 1.7608439922332764 | eererrerrererre \n",
            "r\\ Iteration: 1335 Loss: 1.8207719326019287 | eererreerre \n",
            "r\\ Iteration: 1336 Loss: 1.8409943580627441 | eererrererre \n",
            "r\\ Iteration: 1337 Loss: 1.769676923751831 | eererererre \n",
            "r\\ Iteration: 1338 Loss: 1.9069240093231201 | eererererre \n",
            "r\\ Iteration: 1339 Loss: 1.9053244590759277 | eerrrererre \n",
            "r\\ Iteration: 1340 Loss: 1.8527610301971436 | eererreereerrre \n",
            "r\\ Iteration: 1341 Loss: 1.842712640762329 | eereererrrerre \n",
            "r\\ Iteration: 1342 Loss: 1.8620989322662354 | eeerererereree \n",
            "r\\ Iteration: 1343 Loss: 1.9205448627471924 | errrrrrrerre \n",
            "r\\ Iteration: 1344 Loss: 1.8856022357940674 | ereererereeree \n",
            "r\\ Iteration: 1345 Loss: 1.8690741062164307 | eerrrerererere \n",
            "r\\ Iteration: 1346 Loss: 1.877962589263916 | eeeeerrrrrrerre \n",
            "r\\ Iteration: 1347 Loss: 1.9221651554107666 | eereerrrrerre \n",
            "r\\ Iteration: 1348 Loss: 1.827653169631958 | ereerrrrerre \n",
            "r\\ Iteration: 1349 Loss: 1.7956717014312744 | eererreerre \n",
            "r\\ Iteration: 1350 Loss: 2.1418144702911377 | sreerereree \n",
            "r\\ Iteration: 1351 Loss: 2.071059465408325 | serrererrerre \n",
            "r\\ Iteration: 1352 Loss: 1.9821512699127197 | serererrrrerre \n",
            "r\\ Iteration: 1353 Loss: 1.8284704685211182 | sereereereerrrrerre \n",
            "r\\ Iteration: 1354 Loss: 1.881728172302246 | srrerereereree \n",
            "r\\ Iteration: 1355 Loss: 1.8827764987945557 | seerrrrrerre \n",
            "r\\ Iteration: 1356 Loss: 1.8015129566192627 | srerrererre \n",
            "r\\ Iteration: 1357 Loss: 2.05204701423645 | seerererererere \n",
            "r\\ Iteration: 1358 Loss: 1.9422180652618408 | sererrerre \n",
            "r\\ Iteration: 1359 Loss: 1.9594557285308838 | sererrrrerre \n",
            "r\\ Iteration: 1360 Loss: 1.8312408924102783 | serreeererrererre \n",
            "r\\ Iteration: 1361 Loss: 1.7771337032318115 | srererrrrrerre \n",
            "r\\ Iteration: 1362 Loss: 1.9183850288391113 | serrrererererere \n",
            "r\\ Iteration: 1363 Loss: 1.945946216583252 | sereeerereeree \n",
            "r\\ Iteration: 1364 Loss: 1.8447859287261963 | sereereerrrrerre \n",
            "r\\ Iteration: 1365 Loss: 1.7348244190216064 | serererererere \n",
            "r\\ Iteration: 1366 Loss: 1.8852427005767822 | seererrerre \n",
            "r\\ Iteration: 1367 Loss: 1.854041576385498 | sreerereerrrrrerre \n",
            "r\\ Iteration: 1368 Loss: 1.898977279663086 | srrererrrrerre \n",
            "r\\ Iteration: 1369 Loss: 1.8128294944763184 | seereeereeereee \n",
            "r\\ Iteration: 1370 Loss: 2.1972241401672363 | seerrrrerre \n",
            "r\\ Iteration: 1371 Loss: 1.7558887004852295 | sererrrrerre \n",
            "r\\ Iteration: 1372 Loss: 1.7717769145965576 | seereereeerererere \n",
            "r\\ Iteration: 1373 Loss: 1.9435055255889893 | seeerreeerrererre \n",
            "r\\ Iteration: 1374 Loss: 1.8014869689941406 | seeeererrrererre \n",
            "r\\ Iteration: 1375 Loss: 1.8113679885864258 | seeerrerere \n",
            "r\\ Iteration: 1376 Loss: 1.920470952987671 | srrrereereererrerre \n",
            "r\\ Iteration: 1377 Loss: 1.907118320465088 | seeeererrererre \n",
            "r\\ Iteration: 1378 Loss: 1.8853609561920166 | seerererrre \n",
            "r\\ Iteration: 1379 Loss: 2.0051846504211426 | seeeererre \n",
            "r\\ Iteration: 1380 Loss: 1.9290878772735596 | srereererrrere \n",
            "r\\ Iteration: 1381 Loss: 2.153355598449707 | serreereeeererre \n",
            "r\\ Iteration: 1382 Loss: 2.00010347366333 | seeereeereree \n",
            "r\\ Iteration: 1383 Loss: 1.9352381229400635 | srreeerererre \n",
            "r\\ Iteration: 1384 Loss: 1.7872073650360107 | seeeeererrerrre \n",
            "r\\ Iteration: 1385 Loss: 2.055615186691284 | seeeeeeererre \n",
            "r\\ Iteration: 1386 Loss: 1.812854528427124 | srreereeeree \n",
            "r\\ Iteration: 1387 Loss: 1.9485726356506348 | seheeeerrererre \n",
            "r\\ Iteration: 1388 Loss: 1.8272480964660645 | sreeeerrrerre \n",
            "r\\ Iteration: 1389 Loss: 1.8209238052368164 | srerereeeeeeere \n",
            "r\\ Iteration: 1390 Loss: 1.9059045314788818 | serreeerrererre \n",
            "r\\ Iteration: 1391 Loss: 1.8690893650054932 | seeeeere \n",
            "r\\ Iteration: 1392 Loss: 1.9825797080993652 | seeerrrrerre \n",
            "r\\ Iteration: 1393 Loss: 1.8260159492492676 | seeeeeeeeerere \n",
            "r\\ Iteration: 1394 Loss: 1.9151711463928223 | seeereerrrre \n",
            "r\\ Iteration: 1395 Loss: 2.0169851779937744 | seeereeeere \n",
            "r\\ Iteration: 1396 Loss: 1.9749624729156494 | seerereeeeee \n",
            "r\\ Iteration: 1397 Loss: 1.849546194076538 | sereererrrrerre \n",
            "r\\ Iteration: 1398 Loss: 1.8834946155548096 | srereeerrrrerre \n",
            "r\\ Iteration: 1399 Loss: 1.897900104522705 | seerrrrerre \n",
            "r\\ Iteration: 1400 Loss: 1.7788548469543457 | seeererrrrerre \n",
            "r\\ Iteration: 1401 Loss: 1.7721185684204102 | seererrrrerre \n",
            "r\\ Iteration: 1402 Loss: 1.775249719619751 | sereeerrrrerre \n",
            "r\\ Iteration: 1403 Loss: 1.8095433712005615 | seeerrrerererere \n",
            "r\\ Iteration: 1404 Loss: 1.8224992752075195 | sheeeeeeeerereerre \n",
            "r\\ Iteration: 1405 Loss: 2.0626018047332764 | seeeeeerrrrerre \n",
            "r\\ Iteration: 1406 Loss: 1.8559727668762207 | sreeereree \n",
            "r\\ Iteration: 1407 Loss: 1.972827434539795 | seeerereree \n",
            "r\\ Iteration: 1408 Loss: 1.936424732208252 | serreerereereee \n",
            "r\\ Iteration: 1409 Loss: 2.172839641571045 | seeeereerrrre \n",
            "r\\ Iteration: 1410 Loss: 1.9057343006134033 | seeerrre \n",
            "r\\ Iteration: 1411 Loss: 1.774639368057251 | seeere \n",
            "r\\ Iteration: 1412 Loss: 2.1601223945617676 | seeeerrerreerre \n",
            "r\\ Iteration: 1413 Loss: 1.996645212173462 | seeererrrrerre \n",
            "r\\ Iteration: 1414 Loss: 1.7969257831573486 | seeeerrrrerre \n",
            "r\\ Iteration: 1415 Loss: 1.826730728149414 | seeerererrereereree \n",
            "r\\ Iteration: 1416 Loss: 2.065436840057373 | seeererererere \n",
            "r\\ Iteration: 1417 Loss: 1.8834636211395264 | seeerereerrrrerre \n",
            "r\\ Iteration: 1418 Loss: 1.815718412399292 | seeererreerrrrerre \n",
            "r\\ Iteration: 1419 Loss: 1.957930564880371 | seerererrrererre \n",
            "r\\ Iteration: 1420 Loss: 2.06205415725708 | seereerereree \n",
            "r\\ Iteration: 1421 Loss: 2.193533182144165 | seeerrrrrerre \n",
            "r\\ Iteration: 1422 Loss: 1.7529017925262451 | seeerrrrereerre \n",
            "r\\ Iteration: 1423 Loss: 1.901613473892212 | serreererrrerre \n",
            "r\\ Iteration: 1424 Loss: 1.830425500869751 | serreerrrrrerre \n",
            "r\\ Iteration: 1425 Loss: 1.9247639179229736 | seeeereeerreerrrrerre \n",
            "r\\ Iteration: 1426 Loss: 1.8741405010223389 | seeeerereererre \n",
            "r\\ Iteration: 1427 Loss: 1.882037878036499 | sereeereeerrrrerre \n",
            "r\\ Iteration: 1428 Loss: 1.9537420272827148 | seeereerrrrerre \n",
            "r\\ Iteration: 1429 Loss: 1.7404613494873047 | seeeeeeeeeree \n",
            "r\\ Iteration: 1430 Loss: 2.0283641815185547 | seeereeerrrerre \n",
            "r\\ Iteration: 1431 Loss: 1.8626682758331299 | seeeeeeeeerrererre \n",
            "r\\ Iteration: 1432 Loss: 1.813720703125 | seerereeeeeeree \n",
            "r\\ Iteration: 1433 Loss: 1.9067511558532715 | sereereeee \n",
            "r\\ Iteration: 1434 Loss: 1.9596624374389648 | sreeeereeeeeerre \n",
            "r\\ Iteration: 1435 Loss: 1.8406651020050049 | seeeeerererre \n",
            "r\\ Iteration: 1436 Loss: 1.7702662944793701 | sereereeerrererre \n",
            "r\\ Iteration: 1437 Loss: 1.9213011264801025 | seeeeeeeeeeree \n",
            "r\\ Iteration: 1438 Loss: 1.8944425582885742 | seeeerereerre \n",
            "r\\ Iteration: 1439 Loss: 1.8119287490844727 | seeeeereee \n",
            "r\\ Iteration: 1440 Loss: 2.0025079250335693 | seeeeerrererre \n",
            "r\\ Iteration: 1441 Loss: 1.6905145645141602 | seeerererre \n",
            "r\\ Iteration: 1442 Loss: 1.7724323272705078 | sreeeerrrerre \n",
            "r\\ Iteration: 1443 Loss: 1.8681421279907227 | seeereeeeree \n",
            "r\\ Iteration: 1444 Loss: 1.9017155170440674 | seeeeereree \n",
            "r\\ Iteration: 1445 Loss: 2.0066728591918945 | seeeeeererrererre \n",
            "r\\ Iteration: 1446 Loss: 1.7744557857513428 | seeeeerrererre \n",
            "r\\ Iteration: 1447 Loss: 1.691437005996704 | srreereeeree \n",
            "r\\ Iteration: 1448 Loss: 1.9466605186462402 | seeeeeeerererre \n",
            "r\\ Iteration: 1449 Loss: 1.8386256694793701 | seeeeeeeee \n",
            "r\\ Iteration: 1450 Loss: 2.198206663131714 | sereeerererre \n",
            "r\\ Iteration: 1451 Loss: 1.6697139739990234 | seeeereerrererre \n",
            "r\\ Iteration: 1452 Loss: 1.747534990310669 | seereeeeerrererre \n",
            "r\\ Iteration: 1453 Loss: 1.7532155513763428 | seeereeere \n",
            "r\\ Iteration: 1454 Loss: 1.9379730224609375 | seeeeeeerrreerre \n",
            "r\\ Iteration: 1455 Loss: 1.9734601974487305 | seeeerreerre \n",
            "r\\ Iteration: 1456 Loss: 1.9003467559814453 | seeeereeeere \n",
            "r\\ Iteration: 1457 Loss: 2.1766836643218994 | seeeeeeeeeee \n",
            "r\\ Iteration: 1458 Loss: 2.300161123275757 | seeeerrererre \n",
            "r\\ Iteration: 1459 Loss: 1.780268907546997 | seeeereeerrererre \n",
            "r\\ Iteration: 1460 Loss: 1.7849702835083008 | sreeerreereeeeeee \n",
            "r\\ Iteration: 1461 Loss: 2.025346040725708 | seereerererre \n",
            "r\\ Iteration: 1462 Loss: 1.8124816417694092 | seeeeerrererre \n",
            "r\\ Iteration: 1463 Loss: 1.9012372493743896 | seeeerrererre \n",
            "r\\ Iteration: 1464 Loss: 1.7544946670532227 | sereeeerrererre \n",
            "r\\ Iteration: 1465 Loss: 1.802668809890747 | seeeeeereeerre \n",
            "r\\ Iteration: 1466 Loss: 2.1009106636047363 | sreeereerererre \n",
            "r\\ Iteration: 1467 Loss: 1.7800250053405762 | seeereerererre \n",
            "r\\ Iteration: 1468 Loss: 1.8242096900939941 | seeereeerre \n",
            "r\\ Iteration: 1469 Loss: 1.8335344791412354 | sereeeeerrererre \n",
            "r\\ Iteration: 1470 Loss: 1.767437219619751 | seeeeeerrererre \n",
            "r\\ Iteration: 1471 Loss: 1.8090598583221436 | sereerrererre \n",
            "r\\ Iteration: 1472 Loss: 1.7244949340820312 | seeeeeererrreerre \n",
            "r\\ Iteration: 1473 Loss: 1.9335317611694336 | seeeereeeeere \n",
            "r\\ Iteration: 1474 Loss: 1.966689109802246 | sereereerererre \n",
            "r\\ Iteration: 1475 Loss: 1.7764732837677002 | seeeeererre \n",
            "r\\ Iteration: 1476 Loss: 1.907545804977417 | seeereeeeere \n",
            "r\\ Iteration: 1477 Loss: 1.9855103492736816 | sererreeeeeeee \n",
            "r\\ Iteration: 1478 Loss: 2.121579885482788 | seereeerererre \n",
            "r\\ Iteration: 1479 Loss: 1.8030319213867188 | sereeeeeee \n",
            "r\\ Iteration: 1480 Loss: 2.084134578704834 | seeerereereeeeeree \n",
            "r\\ Iteration: 1481 Loss: 1.982567548751831 | seeeereeerre \n",
            "r\\ Iteration: 1482 Loss: 1.8834764957427979 | seerrererre \n",
            "r\\ Iteration: 1483 Loss: 1.7610325813293457 | seerereerererre \n",
            "r\\ Iteration: 1484 Loss: 1.7043344974517822 | seeeereeeeerrererre \n",
            "r\\ Iteration: 1485 Loss: 1.883500576019287 | seeeeeerererre \n",
            "r\\ Iteration: 1486 Loss: 1.8083434104919434 | seeeerre \n",
            "r\\ Iteration: 1487 Loss: 1.7534377574920654 | seeeeeerrererre \n",
            "r\\ Iteration: 1488 Loss: 1.7957570552825928 | seeeeeerrererre \n",
            "r\\ Iteration: 1489 Loss: 1.804302453994751 | seeereererre \n",
            "r\\ Iteration: 1490 Loss: 2.006821632385254 | seeeeeeereeeeeee \n",
            "r\\ Iteration: 1491 Loss: 2.0928709506988525 | seeeeeeerererre \n",
            "r\\ Iteration: 1492 Loss: 1.800119400024414 | seeeeerre \n",
            "r\\ Iteration: 1493 Loss: 1.9211454391479492 | seeeeeeeeeree \n",
            "r\\ Iteration: 1494 Loss: 1.972707748413086 | seeeeeereeeeree \n",
            "r\\ Iteration: 1495 Loss: 1.9060993194580078 | sereereeeeeerre \n",
            "r\\ Iteration: 1496 Loss: 2.103923797607422 | seeeeereereerre \n",
            "r\\ Iteration: 1497 Loss: 1.71720552444458 | seereeerrererre \n",
            "r\\ Iteration: 1498 Loss: 1.8530409336090088 | seeeeeeeeee \n",
            "r\\ Iteration: 1499 Loss: 2.0418806076049805 | seeerrererre \n",
            "r\\ Iteration: 1500 Loss: 1.7424771785736084 | seeeereeeere \n",
            "r\\ Iteration: 1501 Loss: 2.0083062648773193 | seerrererre \n",
            "r\\ Iteration: 1502 Loss: 1.7655014991760254 | seeeeereeere \n",
            "r\\ Iteration: 1503 Loss: 1.981663703918457 | seeeereeeere \n",
            "r\\ Iteration: 1504 Loss: 1.8831491470336914 | seeeereereerrererre \n",
            "r\\ Iteration: 1505 Loss: 1.8849754333496094 | seeeeerrererre \n",
            "r\\ Iteration: 1506 Loss: 1.8179128170013428 | sereererrererre \n",
            "r\\ Iteration: 1507 Loss: 1.8406322002410889 | seeeerererre \n",
            "r\\ Iteration: 1508 Loss: 1.8303399085998535 | seeerereeree \n",
            "r\\ Iteration: 1509 Loss: 1.8926644325256348 | serereeereee \n",
            "r\\ Iteration: 1510 Loss: 2.034799814224243 | seeeeerereerrererre \n",
            "r\\ Iteration: 1511 Loss: 1.8119893074035645 | seeeerereereerrrrerre \n",
            "r\\ Iteration: 1512 Loss: 1.8717677593231201 | seeererrrrerre \n",
            "r\\ Iteration: 1513 Loss: 1.791161060333252 | seerererrrrerre \n",
            "r\\ Iteration: 1514 Loss: 1.8046777248382568 | serereeererere \n",
            "r\\ Iteration: 1515 Loss: 1.8932952880859375 | serereereerre \n",
            "r\\ Iteration: 1516 Loss: 1.881962776184082 | sereererre \n",
            "r\\ Iteration: 1517 Loss: 1.7008962631225586 | seeeerrrrerre \n",
            "r\\ Iteration: 1518 Loss: 1.8146636486053467 | seeerererereeree \n",
            "r\\ Iteration: 1519 Loss: 1.826124668121338 | sereerereeerrrerre \n",
            "r\\ Iteration: 1520 Loss: 1.9579792022705078 | srrererrrrerre \n",
            "r\\ Iteration: 1521 Loss: 1.7387254238128662 | seeererrrrerre \n",
            "r\\ Iteration: 1522 Loss: 1.8961598873138428 | seererrrrerre \n",
            "r\\ Iteration: 1523 Loss: 1.668541669845581 | sereeee \n",
            "r\\ Iteration: 1524 Loss: 2.2171237468719482 | sereereeerre \n",
            "r\\ Iteration: 1525 Loss: 2.1117348670959473 | sreeeereeeererre \n",
            "r\\ Iteration: 1526 Loss: 1.8950488567352295 | seeeerreerre \n",
            "r\\ Iteration: 1527 Loss: 1.949392557144165 | seeeereereeeerre \n",
            "r\\ Iteration: 1528 Loss: 2.0425655841827393 | sreererereeerre \n",
            "r\\ Iteration: 1529 Loss: 1.9783227443695068 | seereereerere \n",
            "r\\ Iteration: 1530 Loss: 2.075171709060669 | serrereeeree \n",
            "r\\ Iteration: 1531 Loss: 1.9528188705444336 | srereererrreee \n",
            "r\\ Iteration: 1532 Loss: 2.111485004425049 | serreeeeerrereererre \n",
            "r\\ Iteration: 1533 Loss: 1.9083878993988037 | seereeeeerrererre \n",
            "r\\ Iteration: 1534 Loss: 1.9023411273956299 | seeeeeerrererre \n",
            "r\\ Iteration: 1535 Loss: 1.8129615783691406 | srreeeeeeerererre \n",
            "r\\ Iteration: 1536 Loss: 1.8542587757110596 | serreereeeerre \n",
            "r\\ Iteration: 1537 Loss: 1.8494188785552979 | sreerereeeeee \n",
            "r\\ Iteration: 1538 Loss: 1.8751335144042969 | seeeereeeeeree \n",
            "r\\ Iteration: 1539 Loss: 1.9088811874389648 | seeeereere \n",
            "r\\ Iteration: 1540 Loss: 1.9651575088500977 | seeeeererre \n",
            "r\\ Iteration: 1541 Loss: 1.9265456199645996 | seeeeeeeeere \n",
            "r\\ Iteration: 1542 Loss: 1.8401830196380615 | sreeerrererre \n",
            "r\\ Iteration: 1543 Loss: 1.748403549194336 | seeeeeerrererre \n",
            "r\\ Iteration: 1544 Loss: 1.8247835636138916 | sereereeeeereeerre \n",
            "r\\ Iteration: 1545 Loss: 2.0405142307281494 | seeeeeeeerererre \n",
            "r\\ Iteration: 1546 Loss: 1.8302559852600098 | seeeeeererrererre \n",
            "r\\ Iteration: 1547 Loss: 1.9411957263946533 | seeeeeeeeerrererre \n",
            "r\\ Iteration: 1548 Loss: 1.984109878540039 | srreereeerre \n",
            "r\\ Iteration: 1549 Loss: 1.8734121322631836 | sreeeereree \n",
            "r\\ Iteration: 1550 Loss: 1.9665350914001465 | seeerreerererre \n",
            "r\\ Iteration: 1551 Loss: 1.8796169757843018 | seereeerrererre \n",
            "r\\ Iteration: 1552 Loss: 1.6976189613342285 | seeeerrererere \n",
            "r\\ Iteration: 1553 Loss: 1.845325231552124 | srrerererre \n",
            "r\\ Iteration: 1554 Loss: 1.9352960586547852 | seeeeeeerrererre \n",
            "r\\ Iteration: 1555 Loss: 1.8772163391113281 | seeereeeereee \n",
            "r\\ Iteration: 1556 Loss: 2.20418381690979 | seereerere \n",
            "r\\ Iteration: 1557 Loss: 1.9400780200958252 | seeeeeerererre \n",
            "r\\ Iteration: 1558 Loss: 1.684434175491333 | sreeeeerereerrererre \n",
            "r\\ Iteration: 1559 Loss: 1.8199145793914795 | seeeeereeerre \n",
            "r\\ Iteration: 1560 Loss: 1.9410343170166016 | sreeeeeereeerre \n",
            "r\\ Iteration: 1561 Loss: 1.9675662517547607 | seeeeeerrererre \n",
            "r\\ Iteration: 1562 Loss: 1.7931804656982422 | serreeerre \n",
            "r\\ Iteration: 1563 Loss: 1.9358282089233398 | sreeeeererere \n",
            "r\\ Iteration: 1564 Loss: 2.0250253677368164 | sreeerrererre \n",
            "r\\ Iteration: 1565 Loss: 1.8792121410369873 | sreeerrererre \n",
            "r\\ Iteration: 1566 Loss: 1.8756132125854492 | seeeerrereererre \n",
            "r\\ Iteration: 1567 Loss: 2.0637428760528564 | seeerrerrererre \n",
            "r\\ Iteration: 1568 Loss: 1.7101101875305176 | srereeeererere \n",
            "r\\ Iteration: 1569 Loss: 1.9950196743011475 | seeeererrereererre \n",
            "r\\ Iteration: 1570 Loss: 1.9478881359100342 | sereeerereeree \n",
            "r\\ Iteration: 1571 Loss: 1.8121097087860107 | seeeererrrrerre \n",
            "r\\ Iteration: 1572 Loss: 1.713594913482666 | seeerreerrreerre \n",
            "r\\ Iteration: 1573 Loss: 1.9078564643859863 | sreereeeeere \n",
            "r\\ Iteration: 1574 Loss: 2.133707284927368 | seereerreeeeree \n",
            "r\\ Iteration: 1575 Loss: 1.902245283126831 | seeeeeereeree \n",
            "r\\ Iteration: 1576 Loss: 1.7999942302703857 | srererrererre \n",
            "r\\ Iteration: 1577 Loss: 1.7046239376068115 | seeeeerererreeere \n",
            "r\\ Iteration: 1578 Loss: 1.9769871234893799 | seereerereeere \n",
            "r\\ Iteration: 1579 Loss: 1.9843215942382812 | sreereeereeerre \n",
            "r\\ Iteration: 1580 Loss: 2.040522336959839 | seeerrererre \n",
            "r\\ Iteration: 1581 Loss: 1.8114042282104492 | sreeeereerrererre \n",
            "r\\ Iteration: 1582 Loss: 1.825634479522705 | seeereeere \n",
            "r\\ Iteration: 1583 Loss: 1.9060180187225342 | seeeeererre \n",
            "r\\ Iteration: 1584 Loss: 1.741602897644043 | seeeerrerererre \n",
            "r\\ Iteration: 1585 Loss: 1.7684648036956787 | seeeeeeerererre \n",
            "r\\ Iteration: 1586 Loss: 1.727376937866211 | sreeerrererre \n",
            "r\\ Iteration: 1587 Loss: 1.7871859073638916 | seeeeereeeeerre \n",
            "r\\ Iteration: 1588 Loss: 1.9993793964385986 | seeeeeeeeeee \n",
            "r\\ Iteration: 1589 Loss: 1.922283411026001 | seeeeeerererre \n",
            "r\\ Iteration: 1590 Loss: 1.705153226852417 | seeeeeeeee \n",
            "r\\ Iteration: 1591 Loss: 2.0382614135742188 | seeeerrererre \n",
            "r\\ Iteration: 1592 Loss: 1.808251142501831 | sereeeeeeeeeeee \n",
            "r\\ Iteration: 1593 Loss: 2.047576665878296 | seereeeeerrererre \n",
            "r\\ Iteration: 1594 Loss: 1.8472111225128174 | sereerrererre \n",
            "r\\ Iteration: 1595 Loss: 1.753357172012329 | seeeeeeeeeeeeee \n",
            "r\\ Iteration: 1596 Loss: 1.9749162197113037 | seeeerreerre \n",
            "r\\ Iteration: 1597 Loss: 1.8979361057281494 | srreeeeeeerererre \n",
            "r\\ Iteration: 1598 Loss: 1.9002845287322998 | sereererrererre \n",
            "r\\ Iteration: 1599 Loss: 1.8486459255218506 | sereeeerrereererre \n",
            "r\\ Iteration: 1600 Loss: 2.052553176879883 | seeeererre \n",
            "r\\ Iteration: 1601 Loss: 1.8932774066925049 | seerereeeeerere \n",
            "r\\ Iteration: 1602 Loss: 1.811048984527588 | sreeeeeeerrererre \n",
            "r\\ Iteration: 1603 Loss: 1.850264072418213 | sreeeerererre \n",
            "r\\ Iteration: 1604 Loss: 1.756829023361206 | sereeeerrererre \n",
            "r\\ Iteration: 1605 Loss: 1.815009355545044 | sreeerrereeeere \n",
            "r\\ Iteration: 1606 Loss: 1.8887507915496826 | seeererre \n",
            "r\\ Iteration: 1607 Loss: 1.9297091960906982 | sereeeeerere \n",
            "r\\ Iteration: 1608 Loss: 1.8120007514953613 | srereeeererererre \n",
            "r\\ Iteration: 1609 Loss: 1.8585405349731445 | seeeeeeerrererre \n",
            "r\\ Iteration: 1610 Loss: 1.8655281066894531 | seeereerererre \n",
            "r\\ Iteration: 1611 Loss: 1.8030736446380615 | sreereeereeerre \n",
            "r\\ Iteration: 1612 Loss: 2.0537617206573486 | serereereereree \n",
            "r\\ Iteration: 1613 Loss: 2.0281498432159424 | seeeeerrererre \n",
            "r\\ Iteration: 1614 Loss: 1.6675405502319336 | sreeerrererre \n",
            "r\\ Iteration: 1615 Loss: 1.7713053226470947 | srrreereeeeerre \n",
            "r\\ Iteration: 1616 Loss: 1.850437879562378 | seeeeeeeeeee \n",
            "r\\ Iteration: 1617 Loss: 1.8283469676971436 | seeererrererre \n",
            "r\\ Iteration: 1618 Loss: 1.8456716537475586 | seeeeerererrererre \n",
            "r\\ Iteration: 1619 Loss: 1.8799617290496826 | seeeeeeereee \n",
            "r\\ Iteration: 1620 Loss: 1.9469292163848877 | sereerererre \n",
            "r\\ Iteration: 1621 Loss: 1.6626396179199219 | seeeeeeerrererre \n",
            "r\\ Iteration: 1622 Loss: 1.8731634616851807 | sreeeeereeerre \n",
            "r\\ Iteration: 1623 Loss: 2.069148540496826 | serrrreeeere \n",
            "r\\ Iteration: 1624 Loss: 2.130445957183838 | seeereeerreeeerre \n",
            "r\\ Iteration: 1625 Loss: 1.9168846607208252 | sreeeeereeerre \n",
            "r\\ Iteration: 1626 Loss: 2.00278902053833 | sereeerrererre \n",
            "r\\ Iteration: 1627 Loss: 1.8199124336242676 | seereeeeerrrrererre \n",
            "r\\ Iteration: 1628 Loss: 1.9791958332061768 | sreerereeerre \n",
            "r\\ Iteration: 1629 Loss: 1.9241912364959717 | sereeeerrerrererre \n",
            "r\\ Iteration: 1630 Loss: 1.8359789848327637 | seeeerereree \n",
            "r\\ Iteration: 1631 Loss: 1.8080353736877441 | srrrrerererre \n",
            "r\\ Iteration: 1632 Loss: 1.8939926624298096 | sereererre \n",
            "r\\ Iteration: 1633 Loss: 1.7357432842254639 | sereerrrrrerre \n",
            "r\\ Iteration: 1634 Loss: 1.8855435848236084 | seeerrererre \n",
            "r\\ Iteration: 1635 Loss: 1.8299744129180908 | srereereeree \n",
            "r\\ Iteration: 1636 Loss: 2.030184030532837 | seeererrrrerre \n",
            "r\\ Iteration: 1637 Loss: 1.8621869087219238 | sererrrrrerre \n",
            "r\\ Iteration: 1638 Loss: 1.7421271800994873 | seeeereereerre \n",
            "r\\ Iteration: 1639 Loss: 1.912553071975708 | sreereerrererre \n",
            "r\\ Iteration: 1640 Loss: 1.855947732925415 | seeererrererre \n",
            "r\\ Iteration: 1641 Loss: 1.7010369300842285 | seeeeeeeere \n",
            "r\\ Iteration: 1642 Loss: 1.8415098190307617 | serereeeeeerrererre \n",
            "r\\ Iteration: 1643 Loss: 1.8442189693450928 | seerereeererere \n",
            "r\\ Iteration: 1644 Loss: 1.9186084270477295 | seeeeeeeeee \n",
            "r\\ Iteration: 1645 Loss: 2.0152244567871094 | srreeerrererre \n",
            "r\\ Iteration: 1646 Loss: 1.7334620952606201 | srereereerre \n",
            "r\\ Iteration: 1647 Loss: 1.9624369144439697 | seeeeeerererre \n",
            "r\\ Iteration: 1648 Loss: 1.7355585098266602 | sreerereereeeeeree \n",
            "r\\ Iteration: 1649 Loss: 1.951720952987671 | seseeeerrererre \n",
            "r\\ Iteration: 1650 Loss: 1.8137421607971191 | seeeeerrererre \n",
            "r\\ Iteration: 1651 Loss: 1.7591633796691895 | sereeeeeeerererre \n",
            "r\\ Iteration: 1652 Loss: 1.8111693859100342 | seereeerrererre \n",
            "r\\ Iteration: 1653 Loss: 1.8131904602050781 | sereeeeererre \n",
            "r\\ Iteration: 1654 Loss: 1.8721303939819336 | seeeeeeerrererre \n",
            "r\\ Iteration: 1655 Loss: 1.8800733089447021 | seeeererrererre \n",
            "r\\ Iteration: 1656 Loss: 1.880953073501587 | sereeeeerrererre \n",
            "r\\ Iteration: 1657 Loss: 1.933774709701538 | seereeereerererre \n",
            "r\\ Iteration: 1658 Loss: 1.8192510604858398 | seseeerrererre \n",
            "r\\ Iteration: 1659 Loss: 1.7817354202270508 | sreeeeee \n",
            "r\\ Iteration: 1660 Loss: 2.0153090953826904 | seeeerrererre \n",
            "r\\ Iteration: 1661 Loss: 1.7530629634857178 | sereeeeeeeeree \n",
            "r\\ Iteration: 1662 Loss: 1.8882701396942139 | sererreerrererre \n",
            "r\\ Iteration: 1663 Loss: 1.9391098022460938 | seeeereeerrererre \n",
            "r\\ Iteration: 1664 Loss: 1.7912962436676025 | sereeeerrererre \n",
            "r\\ Iteration: 1665 Loss: 1.8045766353607178 | seeeeerrererre \n",
            "r\\ Iteration: 1666 Loss: 1.8167812824249268 | seeeerereee \n",
            "r\\ Iteration: 1667 Loss: 1.8532133102416992 | serreereerrererre \n",
            "r\\ Iteration: 1668 Loss: 1.8424570560455322 | seeerrrereee \n",
            "r\\ Iteration: 1669 Loss: 2.113971471786499 | serreererrererre \n",
            "r\\ Iteration: 1670 Loss: 1.7998895645141602 | seeerereeeeee \n",
            "r\\ Iteration: 1671 Loss: 1.9128873348236084 | seeeeeeeeee \n",
            "r\\ Iteration: 1672 Loss: 1.9155330657958984 | sreeeeerererre \n",
            "r\\ Iteration: 1673 Loss: 1.8786263465881348 | seereeeeerrererre \n",
            "r\\ Iteration: 1674 Loss: 1.7643482685089111 | sereeeeeeeererre \n",
            "r\\ Iteration: 1675 Loss: 1.9930500984191895 | sreeerrereeeere \n",
            "r\\ Iteration: 1676 Loss: 1.867600679397583 | sereeaerrererre \n",
            "r\\ Iteration: 1677 Loss: 1.7795672416687012 | seeeeerrererre \n",
            "r\\ Iteration: 1678 Loss: 1.7427339553833008 | serereeeeee \n",
            "r\\ Iteration: 1679 Loss: 2.2001609802246094 | sreeereeeeee \n",
            "r\\ Iteration: 1680 Loss: 2.047269582748413 | seeeeerererre \n",
            "r\\ Iteration: 1681 Loss: 1.885375738143921 | seeeerrererre \n",
            "r\\ Iteration: 1682 Loss: 1.8782579898834229 | seeererererre \n",
            "r\\ Iteration: 1683 Loss: 1.822286605834961 | seeererrererre \n",
            "r\\ Iteration: 1684 Loss: 1.8603641986846924 | seereerreerre \n",
            "r\\ Iteration: 1685 Loss: 1.9797983169555664 | seereeeeeerrererre \n",
            "r\\ Iteration: 1686 Loss: 1.9018688201904297 | sreeeerreeeeeree \n",
            "r\\ Iteration: 1687 Loss: 2.1544806957244873 | sreereeeeree \n",
            "r\\ Iteration: 1688 Loss: 1.9442434310913086 | seeeereereree \n",
            "r\\ Iteration: 1689 Loss: 1.908890724182129 | seeeeereeere \n",
            "r\\ Iteration: 1690 Loss: 2.0166008472442627 | seereeeerrererre \n",
            "r\\ Iteration: 1691 Loss: 1.968141794204712 | seeeeerrererre \n",
            "r\\ Iteration: 1692 Loss: 1.7138886451721191 | sreereeeeeree \n",
            "r\\ Iteration: 1693 Loss: 1.8607072830200195 | seeerrererre \n",
            "r\\ Iteration: 1694 Loss: 1.7866098880767822 | seereeeeeeeeeerere \n",
            "r\\ Iteration: 1695 Loss: 1.9533421993255615 | seeereereeeeee \n",
            "r\\ Iteration: 1696 Loss: 1.9433300495147705 | seeeeeeerererre \n",
            "r\\ Iteration: 1697 Loss: 1.792194128036499 | sreeeeereereere \n",
            "r\\ Iteration: 1698 Loss: 2.0169084072113037 | sereeeerrererre \n",
            "r\\ Iteration: 1699 Loss: 1.8089847564697266 | serreereeeeree \n",
            "r\\ Iteration: 1700 Loss: 1.7977209091186523 | seeeeeeeee \n",
            "r\\ Iteration: 1701 Loss: 1.940382957458496 | serereerreeerre \n",
            "r\\ Iteration: 1702 Loss: 1.9684293270111084 | seeeerrererere \n",
            "r\\ Iteration: 1703 Loss: 1.8217229843139648 | sereerrererre \n",
            "r\\ Iteration: 1704 Loss: 1.807063102722168 | sreereeeeeree \n",
            "r\\ Iteration: 1705 Loss: 1.8566596508026123 | seereerrererre \n",
            "r\\ Iteration: 1706 Loss: 1.7110047340393066 | seeeeeeeeeaee \n",
            "r\\ Iteration: 1707 Loss: 2.1979024410247803 | serereererrererre \n",
            "r\\ Iteration: 1708 Loss: 1.7180674076080322 | sreeeeerre \n",
            "r\\ Iteration: 1709 Loss: 1.9789457321166992 | sreeeeerreaeeree \n",
            "r\\ Iteration: 1710 Loss: 1.8827948570251465 | sereeeerrererre \n",
            "r\\ Iteration: 1711 Loss: 1.7927334308624268 | seaeaerrererre \n",
            "r\\ Iteration: 1712 Loss: 1.7260777950286865 | srereerrrererre \n",
            "r\\ Iteration: 1713 Loss: 1.8457448482513428 | sreareree \n",
            "r\\ Iteration: 1714 Loss: 2.1559741497039795 | srrrereeaererre \n",
            "r\\ Iteration: 1715 Loss: 1.834179162979126 | searreeeaeeeeae \n",
            "r\\ Iteration: 1716 Loss: 2.0478107929229736 | seaeaerrererre \n",
            "r\\ Iteration: 1717 Loss: 1.799649715423584 | sreaererrrerre \n",
            "r\\ Iteration: 1718 Loss: 1.8795533180236816 | seaeaeaeaeaee \n",
            "r\\ Iteration: 1719 Loss: 1.791867971420288 | seaeerrrererre \n",
            "r\\ Iteration: 1720 Loss: 1.8737413883209229 | sereeereree \n",
            "r\\ Iteration: 1721 Loss: 1.985929012298584 | seaeerrererre \n",
            "r\\ Iteration: 1722 Loss: 1.7366969585418701 | sereerrererre \n",
            "r\\ Iteration: 1723 Loss: 1.7241361141204834 | seaerrererre \n",
            "r\\ Iteration: 1724 Loss: 1.7182540893554688 | seaeerearerre \n",
            "r\\ Iteration: 1725 Loss: 1.8460514545440674 | sereerreereeeeae \n",
            "r\\ Iteration: 1726 Loss: 1.9544057846069336 | srrereeeerrererre \n",
            "r\\ Iteration: 1727 Loss: 1.7477750778198242 | seaerrrererre \n",
            "r\\ Iteration: 1728 Loss: 1.7067832946777344 | seaeeaeereree \n",
            "r\\ Iteration: 1729 Loss: 1.9315979480743408 | serreaearererre \n",
            "r\\ Iteration: 1730 Loss: 1.8794703483581543 | seaeareeeeae \n",
            "r\\ Iteration: 1731 Loss: 1.9031710624694824 | serearrererre \n",
            "r\\ Iteration: 1732 Loss: 1.7776305675506592 | sreearererre \n",
            "r\\ Iteration: 1733 Loss: 1.7548632621765137 | serearererre \n",
            "r\\ Iteration: 1734 Loss: 1.8326911926269531 | seaeeaeareaae \n",
            "r\\ Iteration: 1735 Loss: 2.01358962059021 | seaaeeeaeerrererre \n",
            "r\\ Iteration: 1736 Loss: 1.8592348098754883 | sreaeeaeaae \n",
            "r\\ Iteration: 1737 Loss: 2.1116795539855957 | sereeraeereeeeae \n",
            "r\\ Iteration: 1738 Loss: 1.9368834495544434 | srreaearererre \n",
            "r\\ Iteration: 1739 Loss: 1.9035565853118896 | sreereaeeree \n",
            "r\\ Iteration: 1740 Loss: 1.9063663482666016 | sereaeaeaeree \n",
            "r\\ Iteration: 1741 Loss: 1.969803810119629 | sereaereeerrererre \n",
            "r\\ Iteration: 1742 Loss: 1.9430346488952637 | seaeeeaerereerrererre \n",
            "r\\ Iteration: 1743 Loss: 1.7981114387512207 | sreeaerereeaerae \n",
            "r\\ Iteration: 1744 Loss: 2.115969657897949 | srereeeareae \n",
            "r\\ Iteration: 1745 Loss: 2.008565664291382 | seeerrererre \n",
            "r\\ Iteration: 1746 Loss: 1.82088041305542 | srraereree \n",
            "r\\ Iteration: 1747 Loss: 2.0315816402435303 | seaeraeearereae \n",
            "r\\ Iteration: 1748 Loss: 1.8680975437164307 | seaeaeeaeeae \n",
            "r\\ Iteration: 1749 Loss: 1.9159269332885742 | seereeeaeerrererre \n",
            "r\\ Iteration: 1750 Loss: 1.9045932292938232 | seaeaearee \n",
            "r\\ Iteration: 1751 Loss: 2.129650115966797 | srerearrrererre \n",
            "r\\ Iteration: 1752 Loss: 1.8499476909637451 | serararrererre \n",
            "r\\ Iteration: 1753 Loss: 1.9018654823303223 | seaerererrererre \n",
            "r\\ Iteration: 1754 Loss: 1.8049776554107666 | seaeaeaerererre \n",
            "r\\ Iteration: 1755 Loss: 1.8126485347747803 | seaereaeaeaerererre \n",
            "r\\ Iteration: 1756 Loss: 1.83915114402771 | seaeeaeerrererre \n",
            "r\\ Iteration: 1757 Loss: 1.8553736209869385 | seaeaeeaeeae \n",
            "r\\ Iteration: 1758 Loss: 1.898526906967163 | sreaeeaerrererre \n",
            "r\\ Iteration: 1759 Loss: 1.742049217224121 | seerreaeaere \n",
            "r\\ Iteration: 1760 Loss: 2.058509111404419 | seaererrererre \n",
            "r\\ Iteration: 1761 Loss: 1.6980814933776855 | sereaeaeaeaere \n",
            "r\\ Iteration: 1762 Loss: 2.0458338260650635 | srreaeearrerererre \n",
            "r\\ Iteration: 1763 Loss: 1.9545302391052246 | sreeeaeraererre \n",
            "r\\ Iteration: 1764 Loss: 1.9354805946350098 | seaereaerraererre \n",
            "r\\ Iteration: 1765 Loss: 1.8518645763397217 | seaereeraererre \n",
            "r\\ Iteration: 1766 Loss: 1.6910479068756104 | seeaeaeaeaeaerere \n",
            "r\\ Iteration: 1767 Loss: 1.8832242488861084 | seeeeaerereaere \n",
            "r\\ Iteration: 1768 Loss: 1.9524211883544922 | sreeeaeeraererre \n",
            "r\\ Iteration: 1769 Loss: 1.9075684547424316 | seaeeraererre \n",
            "r\\ Iteration: 1770 Loss: 1.6629552841186523 | seeaeaeraererre \n",
            "r\\ Iteration: 1771 Loss: 1.7800889015197754 | seereaeraererre \n",
            "r\\ Iteration: 1772 Loss: 1.8078844547271729 | seaeaeaaeaee \n",
            "r\\ Iteration: 1773 Loss: 1.8961827754974365 | seaeeaeaeeree \n",
            "r\\ Iteration: 1774 Loss: 1.9259541034698486 | seaeaearee \n",
            "r\\ Iteration: 1775 Loss: 2.1282804012298584 | seaaeeeaeeraeaae \n",
            "r\\ Iteration: 1776 Loss: 2.0481884479522705 | sreeraeaeare \n",
            "r\\ Iteration: 1777 Loss: 1.8383610248565674 | seaeeaeaereaaeare \n",
            "r\\ Iteration: 1778 Loss: 1.9948887825012207 | seaaeeeaareaeare \n",
            "r\\ Iteration: 1779 Loss: 1.8696458339691162 | seaeeaaaeeaaeaeare \n",
            "r\\ Iteration: 1780 Loss: 1.8763303756713867 | seaeeaaeeaee \n",
            "r\\ Iteration: 1781 Loss: 2.138719081878662 | seaeaaeaeaae \n",
            "r\\ Iteration: 1782 Loss: 1.7545130252838135 | seaeeaaeaeaae \n",
            "r\\ Iteration: 1783 Loss: 1.7203633785247803 | sreaeaaeaeeaeaae \n",
            "r\\ Iteration: 1784 Loss: 1.9339730739593506 | seaeeaeaeeaee \n",
            "r\\ Iteration: 1785 Loss: 1.9126529693603516 | seaeaaeeaeaeaeae \n",
            "r\\ Iteration: 1786 Loss: 1.7590713500976562 | seeeaaeaeaae \n",
            "r\\ Iteration: 1787 Loss: 1.7941813468933105 | seaeaaeaaeaeaae \n",
            "r\\ Iteration: 1788 Loss: 1.8323419094085693 | seaeeaeeaeaae \n",
            "r\\ Iteration: 1789 Loss: 2.1782829761505127 | seeeeaeaeaeeaaeaeaae \n",
            "r\\ Iteration: 1790 Loss: 1.7645952701568604 | seaeeaeaeaeaae \n",
            "r\\ Iteration: 1791 Loss: 1.8611445426940918 | seaeeeaeaae \n",
            "r\\ Iteration: 1792 Loss: 1.9431610107421875 | seaeaaaeeaae \n",
            "r\\ Iteration: 1793 Loss: 1.9513890743255615 | seaeeaeaeaaeaeaae \n",
            "r\\ Iteration: 1794 Loss: 1.9079499244689941 | seaaeaeaaeaeaae \n",
            "r\\ Iteration: 1795 Loss: 1.8779244422912598 | seaeeaeaeeaee \n",
            "r\\ Iteration: 1796 Loss: 1.8175323009490967 | seeaeeaeaeaeaae \n",
            "r\\ Iteration: 1797 Loss: 1.8480641841888428 | seaeeeaaeaeaae \n",
            "r\\ Iteration: 1798 Loss: 2.134413242340088 | seaeae \n",
            "r\\ Iteration: 1799 Loss: 1.995058298110962 | seaeaeaaeaeae \n",
            "r\\ Iteration: 1800 Loss: 1.8121116161346436 | seaeeeaeaeaae \n",
            "r\\ Iteration: 1801 Loss: 1.8840491771697998 | seeeareaaaeaeaae \n",
            "r\\ Iteration: 1802 Loss: 1.919670581817627 | seaeea|eeaeeaaae \n",
            "r\\ Iteration: 1803 Loss: 1.7841851711273193 | sreeea|eaeaae \n",
            "r\\ Iteration: 1804 Loss: 1.7698049545288086 | sreaeaeeaea|eaeaae \n",
            "r\\ Iteration: 1805 Loss: 1.7458858489990234 | seaeaeaeeaee \n",
            "r\\ Iteration: 1806 Loss: 1.8335723876953125 | seaeae|ree \n",
            "r\\ Iteration: 1807 Loss: 2.128235101699829 | seeea|eaeeae \n",
            "r\\ Iteration: 1808 Loss: 2.052769422531128 | seea|eaea|eaeaae \n",
            "r\\ Iteration: 1809 Loss: 1.7995450496673584 | seaaeeaeaeaae \n",
            "r\\ Iteration: 1810 Loss: 1.9514544010162354 | sreaeareaaeeaeaee \n",
            "r\\ Iteration: 1811 Loss: 2.0713419914245605 | seaeeaeea|eaea|e \n",
            "r\\ Iteration: 1812 Loss: 1.8282053470611572 | srraeaeeeaeaeaee \n",
            "r\\ Iteration: 1813 Loss: 1.8381686210632324 | seaea|eeaeaeae|e \n",
            "r\\ Iteration: 1814 Loss: 1.8220133781433105 | seeaaeae|e \n",
            "r\\ Iteration: 1815 Loss: 1.9177944660186768 | seaeaea|eaeaae \n",
            "r\\ Iteration: 1816 Loss: 1.6665754318237305 | sreaeseaeaee \n",
            "r\\ Iteration: 1817 Loss: 1.898179054260254 | seaeaeeesesee \n",
            "r\\ Iteration: 1818 Loss: 1.931685447692871 | seeaea|eaeae \n",
            "r\\ Iteration: 1819 Loss: 1.7028391361236572 | seaae \n",
            "r\\ Iteration: 1820 Loss: 2.1016039848327637 | seaeeaaaeaeaeaae \n",
            "r\\ Iteration: 1821 Loss: 1.9218237400054932 | seaeeaeaeaeaae \n",
            "r\\ Iteration: 1822 Loss: 1.8940744400024414 | seaeaa|eaeaae \n",
            "r\\ Iteration: 1823 Loss: 1.8208980560302734 | seseaea|eaea|e \n",
            "r\\ Iteration: 1824 Loss: 1.7427852153778076 | sreaeaeeeaeaeaee \n",
            "r\\ Iteration: 1825 Loss: 1.8368499279022217 | se|eeaeaeaaae \n",
            "r\\ Iteration: 1826 Loss: 1.9393141269683838 | seaeaeaaeesea|e \n",
            "r\\ Iteration: 1827 Loss: 2.0413734912872314 | seeaeeaeeea|eaeaae \n",
            "r\\ Iteration: 1828 Loss: 1.8831582069396973 | seaeees|eaeaae \n",
            "r\\ Iteration: 1829 Loss: 1.6943769454956055 | sea|eseaae \n",
            "r\\ Iteration: 1830 Loss: 1.7960870265960693 | seeeeaesesees|eaeaae \n",
            "r\\ Iteration: 1831 Loss: 1.8203134536743164 | seaeeeaaae \n",
            "r\\ Iteration: 1832 Loss: 2.1196584701538086 | seeaeeeses|eaeaae \n",
            "r\\ Iteration: 1833 Loss: 1.810391902923584 | seaeaeaea|eaeaae \n",
            "r\\ Iteration: 1834 Loss: 1.852224588394165 | sreaeaea|eaeaae \n",
            "r\\ Iteration: 1835 Loss: 1.8677246570587158 | seaaeeaeaeaeseae \n",
            "r\\ Iteration: 1836 Loss: 1.9021921157836914 | seaees|eaaae \n",
            "r\\ Iteration: 1837 Loss: 1.8740296363830566 | seaaaeeeaae \n",
            "r\\ Iteration: 1838 Loss: 2.032398223876953 | sesaeeaeeaeaee \n",
            "r\\ Iteration: 1839 Loss: 2.093681812286377 | seaeeaeaeaeaae \n",
            "r\\ Iteration: 1840 Loss: 1.8088769912719727 | seaeaeeeaeaee \n",
            "r\\ Iteration: 1841 Loss: 1.9663727283477783 | seaeeaaeaeaae \n",
            "r\\ Iteration: 1842 Loss: 1.6554138660430908 | seeaeaeeeaeaeae \n",
            "r\\ Iteration: 1843 Loss: 1.919623851776123 | seaeeaeaaeaeaae \n",
            "r\\ Iteration: 1844 Loss: 1.8100485801696777 | seaeeaeeeeeaee \n",
            "r\\ Iteration: 1845 Loss: 2.0580942630767822 | seaaaeeeaeeeeae \n",
            "r\\ Iteration: 1846 Loss: 1.9442784786224365 | seeeeaeaaeaeaae \n",
            "r\\ Iteration: 1847 Loss: 1.9129524230957031 | seaeeeeaeae \n",
            "r\\ Iteration: 1848 Loss: 2.109238862991333 | seeaeeaeeaae \n",
            "r\\ Iteration: 1849 Loss: 1.8628170490264893 | seaaeaeaeeaae \n",
            "r\\ Iteration: 1850 Loss: 1.9258854389190674 | seeeaeeaaeeeaae \n",
            "r\\ Iteration: 1851 Loss: 2.0352299213409424 | saeeeaeaeaae \n",
            "r\\ Iteration: 1852 Loss: 1.7922554016113281 | seeaeeaeaeeaaae \n",
            "r\\ Iteration: 1853 Loss: 1.9355547428131104 | seeaeeaeaeaeaeae \n",
            "r\\ Iteration: 1854 Loss: 1.9017786979675293 | seeaeaeaeeaaeaeaae \n",
            "r\\ Iteration: 1855 Loss: 1.844853162765503 | seeeaeae \n",
            "r\\ Iteration: 1856 Loss: 2.1258482933044434 | seaeaeeaaeaeaae \n",
            "r\\ Iteration: 1857 Loss: 1.8145625591278076 | seaeaeaaeaeaae \n",
            "r\\ Iteration: 1858 Loss: 1.91033935546875 | seeeae \n",
            "r\\ Iteration: 1859 Loss: 2.12553071975708 | seeaeaeeaeaae \n",
            "r\\ Iteration: 1860 Loss: 1.8931200504302979 | seaeeaeaeeeaaeaeaae \n",
            "r\\ Iteration: 1861 Loss: 1.851621389389038 | saeaeaeaaae \n",
            "r\\ Iteration: 1862 Loss: 1.9793424606323242 | seaaeaaeaaeae \n",
            "r\\ Iteration: 1863 Loss: 1.9044418334960938 | seaeeaeaeaae \n",
            "r\\ Iteration: 1864 Loss: 1.873384714126587 | seaeaaaaaeaae \n",
            "r\\ Iteration: 1865 Loss: 1.769862174987793 | seaeaaeaaeaaaae \n",
            "r\\ Iteration: 1866 Loss: 1.9902193546295166 | seaaaeaaraeae \n",
            "r\\ Iteration: 1867 Loss: 1.8067119121551514 | seaaeaeaeaeaeaaae \n",
            "r\\ Iteration: 1868 Loss: 1.7537775039672852 | saeeaaaeaeaae \n",
            "r\\ Iteration: 1869 Loss: 1.778374433517456 | seaeeaaaeaeaae \n",
            "r\\ Iteration: 1870 Loss: 1.8221075534820557 | seaeaaae \n",
            "r\\ Iteration: 1871 Loss: 2.0456180572509766 | seaaeaeaeaee \n",
            "r\\ Iteration: 1872 Loss: 1.8638603687286377 | seaaeaaeaeaaeaeaae \n",
            "r\\ Iteration: 1873 Loss: 1.971179723739624 | seaeaeaeaeaee \n",
            "r\\ Iteration: 1874 Loss: 1.9322617053985596 | seaeaaeaeaae \n",
            "r\\ Iteration: 1875 Loss: 1.671449899673462 | saeaeaaeaeaae \n",
            "r\\ Iteration: 1876 Loss: 1.6984498500823975 | seeaaeaaeaeaae \n",
            "r\\ Iteration: 1877 Loss: 1.7504808902740479 | soaaeaeaeaeeaae \n",
            "r\\ Iteration: 1878 Loss: 1.9300956726074219 | seaeaeaaaeaeaae \n",
            "r\\ Iteration: 1879 Loss: 1.8508739471435547 | seaeaea|eaeaae \n",
            "r\\ Iteration: 1880 Loss: 1.852391242980957 | seaeaeaeee \n",
            "r\\ Iteration: 1881 Loss: 2.173895835876465 | seaaeeaeea|eaeeaeaae \n",
            "r\\ Iteration: 1882 Loss: 1.944481611251831 | seeaeea|eaeaae \n",
            "r\\ Iteration: 1883 Loss: 1.7568562030792236 | seaeaea|eaeae \n",
            "r\\ Iteration: 1884 Loss: 1.806966781616211 | seaeaeaeaea|e \n",
            "r\\ Iteration: 1885 Loss: 1.9486262798309326 | seaeeeaeaeaeea|eaea|e \n",
            "r\\ Iteration: 1886 Loss: 1.8299829959869385 | seeaea|eaeaea|e \n",
            "r\\ Iteration: 1887 Loss: 1.8146662712097168 | soaeaea|eaea|e \n",
            "r\\ Iteration: 1888 Loss: 1.8197855949401855 | seaeeaeaeaea|ea|e \n",
            "r\\ Iteration: 1889 Loss: 2.03564453125 | soaeeeeaaeeaae \n",
            "r\\ Iteration: 1890 Loss: 2.109121561050415 | soaees|eaea|e \n",
            "r\\ Iteration: 1891 Loss: 1.8336799144744873 | soaeeaeaeea|eaea|e \n",
            "r\\ Iteration: 1892 Loss: 1.9438302516937256 | soaaeeeaees|eaea|e \n",
            "r\\ Iteration: 1893 Loss: 1.861349105834961 | seseaeaaee \n",
            "r\\ Iteration: 1894 Loss: 1.9504938125610352 | soaeaeaeaese|e \n",
            "r\\ Iteration: 1895 Loss: 1.891817331314087 | saaeeseaae \n",
            "r\\ Iteration: 1896 Loss: 1.8304574489593506 | soeseaesesee \n",
            "r\\ Iteration: 1897 Loss: 1.9973924160003662 | seaeeaes|eaeaae \n",
            "r\\ Iteration: 1898 Loss: 1.816810131072998 | seaeaesaeaeaae \n",
            "r\\ Iteration: 1899 Loss: 1.7599363327026367 | seeseeeaeseae \n",
            "r\\ Iteration: 1900 Loss: 1.9003384113311768 | seeeeeeesaeaeaae \n",
            "r\\ Iteration: 1901 Loss: 1.9598329067230225 | soseeaeaesaeaeaae \n",
            "r\\ Iteration: 1902 Loss: 1.9011256694793701 | seeeeseeaae \n",
            "r\\ Iteration: 1903 Loss: 1.832425594329834 | seeeeeaaeaeaae \n",
            "r\\ Iteration: 1904 Loss: 1.821796178817749 | seeeeaesaeaeaae \n",
            "r\\ Iteration: 1905 Loss: 1.7370858192443848 | seeeaeeseseeeeaaeeae \n",
            "r\\ Iteration: 1906 Loss: 2.0462114810943604 | seeeaeaeesee \n",
            "r\\ Iteration: 1907 Loss: 1.8459842205047607 | seeaeeeeaaeeaae \n",
            "r\\ Iteration: 1908 Loss: 1.8794853687286377 | saeeaaeseesaeaeaae \n",
            "r\\ Iteration: 1909 Loss: 1.8980262279510498 | seeaeeeaeesaeaeaae \n",
            "r\\ Iteration: 1910 Loss: 1.8625924587249756 | saeesaeesee \n",
            "r\\ Iteration: 1911 Loss: 1.8892662525177002 | seeseeeeeaeeeaae \n",
            "r\\ Iteration: 1912 Loss: 2.0276525020599365 | seaeeeeaeeeeaee \n",
            "r\\ Iteration: 1913 Loss: 2.0539634227752686 | seeeeeeaeaeaae \n",
            "r\\ Iteration: 1914 Loss: 1.7447454929351807 | seeesesaeaeaae \n",
            "r\\ Iteration: 1915 Loss: 1.814420461654663 | seeaeaeeee \n",
            "r\\ Iteration: 1916 Loss: 2.101731300354004 | seeeeaeeaaeaeaae \n",
            "r\\ Iteration: 1917 Loss: 1.7376832962036133 | seeeaaaaeeaeeae \n",
            "r\\ Iteration: 1918 Loss: 1.8992576599121094 | seeeaaeeeae \n",
            "r\\ Iteration: 1919 Loss: 2.103651285171509 | saeeeeaeaeaae \n",
            "r\\ Iteration: 1920 Loss: 1.755472183227539 | seaeeseeeaeseae \n",
            "r\\ Iteration: 1921 Loss: 1.8129627704620361 | seaeeaeaeaae \n",
            "r\\ Iteration: 1922 Loss: 1.7619147300720215 | saeeesaeaeeeeae \n",
            "r\\ Iteration: 1923 Loss: 1.888709545135498 | saeaesesee \n",
            "r\\ Iteration: 1924 Loss: 1.8499865531921387 | seseaeaeeeseeeae \n",
            "r\\ Iteration: 1925 Loss: 1.982665777206421 | saeeeeesaeaeaae \n",
            "r\\ Iteration: 1926 Loss: 1.8272604942321777 | seaeeeseseaae \n",
            "r\\ Iteration: 1927 Loss: 1.9318406581878662 | seeeeaeaeaeaae \n",
            "r\\ Iteration: 1928 Loss: 1.7947540283203125 | seaeeseeaeesaeaeaae \n",
            "r\\ Iteration: 1929 Loss: 1.7905399799346924 | seaeaeeaeeeae \n",
            "r\\ Iteration: 1930 Loss: 2.221310615539551 | seaaeaeeeaeaeaae \n",
            "r\\ Iteration: 1931 Loss: 1.8444721698760986 | seeeeeseaae \n",
            "r\\ Iteration: 1932 Loss: 1.8144490718841553 | saeeeeeseaeae \n",
            "r\\ Iteration: 1933 Loss: 2.0144898891448975 | seseeeeeeeeaee \n",
            "r\\ Iteration: 1934 Loss: 1.9599080085754395 | seeaeesaeaeaae \n",
            "r\\ Iteration: 1935 Loss: 1.734755516052246 | seaeaesaeaeaae \n",
            "r\\ Iteration: 1936 Loss: 1.798508644104004 | seaeseaaeaeaae \n",
            "r\\ Iteration: 1937 Loss: 1.6753759384155273 | seaeeseseeseeesee \n",
            "r\\ Iteration: 1938 Loss: 1.8775913715362549 | seeeeeeseaeae \n",
            "r\\ Iteration: 1939 Loss: 2.150710105895996 | saeeaeeseeseaae \n",
            "r\\ Iteration: 1940 Loss: 1.9464294910430908 | seeeeseeeaeseae \n",
            "r\\ Iteration: 1941 Loss: 1.8532650470733643 | sesaeaesaeaeaae \n",
            "r\\ Iteration: 1942 Loss: 1.8538877964019775 | seeesaaeeaae \n",
            "r\\ Iteration: 1943 Loss: 2.026487112045288 | seeeeeaeaeeesaeaeaae \n",
            "r\\ Iteration: 1944 Loss: 1.7856268882751465 | seeeaeseeeaeseae \n",
            "r\\ Iteration: 1945 Loss: 1.7164263725280762 | seeeeaeesesee \n",
            "r\\ Iteration: 1946 Loss: 2.0820319652557373 | seaeseaeesesee \n",
            "r\\ Iteration: 1947 Loss: 1.8700368404388428 | seaeaeeeseee \n",
            "r\\ Iteration: 1948 Loss: 2.0647523403167725 | seeeeeeaeaeeae \n",
            "r\\ Iteration: 1949 Loss: 1.7539937496185303 | saeaeaaeeaeeeeaae \n",
            "r\\ Iteration: 1950 Loss: 2.0701069831848145 | saeaaeeesaeaeaae \n",
            "r\\ Iteration: 1951 Loss: 1.8438720703125 | seeaeeaeaeaeae \n",
            "r\\ Iteration: 1952 Loss: 1.9684884548187256 | seeeeeaeee \n",
            "r\\ Iteration: 1953 Loss: 1.8677423000335693 | saeaeaeaaeaeaae \n",
            "r\\ Iteration: 1954 Loss: 1.8019814491271973 | seeeaaeaeaae \n",
            "r\\ Iteration: 1955 Loss: 1.8356995582580566 | seaaeaeeeaeaeae \n",
            "r\\ Iteration: 1956 Loss: 1.847428560256958 | saeeaeeeaeaeaae \n",
            "r\\ Iteration: 1957 Loss: 1.9059910774230957 | seaeeeaeeae \n",
            "r\\ Iteration: 1958 Loss: 1.8566231727600098 | saeeeaaeaeaae \n",
            "r\\ Iteration: 1959 Loss: 1.8311970233917236 | saeeeaeaaeaeaae \n",
            "r\\ Iteration: 1960 Loss: 1.8456628322601318 | seeeeeaaeaeaae \n",
            "r\\ Iteration: 1961 Loss: 1.8185069561004639 | seaaaaeeaaeaeaae \n",
            "r\\ Iteration: 1962 Loss: 1.8541624546051025 | saeeeaeeeaae \n",
            "r\\ Iteration: 1963 Loss: 1.9438161849975586 | seeeaeaeaaaeaae \n",
            "r\\ Iteration: 1964 Loss: 1.903308391571045 | seaaeeaeeaaeaeeaeaae \n",
            "r\\ Iteration: 1965 Loss: 1.919724464416504 | saeeeeeaeeaeaae \n",
            "r\\ Iteration: 1966 Loss: 1.8962955474853516 | seeaeeeaeaaaeeaae \n",
            "r\\ Iteration: 1967 Loss: 1.860424518585205 | saeeeaaaeaaaaaeaae \n",
            "r\\ Iteration: 1968 Loss: 1.896158218383789 | seaeaaaaeaae \n",
            "r\\ Iteration: 1969 Loss: 1.7477648258209229 | seaeaeeeaeaeae \n",
            "r\\ Iteration: 1970 Loss: 1.8112590312957764 | seaeaeaeaeeaeeaeaee \n",
            "r\\ Iteration: 1971 Loss: 2.01556134223938 | eeaeeaeaeaeaaae \n",
            "r\\ Iteration: 1972 Loss: 1.9488635063171387 | eaeeeaaeeaeeeaae \n",
            "r\\ Iteration: 1973 Loss: 1.8314430713653564 | eeaeeaaeaeaae \n",
            "r\\ Iteration: 1974 Loss: 1.820876121520996 | eaeaaeaeaee \n",
            "r\\ Iteration: 1975 Loss: 1.8938894271850586 | eeaaeaeeeaaaeaae \n",
            "r\\ Iteration: 1976 Loss: 1.8026044368743896 | eeeeeeaaaeaeaae \n",
            "r\\ Iteration: 1977 Loss: 1.9016897678375244 | eeaeaeeeaeaeae \n",
            "r\\ Iteration: 1978 Loss: 1.8621439933776855 | eeaeeeaaeaeaae \n",
            "r\\ Iteration: 1979 Loss: 1.758169412612915 | eeaeaeaaeaeaae \n",
            "r\\ Iteration: 1980 Loss: 1.8559014797210693 | eeaeaeaeaaeaeaae \n",
            "r\\ Iteration: 1981 Loss: 1.7541520595550537 | eeeaeeeeaeaeaae \n",
            "r\\ Iteration: 1982 Loss: 1.7548558712005615 | eeaeaeaeeaeaee \n",
            "r\\ Iteration: 1983 Loss: 1.8914072513580322 | eaaeeaeeeaee \n",
            "r\\ Iteration: 1984 Loss: 1.9625091552734375 | eeeaeaeaee \n",
            "r\\ Iteration: 1985 Loss: 1.926973581314087 | eeaeaeaaeaeae \n",
            "r\\ Iteration: 1986 Loss: 1.756591558456421 | eaaeeaeaeaee \n",
            "r\\ Iteration: 1987 Loss: 2.059922218322754 | eaaaeaeeeeeae \n",
            "r\\ Iteration: 1988 Loss: 1.7677650451660156 | eaaeaaeaeaeaeeaae \n",
            "r\\ Iteration: 1989 Loss: 1.8622655868530273 | eaeeeaeaeaae \n",
            "r\\ Iteration: 1990 Loss: 1.9145493507385254 | oeeeeaeaaeaeaae \n",
            "r\\ Iteration: 1991 Loss: 1.8444857597351074 | oeeeaeeeeeae \n",
            "r\\ Iteration: 1992 Loss: 1.928877830505371 | oeaeaeaeaeaaaeaae \n",
            "r\\ Iteration: 1993 Loss: 1.9984285831451416 | oeaaeeeaeeaaeaeaae \n",
            "r\\ Iteration: 1994 Loss: 1.870809555053711 | oaeaeaaeaeaae \n",
            "r\\ Iteration: 1995 Loss: 1.7599713802337646 | oeaeeaaeaeeaeaae \n",
            "r\\ Iteration: 1996 Loss: 2.0036308765411377 | beaeeaeeeaeaaae \n",
            "r\\ Iteration: 1997 Loss: 1.750124216079712 | baaeaaeaae \n",
            "r\\ Iteration: 1998 Loss: 1.8668901920318604 | beeaaeaaaaeaaaeeae \n",
            "r\\ Iteration: 1999 Loss: 1.9076197147369385 | beaeaeaeaaeaae \n",
            "r\\ Iteration: 2000 Loss: 1.9024946689605713 | buaeaaeaaeaeaae \n",
            "r\\ Iteration: 2001 Loss: 1.8433990478515625 | baeaeaaaeeaaeaeaae \n",
            "r\\ Iteration: 2002 Loss: 1.801729440689087 | beaeeaeeaeaeaae \n",
            "r\\ Iteration: 2003 Loss: 2.0694727897644043 | seaeaeaaeaeeaae \n",
            "r\\ Iteration: 2004 Loss: 1.8959558010101318 | suaeaeeaaaee \n",
            "r\\ Iteration: 2005 Loss: 1.893662691116333 | seeaeaeaeaeaeaaae \n",
            "r\\ Iteration: 2006 Loss: 1.7687888145446777 | saaeaeaeaeaae \n",
            "r\\ Iteration: 2007 Loss: 1.9008052349090576 | suaaeaaeaeaae \n",
            "r\\ Iteration: 2008 Loss: 1.766958236694336 | suaeeaeaae \n",
            "r\\ Iteration: 2009 Loss: 2.169234037399292 | saeeaeeaeaaaaae \n",
            "r\\ Iteration: 2010 Loss: 2.0041310787200928 | suaaeaeeaaaae \n",
            "r\\ Iteration: 2011 Loss: 1.875077486038208 | suaeeaaeaae \n",
            "r\\ Iteration: 2012 Loss: 2.0579841136932373 | suaeaaaeae \n",
            "r\\ Iteration: 2013 Loss: 1.8737387657165527 | saeeaeaeaeeeaae \n",
            "r\\ Iteration: 2014 Loss: 1.9749267101287842 | seaeeaaeaaeaeaae \n",
            "r\\ Iteration: 2015 Loss: 1.9861273765563965 | sueaeaaeaaeaeaae \n",
            "r\\ Iteration: 2016 Loss: 1.9876303672790527 | seeaa \n",
            "r\\ Iteration: 2017 Loss: 2.7536630630493164 | saaeaeaeeaaaaaeaae \n",
            "r\\ Iteration: 2018 Loss: 1.81141996383667 | seaaeaeaaaaeaae \n",
            "r\\ Iteration: 2019 Loss: 1.819103479385376 | suaaeeaaaaeaae \n",
            "r\\ Iteration: 2020 Loss: 1.7625219821929932 | saaaaaaaeaaaaeaae \n",
            "r\\ Iteration: 2021 Loss: 1.8376960754394531 | seaeeaaaeaaaaeaae \n",
            "r\\ Iteration: 2022 Loss: 1.829524278640747 | seeaeaeeeaaaaaaeaae \n",
            "r\\ Iteration: 2023 Loss: 1.9398853778839111 | seeaaeaaaeeaae \n",
            "r\\ Iteration: 2024 Loss: 1.8078527450561523 | seaaaeaaaae \n",
            "r\\ Iteration: 2025 Loss: 1.8211054801940918 | seeaaeaaaaeaae \n",
            "r\\ Iteration: 2026 Loss: 1.6916441917419434 | seeaaeaaaaeaaaeeae \n",
            "r\\ Iteration: 2027 Loss: 1.8640813827514648 | seaaaeaaeaeaaaaeaae \n",
            "r\\ Iteration: 2028 Loss: 1.893514633178711 | seeaaeaaaaeaae \n",
            "r\\ Iteration: 2029 Loss: 1.8348290920257568 | saaeeaaaaeaae \n",
            "r\\ Iteration: 2030 Loss: 1.8048431873321533 | seaaeaaaaaaaaeae \n",
            "r\\ Iteration: 2031 Loss: 1.8140778541564941 | saeeaaaaaaeaae \n",
            "r\\ Iteration: 2032 Loss: 1.7928667068481445 | saeaeaaaae \n",
            "r\\ Iteration: 2033 Loss: 1.883681297302246 | saaaeaaaaaeaae \n",
            "r\\ Iteration: 2034 Loss: 1.9148294925689697 | seaaaaaaeaa \n",
            "r\\ Iteration: 2035 Loss: 1.9098496437072754 | saeeaeeaaaaeaae \n",
            "r\\ Iteration: 2036 Loss: 1.7705519199371338 | seaeaaaaeaae \n",
            "r\\ Iteration: 2037 Loss: 1.6711235046386719 | seaaasaaeaae \n",
            "r\\ Iteration: 2038 Loss: 2.011922597885132 | seaeeaaaaaaaeaae \n",
            "r\\ Iteration: 2039 Loss: 1.7813961505889893 | seaasaaaaaaeaae \n",
            "r\\ Iteration: 2040 Loss: 1.9367446899414062 | saasaaaeaae \n",
            "r\\ Iteration: 2041 Loss: 1.757009744644165 | saaaaaaaeaae \n",
            "r\\ Iteration: 2042 Loss: 1.853559970855713 | seaaaaaaaaeaae \n",
            "r\\ Iteration: 2043 Loss: 1.954139232635498 | saaasaaaeaae \n",
            "r\\ Iteration: 2044 Loss: 1.84560227394104 | saeeaaaaaaaeaae \n",
            "r\\ Iteration: 2045 Loss: 1.863910436630249 | saaaaeaaeeaaaaeaae \n",
            "r\\ Iteration: 2046 Loss: 1.8367908000946045 | saaaaaaeaae \n",
            "r\\ Iteration: 2047 Loss: 1.7661805152893066 | seaaasaaaeaae \n",
            "r\\ Iteration: 2048 Loss: 1.826782464981079 | seaeasasaeaae \n",
            "r\\ Iteration: 2049 Loss: 1.7563295364379883 | saaaaaaaaeaae \n",
            "r\\ Iteration: 2050 Loss: 2.1141319274902344 | saaaaaeaaaaaaeaae \n",
            "r\\ Iteration: 2051 Loss: 1.8857598304748535 | seaaesaaasae \n",
            "r\\ Iteration: 2052 Loss: 1.7731993198394775 | seaeaaaaaaeaae \n",
            "r\\ Iteration: 2053 Loss: 1.8191914558410645 | seaeaaaaaeaaeaae \n",
            "r\\ Iteration: 2054 Loss: 1.7992124557495117 | seaaaaaaaaeaae \n",
            "r\\ Iteration: 2055 Loss: 1.8439967632293701 | saesaaeaaeaa \n",
            "r\\ Iteration: 2056 Loss: 1.988558053970337 | saaaaaaaaaeaae \n",
            "r\\ Iteration: 2057 Loss: 1.8099884986877441 | saaaaaaaaaeaae \n",
            "r\\ Iteration: 2058 Loss: 1.8467981815338135 | saaesaaaae \n",
            "r\\ Iteration: 2059 Loss: 1.814317226409912 | saaasaaaesaeaaaae \n",
            "r\\ Iteration: 2060 Loss: 1.8893041610717773 | saaesaaaaaaae \n",
            "r\\ Iteration: 2061 Loss: 1.9887535572052002 | seaaaeaaaaeaae \n",
            "r\\ Iteration: 2062 Loss: 1.7241439819335938 | sesaeaaaaaaeaae \n",
            "r\\ Iteration: 2063 Loss: 1.7289822101593018 | seaaaaaesaea \n",
            "r\\ Iteration: 2064 Loss: 2.071326971054077 | seaaaaeaaaaae \n",
            "r\\ Iteration: 2065 Loss: 1.9273262023925781 | saaaeaaaaeaaeaaeaae \n",
            "r\\ Iteration: 2066 Loss: 1.8389365673065186 | saaaaaaaaaaae \n",
            "r\\ Iteration: 2067 Loss: 1.9212408065795898 | seaaaaaaaaaae \n",
            "r\\ Iteration: 2068 Loss: 1.8778636455535889 | saaeaaaaaaaaaaaa \n",
            "r\\ Iteration: 2069 Loss: 1.8887441158294678 | seaaaaaaaaeaae \n",
            "r\\ Iteration: 2070 Loss: 1.7553291320800781 | seaaaaaaaaeaae \n",
            "r\\ Iteration: 2071 Loss: 1.8323259353637695 | saaaaaaaaaaaaaae \n",
            "r\\ Iteration: 2072 Loss: 1.9566781520843506 | saaaeaaaaaaaaae \n",
            "r\\ Iteration: 2073 Loss: 1.8357105255126953 | seaaaaaaaae \n",
            "r\\ Iteration: 2074 Loss: 2.0680153369903564 | seaaaaaaaae \n",
            "r\\ Iteration: 2075 Loss: 1.8864359855651855 | seaaaaaaaaeaae \n",
            "r\\ Iteration: 2076 Loss: 1.958630084991455 | seaeaaaaaaaaeaae \n",
            "r\\ Iteration: 2077 Loss: 1.909494161605835 | saeeaeeaaaaeaae \n",
            "r\\ Iteration: 2078 Loss: 1.8142757415771484 | saaaaeaaeaaaaae \n",
            "r\\ Iteration: 2079 Loss: 2.052318811416626 | seeaaaaeaeaaeaae \n",
            "r\\ Iteration: 2080 Loss: 1.7083230018615723 | seaesesaaaeaae \n",
            "r\\ Iteration: 2081 Loss: 1.8508312702178955 | seseeeaaeaeaae \n",
            "r\\ Iteration: 2082 Loss: 2.1098287105560303 | saaeaeaeaaaaaeaeaae \n",
            "r\\ Iteration: 2083 Loss: 2.061495780944824 | sraaeeaeaeaae \n",
            "r\\ Iteration: 2084 Loss: 1.927535057067871 | seaeeaaeaeaae \n",
            "r\\ Iteration: 2085 Loss: 1.7508203983306885 | seaeeaaaaeaae \n",
            "r\\ Iteration: 2086 Loss: 2.059568405151367 | seaeseaaeaeaae \n",
            "r\\ Iteration: 2087 Loss: 1.8009462356567383 | saeaesaae \n",
            "r\\ Iteration: 2088 Loss: 1.8689360618591309 | saaaaeaeaeaaaeaeaae \n",
            "r\\ Iteration: 2089 Loss: 1.8140029907226562 | seeaasasaeaeaae \n",
            "r\\ Iteration: 2090 Loss: 1.7270638942718506 | sraeasaaae \n",
            "r\\ Iteration: 2091 Loss: 2.0729117393493652 | sosaaaesaeaae \n",
            "r\\ Iteration: 2092 Loss: 1.9424560070037842 | seeaeeaeaeaesaae \n",
            "r\\ Iteration: 2093 Loss: 1.805283546447754 | soaaaaesaeaeaae \n",
            "r\\ Iteration: 2094 Loss: 1.7473182678222656 | seeaaasaesaaaeaae \n",
            "r\\ Iteration: 2095 Loss: 1.8357727527618408 | seaeeaaaaaae \n",
            "r\\ Iteration: 2096 Loss: 1.8283519744873047 | saaaaaaaeaaa \n",
            "r\\ Iteration: 2097 Loss: 2.081453800201416 | sesaesaaaeaae \n",
            "r\\ Iteration: 2098 Loss: 1.682694435119629 | seaaeaaaaeaaa \n",
            "r\\ Iteration: 2099 Loss: 2.048234224319458 | seaaaaaeaaaeaasaaa \n",
            "r\\ Iteration: 2100 Loss: 1.8360676765441895 | seaeaaaaaaaaaa \n",
            "r\\ Iteration: 2101 Loss: 1.7191119194030762 | saaaaaaaesaae \n",
            "r\\ Iteration: 2102 Loss: 2.2003908157348633 | saaaaaaaaaa \n",
            "r\\ Iteration: 2103 Loss: 1.9304111003875732 | seaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2104 Loss: 1.812488079071045 | saaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2105 Loss: 1.8546342849731445 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2106 Loss: 1.7568926811218262 | seaaaaaaaaaaaa \n",
            "r\\ Iteration: 2107 Loss: 1.7285966873168945 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2108 Loss: 1.8341877460479736 | seaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2109 Loss: 1.9444050788879395 | seaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2110 Loss: 1.9402620792388916 | saaaeaaaaa \n",
            "r\\ Iteration: 2111 Loss: 1.9395618438720703 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 2112 Loss: 1.8392994403839111 | saaaaaa \n",
            "r\\ Iteration: 2113 Loss: 1.977247953414917 | seeaaaaaaaaaa \n",
            "r\\ Iteration: 2114 Loss: 1.9536125659942627 | saaaaaaaaa \n",
            "r\\ Iteration: 2115 Loss: 1.9397571086883545 | sooaaaaaaaa \n",
            "r\\ Iteration: 2116 Loss: 2.1831154823303223 | saesaaaaaa \n",
            "r\\ Iteration: 2117 Loss: 1.8312177658081055 | soesaaaaaaaaaaa \n",
            "r\\ Iteration: 2118 Loss: 1.6751952171325684 | soaaaaaa \n",
            "r\\ Iteration: 2119 Loss: 1.8247456550598145 | soaaaaaaaa \n",
            "r\\ Iteration: 2120 Loss: 2.216204881668091 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2121 Loss: 1.8217945098876953 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2122 Loss: 1.8553504943847656 | saoaaaaaaaaa \n",
            "r\\ Iteration: 2123 Loss: 1.9136924743652344 | soaaaaaaaaaaaa \n",
            "r\\ Iteration: 2124 Loss: 1.711470603942871 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2125 Loss: 1.866830825805664 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2126 Loss: 1.8235328197479248 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2127 Loss: 1.846095323562622 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2128 Loss: 1.793402910232544 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2129 Loss: 1.8233449459075928 | soaaaaaaaauaaaa \n",
            "r\\ Iteration: 2130 Loss: 2.0449295043945312 | sooaaaaaaaauaaaaa \n",
            "r\\ Iteration: 2131 Loss: 1.9325644969940186 | soaaaaaaaa \n",
            "r\\ Iteration: 2132 Loss: 1.9712612628936768 | soaaaaaaaaauauaaa \n",
            "r\\ Iteration: 2133 Loss: 1.9153311252593994 | sooaoaaauauaau \n",
            "r\\ Iteration: 2134 Loss: 1.8216931819915771 | sooaaaaaaaauauaau \n",
            "r\\ Iteration: 2135 Loss: 1.7980737686157227 | soaoaaaauauaau \n",
            "r\\ Iteration: 2136 Loss: 1.7751808166503906 | sosoaaaauauaau \n",
            "r\\ Iteration: 2137 Loss: 1.8032190799713135 | sosaasauauaau \n",
            "r\\ Iteration: 2138 Loss: 1.8069000244140625 | sooaauaaaauaau \n",
            "r\\ Iteration: 2139 Loss: 1.858795166015625 | soooaasaaaasauauaau \n",
            "r\\ Iteration: 2140 Loss: 1.8173885345458984 | sosooaaaaaa \n",
            "r\\ Iteration: 2141 Loss: 1.843421220779419 | saaausaaaausaaaaaau \n",
            "r\\ Iteration: 2142 Loss: 1.8694806098937988 | soosauauaau \n",
            "r\\ Iteration: 2143 Loss: 1.6741862297058105 | sooooaaaaaasaau \n",
            "r\\ Iteration: 2144 Loss: 1.9171311855316162 | sosaaaaasauauaau \n",
            "r\\ Iteration: 2145 Loss: 1.8070108890533447 | sooaaaaaaaaasaa \n",
            "r\\ Iteration: 2146 Loss: 1.8851618766784668 | soaaaaasauauaau \n",
            "r\\ Iteration: 2147 Loss: 1.80739426612854 | sosaauasauauaaa \n",
            "r\\ Iteration: 2148 Loss: 1.8420989513397217 | soaauaaaaasaa \n",
            "r\\ Iteration: 2149 Loss: 1.8415918350219727 | sosaaaaaaaaaaaa \n",
            "r\\ Iteration: 2150 Loss: 1.886162281036377 | soasausaaaaasaaa \n",
            "r\\ Iteration: 2151 Loss: 1.8255572319030762 | sosaaaaa \n",
            "r\\ Iteration: 2152 Loss: 2.283115863800049 | soaaasasaaauaaa \n",
            "r\\ Iteration: 2153 Loss: 1.7546327114105225 | soaaaasaaauaaa \n",
            "r\\ Iteration: 2154 Loss: 1.7609469890594482 | soaaaa \n",
            "r\\ Iteration: 2155 Loss: 2.0149331092834473 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2156 Loss: 1.7331571578979492 | saasaaasaas|aaaaaa \n",
            "r\\ Iteration: 2157 Loss: 1.7153174877166748 | saaaaaa|aaaa|a \n",
            "r\\ Iteration: 2158 Loss: 1.7598354816436768 | saaaaaa|aaaa|a \n",
            "r\\ Iteration: 2159 Loss: 1.6735987663269043 | soaaaa|aaaa|a \n",
            "r\\ Iteration: 2160 Loss: 1.7732594013214111 | soa|aaaaaaa \n",
            "r\\ Iteration: 2161 Loss: 1.8801796436309814 | soaaaa|aaaa|a \n",
            "r\\ Iteration: 2162 Loss: 1.772625207901001 | saaaa|aaaa|a \n",
            "r\\ Iteration: 2163 Loss: 1.8140556812286377 | soaaaaaaa|aaaa|a \n",
            "r\\ Iteration: 2164 Loss: 1.7979910373687744 | saaaaa|aaaa|a \n",
            "r\\ Iteration: 2165 Loss: 1.7958805561065674 | saaaaa \n",
            "r\\ Iteration: 2166 Loss: 2.1215717792510986 | saaaaaa \n",
            "r\\ Iteration: 2167 Loss: 1.9919555187225342 | soaaaaaa|aaaa|a \n",
            "r\\ Iteration: 2168 Loss: 1.793229341506958 | saaaaaaaaaaa|a \n",
            "r\\ Iteration: 2169 Loss: 1.9576022624969482 | suaaaa|aaaaa|a \n",
            "r\\ Iteration: 2170 Loss: 2.024021625518799 | saaaa|uaaa|u \n",
            "r\\ Iteration: 2171 Loss: 1.8077797889709473 | suaaaauauaaa|uaua|u \n",
            "r\\ Iteration: 2172 Loss: 1.927551031112671 | suaauaua|uaua|u \n",
            "r\\ Iteration: 2173 Loss: 1.9730103015899658 | suaaua|uaua|u \n",
            "r\\ Iteration: 2174 Loss: 1.8215057849884033 | souaaauaaaaaa \n",
            "r\\ Iteration: 2175 Loss: 1.8720760345458984 | soauaaaaaaau \n",
            "r\\ Iteration: 2176 Loss: 2.088336944580078 | saaaa|uaa|a|u \n",
            "r\\ Iteration: 2177 Loss: 1.811798334121704 | saauauauaau \n",
            "r\\ Iteration: 2178 Loss: 1.8416152000427246 | sos|uaa|uauaau \n",
            "r\\ Iteration: 2179 Loss: 1.6689491271972656 | sasaua|uauaau \n",
            "r\\ Iteration: 2180 Loss: 1.7517223358154297 | saaaususauaau \n",
            "r\\ Iteration: 2181 Loss: 1.691659927368164 | sooa|auauauauaaaa \n",
            "r\\ Iteration: 2182 Loss: 2.087296724319458 | soauaas|uauaau \n",
            "r\\ Iteration: 2183 Loss: 1.7687673568725586 | sosauusauaaaau \n",
            "r\\ Iteration: 2184 Loss: 1.913543701171875 | sooousuauaau \n",
            "r\\ Iteration: 2185 Loss: 1.9585669040679932 | sosausa \n",
            "r\\ Iteration: 2186 Loss: 2.0383808612823486 | sousosauauaau \n",
            "r\\ Iteration: 2187 Loss: 1.7588670253753662 | sosaaaaaauauaau \n",
            "r\\ Iteration: 2188 Loss: 1.8003921508789062 | sosuusaauauaau \n",
            "r\\ Iteration: 2189 Loss: 1.8197979927062988 | sosusausuaau \n",
            "r\\ Iteration: 2190 Loss: 1.739894151687622 | soausauausau \n",
            "r\\ Iteration: 2191 Loss: 1.943472146987915 | soasasusauausau \n",
            "r\\ Iteration: 2192 Loss: 1.7172954082489014 | sosasaasuausaau \n",
            "r\\ Iteration: 2193 Loss: 1.8445720672607422 | sosasaasausaaau \n",
            "r\\ Iteration: 2194 Loss: 1.9453492164611816 | sososasasasa \n",
            "r\\ Iteration: 2195 Loss: 2.123809814453125 | sasaasaaausau \n",
            "r\\ Iteration: 2196 Loss: 1.8527824878692627 | soasaaasaasauausau \n",
            "r\\ Iteration: 2197 Loss: 1.7622203826904297 | sosauaaaaausaau \n",
            "r\\ Iteration: 2198 Loss: 1.7836341857910156 | sosasasrsaa \n",
            "r\\ Iteration: 2199 Loss: 1.949920654296875 | soaaasasaaaaasaau \n",
            "r\\ Iteration: 2200 Loss: 1.7671184539794922 | soossasauauaru \n",
            "r\\ Iteration: 2201 Loss: 1.8306169509887695 | sosraraarauaaraa \n",
            "r\\ Iteration: 2202 Loss: 2.049898862838745 | sosuaaurasau \n",
            "r\\ Iteration: 2203 Loss: 2.028225898742676 | sasararaaasarrarau \n",
            "r\\ Iteration: 2204 Loss: 1.9646131992340088 | sosarararrrru \n",
            "r\\ Iteration: 2205 Loss: 1.8093245029449463 | soararsrrrrrau \n",
            "r\\ Iteration: 2206 Loss: 1.999962329864502 | sosarararra \n",
            "r\\ Iteration: 2207 Loss: 1.9869823455810547 | sourarrrrar \n",
            "r\\ Iteration: 2208 Loss: 1.8210468292236328 | sarararrrrrr \n",
            "r\\ Iteration: 2209 Loss: 1.6568078994750977 | soarrararr \n",
            "r\\ Iteration: 2210 Loss: 2.0378944873809814 | sarrrarrrarrr \n",
            "r\\ Iteration: 2211 Loss: 1.9040145874023438 | sraararrrrrrrr \n",
            "r\\ Iteration: 2212 Loss: 1.9999949932098389 | soaararrrrrr \n",
            "r\\ Iteration: 2213 Loss: 2.005107879638672 | soarrarrrrrrrrr \n",
            "r\\ Iteration: 2214 Loss: 1.8703877925872803 | saraorrrrrr \n",
            "r\\ Iteration: 2215 Loss: 1.9563117027282715 | soororrararrrrrr \n",
            "r\\ Iteration: 2216 Loss: 1.787200689315796 | soarrrarrrrar \n",
            "r\\ Iteration: 2217 Loss: 1.9271364212036133 | soarrrrrrrrrrr \n",
            "r\\ Iteration: 2218 Loss: 1.929389476776123 | sorarrrrrr \n",
            "r\\ Iteration: 2219 Loss: 1.894385576248169 | soarrrrrrarr \n",
            "r\\ Iteration: 2220 Loss: 1.973752737045288 | sorarrarrarrrrrr \n",
            "r\\ Iteration: 2221 Loss: 2.035754442214966 | soarrrrarrrrrrrr \n",
            "r\\ Iteration: 2222 Loss: 1.9056212902069092 | saorarrarrrrrr \n",
            "r\\ Iteration: 2223 Loss: 2.073472261428833 | soararrrrrr \n",
            "r\\ Iteration: 2224 Loss: 1.8127644062042236 | sorrrrrrrrrr \n",
            "r\\ Iteration: 2225 Loss: 1.7950546741485596 | soarrrarrrrrrrrr \n",
            "r\\ Iteration: 2226 Loss: 1.8861160278320312 | soarrrrrrrrr \n",
            "r\\ Iteration: 2227 Loss: 1.8733198642730713 | soaarrrrrrrr \n",
            "r\\ Iteration: 2228 Loss: 1.717813491821289 | sorrrrrrrrrr \n",
            "r\\ Iteration: 2229 Loss: 1.6148076057434082 | soarrrarrrrrr \n",
            "r\\ Iteration: 2230 Loss: 1.837097406387329 | soarrrarrrrrr \n",
            "r\\ Iteration: 2231 Loss: 1.8339159488677979 | sorarararrrrrr \n",
            "r\\ Iteration: 2232 Loss: 1.6267988681793213 | soraaarrrrrrrrr \n",
            "r\\ Iteration: 2233 Loss: 1.750732183456421 | sararrarrrrrr \n",
            "r\\ Iteration: 2234 Loss: 1.7009353637695312 | sroorrarrararra \n",
            "r\\ Iteration: 2235 Loss: 1.8556866645812988 | soararrarar \n",
            "r\\ Iteration: 2236 Loss: 2.050128936767578 | soarrrrarrarrrrrr \n",
            "r\\ Iteration: 2237 Loss: 1.7524833679199219 | saorarararrrrrr \n",
            "r\\ Iteration: 2238 Loss: 1.90995192527771 | soorarararrrrrr \n",
            "r\\ Iteration: 2239 Loss: 1.6188647747039795 | soaarara \n",
            "r\\ Iteration: 2240 Loss: 1.9513516426086426 | saarrararar \n",
            "r\\ Iteration: 2241 Loss: 2.0566186904907227 | soaararaaaarar \n",
            "r\\ Iteration: 2242 Loss: 1.7918424606323242 | soaarrraararrarrr \n",
            "r\\ Iteration: 2243 Loss: 1.9031271934509277 | sorarararrrrarr \n",
            "r\\ Iteration: 2244 Loss: 1.9498705863952637 | sorrrararrarrrrrrr \n",
            "r\\ Iteration: 2245 Loss: 1.845844030380249 | sosaaarrrrarrrr \n",
            "r\\ Iteration: 2246 Loss: 1.8481154441833496 | sosarrarrrrrr \n",
            "r\\ Iteration: 2247 Loss: 1.8678381443023682 | sosaarrrrrrrr \n",
            "r\\ Iteration: 2248 Loss: 1.8485994338989258 | saoarrrrrrrrr \n",
            "r\\ Iteration: 2249 Loss: 1.7542388439178467 | sorrrarrrrrrrrr \n",
            "r\\ Iteration: 2250 Loss: 1.7547621726989746 | soarrsrrrrrrr \n",
            "r\\ Iteration: 2251 Loss: 1.7852962017059326 | saarrrrrrrrrr \n",
            "r\\ Iteration: 2252 Loss: 1.8419177532196045 | srarrrrrrrrr \n",
            "r\\ Iteration: 2253 Loss: 1.6990580558776855 | saraarrrarrar \n",
            "r\\ Iteration: 2254 Loss: 1.836059808731079 | soarrrrarrrrrrrrrrr \n",
            "r\\ Iteration: 2255 Loss: 1.8687160015106201 | sorararrararrarrr \n",
            "r\\ Iteration: 2256 Loss: 1.8827903270721436 | sorrrrrrar \n",
            "r\\ Iteration: 2257 Loss: 1.9673006534576416 | soaararrrrrrrr \n",
            "r\\ Iteration: 2258 Loss: 1.721632957458496 | srararrrarrrr \n",
            "r\\ Iteration: 2259 Loss: 1.7603347301483154 | srarrrrarrrr \n",
            "r\\ Iteration: 2260 Loss: 1.992948293685913 | sorrarraarrr \n",
            "r\\ Iteration: 2261 Loss: 1.9396827220916748 | soaarrrrararrarrr \n",
            "r\\ Iteration: 2262 Loss: 1.9062538146972656 | soaarrarrrrrrrrr \n",
            "r\\ Iteration: 2263 Loss: 1.835632085800171 | soarrrrarrrrarrarrr \n",
            "r\\ Iteration: 2264 Loss: 1.9592199325561523 | soaaararrrrrrrr \n",
            "r\\ Iteration: 2265 Loss: 1.7680981159210205 | soarrrarrrrrrrr \n",
            "r\\ Iteration: 2266 Loss: 1.7480692863464355 | saarrrrar \n",
            "r\\ Iteration: 2267 Loss: 2.0392508506774902 | soorrrrrrrrrrrrrr \n",
            "r\\ Iteration: 2268 Loss: 1.7581181526184082 | srrrrrr \n",
            "r\\ Iteration: 2269 Loss: 1.9404280185699463 | soararararrrarr \n",
            "r\\ Iteration: 2270 Loss: 1.7637486457824707 | sorrarrrrrrr \n",
            "r\\ Iteration: 2271 Loss: 1.7417516708374023 | sorararrrrrrrr \n",
            "r\\ Iteration: 2272 Loss: 1.8450944423675537 | soaraarrrrrrrrrr \n",
            "r\\ Iteration: 2273 Loss: 1.9950528144836426 | soarrrrrrrrrrrrrrrr \n",
            "r\\ Iteration: 2274 Loss: 1.84956955909729 | soaarraarrrrrrrr \n",
            "r\\ Iteration: 2275 Loss: 1.9531755447387695 | soarr \n",
            "r\\ Iteration: 2276 Loss: 2.7049202919006348 | saraarrrrrrrr \n",
            "r\\ Iteration: 2277 Loss: 1.7580375671386719 | soaarrrrrrrrrr \n",
            "r\\ Iteration: 2278 Loss: 1.6930758953094482 | soarrrrrrrrrrrr \n",
            "r\\ Iteration: 2279 Loss: 1.8342876434326172 | soaarrrrrrrrrr \n",
            "r\\ Iteration: 2280 Loss: 1.7044243812561035 | soorrarrrrrrrrrrr \n",
            "r\\ Iteration: 2281 Loss: 1.7750179767608643 | soaaaarararrrrrr \n",
            "r\\ Iteration: 2282 Loss: 1.9274890422821045 | sarrrrrrrrr \n",
            "r\\ Iteration: 2283 Loss: 2.0905048847198486 | soarrrrrrrrrr \n",
            "r\\ Iteration: 2284 Loss: 1.835458755493164 | soaarrrrrrrrrrrr \n",
            "r\\ Iteration: 2285 Loss: 1.8232595920562744 | soararrrrrrrrr \n",
            "r\\ Iteration: 2286 Loss: 1.7027904987335205 | soarrrrrrrr \n",
            "r\\ Iteration: 2287 Loss: 1.7736289501190186 | saarrrrrrrrr \n",
            "r\\ Iteration: 2288 Loss: 1.8603408336639404 | sorrrrarrrrrarr \n",
            "r\\ Iteration: 2289 Loss: 1.891852617263794 | sarrrarrararrrrrarr \n",
            "r\\ Iteration: 2290 Loss: 1.8560869693756104 | soorrarrrrrrrrrrr \n",
            "r\\ Iteration: 2291 Loss: 1.7618134021759033 | soararrraarr \n",
            "r\\ Iteration: 2292 Loss: 1.9997003078460693 | soaarrrrrrrrrr \n",
            "r\\ Iteration: 2293 Loss: 1.7788481712341309 | soarrararrr \n",
            "r\\ Iteration: 2294 Loss: 1.9261260032653809 | soaararrrrarr \n",
            "r\\ Iteration: 2295 Loss: 2.1436545848846436 | soaaarararrrrrrrr \n",
            "r\\ Iteration: 2296 Loss: 1.8378243446350098 | sraaarrrrarrarrar \n",
            "r\\ Iteration: 2297 Loss: 2.186631441116333 | soaaarrr \n",
            "r\\ Iteration: 2298 Loss: 1.8709616661071777 | sooaarrrrrrrrr \n",
            "r\\ Iteration: 2299 Loss: 1.65771484375 | soaarrrarrarrr \n",
            "r\\ Iteration: 2300 Loss: 1.9836862087249756 | soraarrrrrrrr \n",
            "r\\ Iteration: 2301 Loss: 1.7640495300292969 | soaarrrrrrrrrr \n",
            "r\\ Iteration: 2302 Loss: 1.6682112216949463 | sararraaarrar \n",
            "r\\ Iteration: 2303 Loss: 1.7608060836791992 | saoarrrrra \n",
            "r\\ Iteration: 2304 Loss: 2.115103244781494 | soaoaraarrarrrrrr \n",
            "r\\ Iteration: 2305 Loss: 1.810974359512329 | soaarraarrrarrrr \n",
            "r\\ Iteration: 2306 Loss: 1.9179906845092773 | sosaraarrrrrrrr \n",
            "r\\ Iteration: 2307 Loss: 1.8347761631011963 | soaaarrrarrrrrrrrr \n",
            "r\\ Iteration: 2308 Loss: 1.7327990531921387 | sooaarrrar \n",
            "r\\ Iteration: 2309 Loss: 2.0335299968719482 | soaaararrrrrr \n",
            "r\\ Iteration: 2310 Loss: 1.9042043685913086 | srarrrrrrrrrrr \n",
            "r\\ Iteration: 2311 Loss: 1.729095458984375 | soarrrarrrrraar \n",
            "r\\ Iteration: 2312 Loss: 1.8205721378326416 | sraarrrarrrrr \n",
            "r\\ Iteration: 2313 Loss: 1.9364092350006104 | sosarrrrraarrrr \n",
            "r\\ Iteration: 2314 Loss: 1.914552927017212 | soarrararrarrrrrrr \n",
            "r\\ Iteration: 2315 Loss: 1.8680455684661865 | soarrrarrar \n",
            "r\\ Iteration: 2316 Loss: 1.8720934391021729 | srarrrrrrrrrrarr \n",
            "r\\ Iteration: 2317 Loss: 1.9469380378723145 | sosarrarrrrrrr \n",
            "r\\ Iteration: 2318 Loss: 1.9111356735229492 | soarrrrrrarrr \n",
            "r\\ Iteration: 2319 Loss: 1.9400584697723389 | soarrararrarrrrrrr \n",
            "r\\ Iteration: 2320 Loss: 1.8591458797454834 | sosrarrrrrrrrr \n",
            "r\\ Iteration: 2321 Loss: 1.7213869094848633 | sosarararrraar \n",
            "r\\ Iteration: 2322 Loss: 1.8727312088012695 | soaaaarrrrrrr \n",
            "r\\ Iteration: 2323 Loss: 1.700516939163208 | soarrrarrrrrrrrr \n",
            "r\\ Iteration: 2324 Loss: 1.8226678371429443 | sosaaraaara \n",
            "r\\ Iteration: 2325 Loss: 2.100010395050049 | sooraaaaarrrrrrrr \n",
            "r\\ Iteration: 2326 Loss: 1.80550217628479 | soararrarrrr \n",
            "r\\ Iteration: 2327 Loss: 1.863245964050293 | sraararrarrrrrrrr \n",
            "r\\ Iteration: 2328 Loss: 1.8874225616455078 | sosarrarrrrrrrr \n",
            "r\\ Iteration: 2329 Loss: 1.7021396160125732 | srarrrraaarara \n",
            "r\\ Iteration: 2330 Loss: 1.871910572052002 | sosrarrrrrrrrr \n",
            "r\\ Iteration: 2331 Loss: 1.6973085403442383 | soarrarrrrrrarr \n",
            "r\\ Iteration: 2332 Loss: 1.924870252609253 | soarrrrarrrrr \n",
            "r\\ Iteration: 2333 Loss: 1.8671865463256836 | soaararrrrrrrrr \n",
            "r\\ Iteration: 2334 Loss: 1.7475879192352295 | soaarrarrarararr \n",
            "r\\ Iteration: 2335 Loss: 1.8017611503601074 | sosrrrrrrrrrrr \n",
            "r\\ Iteration: 2336 Loss: 1.624666452407837 | soararrrraarr \n",
            "r\\ Iteration: 2337 Loss: 1.830857276916504 | sraararararrrarrrr \n",
            "r\\ Iteration: 2338 Loss: 1.8603808879852295 | srarrrrrrararr \n",
            "r\\ Iteration: 2339 Loss: 1.679102897644043 | soarrarrrrararr \n",
            "r\\ Iteration: 2340 Loss: 1.8743433952331543 | srarrarararrrararr \n",
            "r\\ Iteration: 2341 Loss: 1.815054178237915 | soarararrrrararr \n",
            "r\\ Iteration: 2342 Loss: 1.8689534664154053 | soarrararararr \n",
            "r\\ Iteration: 2343 Loss: 1.7891755104064941 | soararrararr \n",
            "r\\ Iteration: 2344 Loss: 2.112118721008301 | soarararrara \n",
            "r\\ Iteration: 2345 Loss: 2.0229995250701904 | soarrararrarrararr \n",
            "r\\ Iteration: 2346 Loss: 1.8435986042022705 | soorrrrararararr \n",
            "r\\ Iteration: 2347 Loss: 1.8918135166168213 | soarararr \n",
            "r\\ Iteration: 2348 Loss: 1.8299527168273926 | sraarararararr \n",
            "r\\ Iteration: 2349 Loss: 1.8437070846557617 | sooaarrrrararrarararr \n",
            "r\\ Iteration: 2350 Loss: 1.8267159461975098 | soarrarrrrraar \n",
            "r\\ Iteration: 2351 Loss: 1.7944886684417725 | soararrarararr \n",
            "r\\ Iteration: 2352 Loss: 1.8275060653686523 | soarrrararararr \n",
            "r\\ Iteration: 2353 Loss: 1.727241039276123 | soaaarrarararr \n",
            "r\\ Iteration: 2354 Loss: 1.864670991897583 | saararararr \n",
            "r\\ Iteration: 2355 Loss: 1.7057082653045654 | soaaarrrarrarararr \n",
            "r\\ Iteration: 2356 Loss: 1.755152702331543 | soararrarararr \n",
            "r\\ Iteration: 2357 Loss: 1.7018601894378662 | soaaaaa \n",
            "r\\ Iteration: 2358 Loss: 2.021354913711548 | sooaaoaararrrrraar \n",
            "r\\ Iteration: 2359 Loss: 1.906470775604248 | soararararar \n",
            "r\\ Iteration: 2360 Loss: 2.0881919860839844 | soaraaararrararr \n",
            "r\\ Iteration: 2361 Loss: 1.8113694190979004 | soaaararararr \n",
            "r\\ Iteration: 2362 Loss: 1.7556912899017334 | soaaararar \n",
            "r\\ Iteration: 2363 Loss: 2.083857297897339 | saaaararrarraar \n",
            "r\\ Iteration: 2364 Loss: 1.690868854522705 | saorraaarrarararr \n",
            "r\\ Iteration: 2365 Loss: 1.8359739780426025 | sroaaraarrrr \n",
            "r\\ Iteration: 2366 Loss: 1.9227304458618164 | soaraaaararar \n",
            "r\\ Iteration: 2367 Loss: 1.9347403049468994 | saoaarraararrr \n",
            "r\\ Iteration: 2368 Loss: 1.8051671981811523 | soaaarrararararr \n",
            "r\\ Iteration: 2369 Loss: 1.749290943145752 | soaaaaaarararr \n",
            "r\\ Iteration: 2370 Loss: 1.7747540473937988 | soaaaaaaaoraar \n",
            "r\\ Iteration: 2371 Loss: 1.8599536418914795 | soaaoararraraarra \n",
            "r\\ Iteration: 2372 Loss: 1.9392132759094238 | soaaaorarar \n",
            "r\\ Iteration: 2373 Loss: 1.7757611274719238 | soarrararaar \n",
            "r\\ Iteration: 2374 Loss: 1.873967170715332 | soaaaaaoraar \n",
            "r\\ Iteration: 2375 Loss: 1.7501757144927979 | saaorararaar \n",
            "r\\ Iteration: 2376 Loss: 1.7930266857147217 | soaaaarararaar \n",
            "r\\ Iteration: 2377 Loss: 1.6288678646087646 | soaarararaar \n",
            "r\\ Iteration: 2378 Loss: 1.6923608779907227 | sooaaoaararraaaaar \n",
            "r\\ Iteration: 2379 Loss: 2.0314574241638184 | sooaraararrarraaraar \n",
            "r\\ Iteration: 2380 Loss: 1.8790836334228516 | soaooaraaar \n",
            "r\\ Iteration: 2381 Loss: 1.9809653759002686 | soaaarooaaa \n",
            "r\\ Iteration: 2382 Loss: 2.0765280723571777 | sraaarraaaaaaaa \n",
            "r\\ Iteration: 2383 Loss: 1.946143388748169 | soaoaaoarararaar \n",
            "r\\ Iteration: 2384 Loss: 1.8855373859405518 | sraaaorararaar \n",
            "r\\ Iteration: 2385 Loss: 1.6506831645965576 | soaaraaaoaaaa \n",
            "r\\ Iteration: 2386 Loss: 2.033515691757202 | soaoaaaaaa \n",
            "r\\ Iteration: 2387 Loss: 1.9734671115875244 | soaoaoaaaaararaaa \n",
            "r\\ Iteration: 2388 Loss: 1.7623767852783203 | soaooaoaoaao \n",
            "r\\ Iteration: 2389 Loss: 1.9529221057891846 | saoaoaaaaoaaar \n",
            "r\\ Iteration: 2390 Loss: 1.982452630996704 | sraroaararaar \n",
            "r\\ Iteration: 2391 Loss: 1.8520910739898682 | sraorarrarararaar \n",
            "r\\ Iteration: 2392 Loss: 1.8785243034362793 | saoaaaraararaa \n",
            "r\\ Iteration: 2393 Loss: 2.025052070617676 | sararrarara|r \n",
            "r\\ Iteration: 2394 Loss: 1.6716556549072266 | saaaaaurr|rrrr|r \n",
            "r\\ Iteration: 2395 Loss: 1.7874455451965332 | saaoararaara \n",
            "r\\ Iteration: 2396 Loss: 2.1389315128326416 | soaarrrararaar \n",
            "r\\ Iteration: 2397 Loss: 1.7019453048706055 | saararrraar \n",
            "r\\ Iteration: 2398 Loss: 1.8636443614959717 | srararararaar \n",
            "r\\ Iteration: 2399 Loss: 1.7022037506103516 | saaraaaaaararaar \n",
            "r\\ Iteration: 2400 Loss: 1.7726786136627197 | soaarararararaar \n",
            "r\\ Iteration: 2401 Loss: 1.6952283382415771 | sararrararaar \n",
            "r\\ Iteration: 2402 Loss: 1.763322114944458 | srararaaraaar \n",
            "r\\ Iteration: 2403 Loss: 1.8210465908050537 | soararaar \n",
            "r\\ Iteration: 2404 Loss: 1.9693474769592285 | soasaaaaaar \n",
            "r\\ Iteration: 2405 Loss: 2.002384662628174 | soaraaaaararaar \n",
            "r\\ Iteration: 2406 Loss: 1.8458952903747559 | saraarraaaaraar \n",
            "r\\ Iteration: 2407 Loss: 2.0398337841033936 | saaaaraaaaaararaar \n",
            "r\\ Iteration: 2408 Loss: 1.8923892974853516 | saaaaararaar \n",
            "r\\ Iteration: 2409 Loss: 1.6304025650024414 | srasaaasararaar \n",
            "r\\ Iteration: 2410 Loss: 1.6486093997955322 | sosasaaa \n",
            "r\\ Iteration: 2411 Loss: 1.9335424900054932 | soaarararaa \n",
            "r\\ Iteration: 2412 Loss: 1.784172773361206 | soarraaaaara \n",
            "r\\ Iteration: 2413 Loss: 1.9676618576049805 | saaaaaaaararaar \n",
            "r\\ Iteration: 2414 Loss: 1.8388779163360596 | sraaraaaararaar \n",
            "r\\ Iteration: 2415 Loss: 1.7890279293060303 | saaoaarararaar \n",
            "r\\ Iteration: 2416 Loss: 1.7683155536651611 | sosarararaar \n",
            "r\\ Iteration: 2417 Loss: 1.6153490543365479 | sosaraaarrarararaar \n",
            "r\\ Iteration: 2418 Loss: 1.8051469326019287 | sosararararrrararaar \n",
            "r\\ Iteration: 2419 Loss: 1.789536952972412 | saoararaarararaar \n",
            "r\\ Iteration: 2420 Loss: 1.7633697986602783 | srarraaraara \n",
            "r\\ Iteration: 2421 Loss: 1.9306907653808594 | sraaas|raraar \n",
            "r\\ Iteration: 2422 Loss: 1.7917051315307617 | sararrarraraar \n",
            "r\\ Iteration: 2423 Loss: 1.8273451328277588 | soaaarraraa \n",
            "r\\ Iteration: 2424 Loss: 1.9488916397094727 | sosaaaararara \n",
            "r\\ Iteration: 2425 Loss: 1.9161241054534912 | soaaaaarrarararaar \n",
            "r\\ Iteration: 2426 Loss: 1.8641185760498047 | sosarararraaa \n",
            "r\\ Iteration: 2427 Loss: 1.949920892715454 | sraaaaararaar \n",
            "r\\ Iteration: 2428 Loss: 1.6999740600585938 | srrrraaaaara \n",
            "r\\ Iteration: 2429 Loss: 1.936704397201538 | srsaarraaraaa \n",
            "r\\ Iteration: 2430 Loss: 2.017578363418579 | sraaarraaaraar \n",
            "r\\ Iteration: 2431 Loss: 1.846297025680542 | sraararaarraa \n",
            "r\\ Iteration: 2432 Loss: 1.7873468399047852 | sraaaaararaaa \n",
            "r\\ Iteration: 2433 Loss: 2.0904605388641357 | srarrarararaar \n",
            "r\\ Iteration: 2434 Loss: 1.7116541862487793 | srarararaarraa \n",
            "r\\ Iteration: 2435 Loss: 1.9015493392944336 | srrarararraa \n",
            "r\\ Iteration: 2436 Loss: 1.8315153121948242 | sraaaaarrara \n",
            "r\\ Iteration: 2437 Loss: 1.8471906185150146 | saaaaaararaar \n",
            "r\\ Iteration: 2438 Loss: 1.9085922241210938 | soaaaaaaarararaar \n",
            "r\\ Iteration: 2439 Loss: 1.7706389427185059 | saaaaraaaaaar \n",
            "r\\ Iteration: 2440 Loss: 1.9237053394317627 | saaaraaararaar \n",
            "r\\ Iteration: 2441 Loss: 1.7025914192199707 | sraaaaaaraa \n",
            "r\\ Iteration: 2442 Loss: 1.7738149166107178 | saaaaaraarararaar \n",
            "r\\ Iteration: 2443 Loss: 1.7982001304626465 | soaaraarar \n",
            "r\\ Iteration: 2444 Loss: 2.099651336669922 | saararaararaar \n",
            "r\\ Iteration: 2445 Loss: 1.7551846504211426 | saaaarararaar \n",
            "r\\ Iteration: 2446 Loss: 1.6963536739349365 | soaaraaaaararaar \n",
            "r\\ Iteration: 2447 Loss: 1.8566629886627197 | sraraarraaraaar \n",
            "r\\ Iteration: 2448 Loss: 1.8507821559906006 | soarraar \n",
            "r\\ Iteration: 2449 Loss: 1.9602453708648682 | soaaararaaraaaaaa \n",
            "r\\ Iteration: 2450 Loss: 1.866701364517212 | soaaaaaaaara \n",
            "r\\ Iteration: 2451 Loss: 1.9644358158111572 | soaaararararaar \n",
            "r\\ Iteration: 2452 Loss: 1.82142972946167 | sraraaaararaar \n",
            "r\\ Iteration: 2453 Loss: 1.7513318061828613 | soaarraraar \n",
            "r\\ Iteration: 2454 Loss: 1.665264368057251 | soaaraaaaaaaaar \n",
            "r\\ Iteration: 2455 Loss: 1.9600732326507568 | soaaaaaaaaaraa \n",
            "r\\ Iteration: 2456 Loss: 1.9016897678375244 | soaaarararaar \n",
            "r\\ Iteration: 2457 Loss: 1.690704584121704 | soaaaraaaa \n",
            "r\\ Iteration: 2458 Loss: 1.8777856826782227 | soaaaarararaar \n",
            "r\\ Iteration: 2459 Loss: 1.6947667598724365 | sraaaaaaaraaa \n",
            "r\\ Iteration: 2460 Loss: 2.2160322666168213 | sararaaaaaararaa \n",
            "r\\ Iteration: 2461 Loss: 1.8320496082305908 | soaaaaaaaasaa \n",
            "r\\ Iteration: 2462 Loss: 1.7825400829315186 | sraaaaraaaaraa \n",
            "r\\ Iteration: 2463 Loss: 1.7856698036193848 | soaaaaarararaaa \n",
            "r\\ Iteration: 2464 Loss: 1.791858434677124 | soaaaaararaa \n",
            "r\\ Iteration: 2465 Loss: 1.6687078475952148 | sraaaaarararaaa \n",
            "r\\ Iteration: 2466 Loss: 1.7649776935577393 | soaaaaararaa \n",
            "r\\ Iteration: 2467 Loss: 1.651305913925171 | sraaarararaaa \n",
            "r\\ Iteration: 2468 Loss: 1.8255977630615234 | sraaaararaaaaaa \n",
            "r\\ Iteration: 2469 Loss: 1.829314947128296 | soaaaaraararaaa \n",
            "r\\ Iteration: 2470 Loss: 1.6899192333221436 | soaaraaaaaaaaraaa \n",
            "r\\ Iteration: 2471 Loss: 1.9442589282989502 | saaaaa|raraaaaa \n",
            "r\\ Iteration: 2472 Loss: 1.8906185626983643 | soaaraa|raraar \n",
            "r\\ Iteration: 2473 Loss: 1.7580626010894775 | sraaraaraaaaa \n",
            "r\\ Iteration: 2474 Loss: 1.8583288192749023 | soaaaaararaar \n",
            "r\\ Iteration: 2475 Loss: 1.9215898513793945 | saaaaaaraaar \n",
            "r\\ Iteration: 2476 Loss: 1.9999573230743408 | sraraaaaaaaaa \n",
            "r\\ Iteration: 2477 Loss: 2.0070226192474365 | soaaaaa|raraar \n",
            "r\\ Iteration: 2478 Loss: 1.8618245124816895 | saoaaaraar|raraar \n",
            "r\\ Iteration: 2479 Loss: 1.8016276359558105 | soaraarraraar \n",
            "r\\ Iteration: 2480 Loss: 1.9550249576568604 | saaaaaaraa|a \n",
            "r\\ Iteration: 2481 Loss: 1.8600494861602783 | soaaraar|raraar \n",
            "r\\ Iteration: 2482 Loss: 1.6873009204864502 | soaaaaar|raraar \n",
            "r\\ Iteration: 2483 Loss: 1.7673649787902832 | soararaaaaaa \n",
            "r\\ Iteration: 2484 Loss: 2.0675415992736816 | soaoaar|raraar \n",
            "r\\ Iteration: 2485 Loss: 1.8311386108398438 | saoaaraaaa|raraar \n",
            "r\\ Iteration: 2486 Loss: 1.8102798461914062 | soaaraaaarararaar \n",
            "r\\ Iteration: 2487 Loss: 1.8775427341461182 | soaaaaaraarararaar \n",
            "r\\ Iteration: 2488 Loss: 1.763739824295044 | sraraararaararaar \n",
            "r\\ Iteration: 2489 Loss: 1.8728928565979004 | soaaaaaaa \n",
            "r\\ Iteration: 2490 Loss: 1.9309344291687012 | soaaaaraaaraaaaaa \n",
            "r\\ Iteration: 2491 Loss: 2.046510934829712 | soaaaaaararaar \n",
            "r\\ Iteration: 2492 Loss: 1.8575692176818848 | saaaararaaaar \n",
            "r\\ Iteration: 2493 Loss: 1.9624545574188232 | soasaaasararaar \n",
            "r\\ Iteration: 2494 Loss: 1.627192735671997 | sosaraararaar \n",
            "r\\ Iteration: 2495 Loss: 1.6114189624786377 | soosarasasaa \n",
            "r\\ Iteration: 2496 Loss: 1.954437494277954 | soaaaaaaraar \n",
            "r\\ Iteration: 2497 Loss: 1.8951716423034668 | soaaaaaaaararaa \n",
            "r\\ Iteration: 2498 Loss: 2.0641708374023438 | soaaaraaasaaa \n",
            "r\\ Iteration: 2499 Loss: 2.044214963912964 | saaaaaraarasaa \n",
            "r\\ Iteration: 2500 Loss: 2.042449474334717 | soasaaasararsaaaaa \n",
            "r\\ Iteration: 2501 Loss: 1.9427897930145264 | saaaarrarararaar \n",
            "r\\ Iteration: 2502 Loss: 1.8175172805786133 | soaarasararaar \n",
            "r\\ Iteration: 2503 Loss: 1.8309502601623535 | soosaaaaraararaar \n",
            "r\\ Iteration: 2504 Loss: 1.9102249145507812 | saaaaaararaar \n",
            "r\\ Iteration: 2505 Loss: 1.697143316268921 | soaaaaaaaararaar \n",
            "r\\ Iteration: 2506 Loss: 1.787151575088501 | soaaraaaaaaaraar \n",
            "r\\ Iteration: 2507 Loss: 1.928222894668579 | soaaaoaara \n",
            "r\\ Iteration: 2508 Loss: 2.076505422592163 | soaaaaaraararaar \n",
            "r\\ Iteration: 2509 Loss: 1.8837623596191406 | soaaaaar \n",
            "r\\ Iteration: 2510 Loss: 1.7627224922180176 | soaraasaaa \n",
            "r\\ Iteration: 2511 Loss: 1.887120246887207 | soaaraaraararaar \n",
            "r\\ Iteration: 2512 Loss: 1.678095817565918 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2513 Loss: 2.110987901687622 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2514 Loss: 2.035900354385376 | sraaaasarsoaar \n",
            "r\\ Iteration: 2515 Loss: 2.0461106300354004 | sraraaaaaaar \n",
            "r\\ Iteration: 2516 Loss: 1.9934051036834717 | saaaaaasararaar \n",
            "r\\ Iteration: 2517 Loss: 1.7273297309875488 | sraaaasaaaaaarasaa \n",
            "r\\ Iteration: 2518 Loss: 1.9357469081878662 | soaraaaarasaa \n",
            "r\\ Iteration: 2519 Loss: 1.8729469776153564 | sraaaaaaaasaar \n",
            "r\\ Iteration: 2520 Loss: 1.8806979656219482 | soaraaasararaar \n",
            "r\\ Iteration: 2521 Loss: 1.8142263889312744 | soaraaaaaaaa \n",
            "r\\ Iteration: 2522 Loss: 2.0258920192718506 | sraaarararaar \n",
            "r\\ Iteration: 2523 Loss: 1.6164791584014893 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2524 Loss: 1.8888757228851318 | sraaaaaraaaaar \n",
            "r\\ Iteration: 2525 Loss: 1.9198994636535645 | saaaraaaaaa \n",
            "r\\ Iteration: 2526 Loss: 1.9041664600372314 | soaaraaaraa \n",
            "r\\ Iteration: 2527 Loss: 2.065479278564453 | saaaaaaaararaar \n",
            "r\\ Iteration: 2528 Loss: 1.6833138465881348 | sraaaaaaraaaaaraa \n",
            "r\\ Iteration: 2529 Loss: 1.7876012325286865 | sraaaaaraararaa \n",
            "r\\ Iteration: 2530 Loss: 2.025602340698242 | soaaaaaaaraararaar \n",
            "r\\ Iteration: 2531 Loss: 1.8008406162261963 | soaaaaaaraaaararaar \n",
            "r\\ Iteration: 2532 Loss: 1.7422816753387451 | sraaaaaaaaa \n",
            "r\\ Iteration: 2533 Loss: 1.872826099395752 | sraaaaaaararaar \n",
            "r\\ Iteration: 2534 Loss: 1.8278918266296387 | saaaaaaaararaar \n",
            "r\\ Iteration: 2535 Loss: 1.9217796325683594 | sraaaaaaaaararaa \n",
            "r\\ Iteration: 2536 Loss: 1.7874054908752441 | soaaaa \n",
            "r\\ Iteration: 2537 Loss: 2.0972063541412354 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2538 Loss: 1.9280061721801758 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 2539 Loss: 2.002899646759033 | soaaaaaa \n",
            "r\\ Iteration: 2540 Loss: 1.9851300716400146 | soaaaaaaararaaa \n",
            "r\\ Iteration: 2541 Loss: 1.694437026977539 | sraaaaaaaaararaaa \n",
            "r\\ Iteration: 2542 Loss: 1.8380367755889893 | sraoaaaaaaaaaa \n",
            "r\\ Iteration: 2543 Loss: 1.7981443405151367 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2544 Loss: 1.7480363845825195 | soaaaaaaaaaaararaaa \n",
            "r\\ Iteration: 2545 Loss: 1.8574812412261963 | saaaaaaaaaa \n",
            "r\\ Iteration: 2546 Loss: 1.878340721130371 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2547 Loss: 1.9162170886993408 | saaaaaaaararaaa \n",
            "r\\ Iteration: 2548 Loss: 1.8236253261566162 | saaaaararaaa \n",
            "r\\ Iteration: 2549 Loss: 1.684859037399292 | soaaaaaaaaaaaa \n",
            "r\\ Iteration: 2550 Loss: 1.8596811294555664 | soaaaaaaaaararaaa \n",
            "r\\ Iteration: 2551 Loss: 1.797079086303711 | soaaaaaa \n",
            "r\\ Iteration: 2552 Loss: 2.103850841522217 | soaaaaaaaa \n",
            "r\\ Iteration: 2553 Loss: 1.9231276512145996 | soaaaaraaaaaa \n",
            "r\\ Iteration: 2554 Loss: 1.771183967590332 | sraaaararaaa \n",
            "r\\ Iteration: 2555 Loss: 1.686340093612671 | soaaaaaaaaaaar \n",
            "r\\ Iteration: 2556 Loss: 1.9389581680297852 | soaaaaaaaaa \n",
            "r\\ Iteration: 2557 Loss: 2.019181251525879 | sooaaaaa|raraar \n",
            "r\\ Iteration: 2558 Loss: 1.836158037185669 | soaaaa|raraar \n",
            "r\\ Iteration: 2559 Loss: 1.693861961364746 | soaaaar|raraar \n",
            "r\\ Iteration: 2560 Loss: 1.8348233699798584 | soaaaa|raraar \n",
            "r\\ Iteration: 2561 Loss: 1.8155622482299805 | sraa|aa|raraar \n",
            "r\\ Iteration: 2562 Loss: 1.6629154682159424 | soa|aaaaa|raraar \n",
            "r\\ Iteration: 2563 Loss: 1.8689215183258057 | saoara|raraar \n",
            "r\\ Iteration: 2564 Loss: 1.7628424167633057 | soaaaaaaaararaar \n",
            "r\\ Iteration: 2565 Loss: 1.770596981048584 | saaaaaaaaaa \n",
            "r\\ Iteration: 2566 Loss: 2.078721284866333 | sooaaaaaaaararaar \n",
            "r\\ Iteration: 2567 Loss: 1.8790278434753418 | soaaaaaaa|raraar \n",
            "r\\ Iteration: 2568 Loss: 1.9270122051239014 | sraaaaaaaaaar \n",
            "r\\ Iteration: 2569 Loss: 2.022962808609009 | saaaaaaaaaaar \n",
            "r\\ Iteration: 2570 Loss: 1.759448766708374 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2571 Loss: 2.0058324337005615 | soaaaaaaaaaar \n",
            "r\\ Iteration: 2572 Loss: 1.9911754131317139 | saaaaaararaar \n",
            "r\\ Iteration: 2573 Loss: 1.8087599277496338 | soaaaasaaaaasaaa \n",
            "r\\ Iteration: 2574 Loss: 1.8619132041931152 | srasaaaaasaaa \n",
            "r\\ Iteration: 2575 Loss: 1.8537883758544922 | soaaaaaaaaa \n",
            "r\\ Iteration: 2576 Loss: 1.98637056350708 | sosaasasararaaa \n",
            "r\\ Iteration: 2577 Loss: 1.760929822921753 | soaasaaaaaa \n",
            "r\\ Iteration: 2578 Loss: 1.8007686138153076 | sraaaasaaaasaa \n",
            "r\\ Iteration: 2579 Loss: 1.7366206645965576 | soaaasasararaaa \n",
            "r\\ Iteration: 2580 Loss: 1.7051949501037598 | soaasaararaaa \n",
            "r\\ Iteration: 2581 Loss: 1.6982848644256592 | soaaaaaaaaa \n",
            "r\\ Iteration: 2582 Loss: 1.8917787075042725 | sraaaaasaaasaaaaa \n",
            "r\\ Iteration: 2583 Loss: 2.1116645336151123 | soaaaasaaaaa \n",
            "r\\ Iteration: 2584 Loss: 2.173354387283325 | soasaaaaasaa \n",
            "r\\ Iteration: 2585 Loss: 1.8478448390960693 | saaaaar \n",
            "r\\ Iteration: 2586 Loss: 1.821861982345581 | sraaaaaaa \n",
            "r\\ Iteration: 2587 Loss: 2.241736888885498 | soaaaaaararaar \n",
            "r\\ Iteration: 2588 Loss: 1.9154534339904785 | soaaaasararaar \n",
            "r\\ Iteration: 2589 Loss: 1.6928937435150146 | saaaaasasaa \n",
            "r\\ Iteration: 2590 Loss: 1.9167535305023193 | saaaaraaaaaaaaa \n",
            "r\\ Iteration: 2591 Loss: 2.0855700969696045 | soaaaaararaar \n",
            "r\\ Iteration: 2592 Loss: 1.8175251483917236 | soaaaaaaaaaararaar \n",
            "r\\ Iteration: 2593 Loss: 1.8997681140899658 | soaaararaar \n",
            "r\\ Iteration: 2594 Loss: 1.6073448657989502 | soaaaaaaaararaar \n",
            "r\\ Iteration: 2595 Loss: 1.8468022346496582 | saaaaaaaararaar \n",
            "r\\ Iteration: 2596 Loss: 1.7175915241241455 | soaaaaaararaar \n",
            "r\\ Iteration: 2597 Loss: 1.7474303245544434 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2598 Loss: 2.0079872608184814 | sraaaaaaararaar \n",
            "r\\ Iteration: 2599 Loss: 1.75701904296875 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2600 Loss: 1.8105697631835938 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2601 Loss: 2.014761209487915 | saaaraaaaaaa \n",
            "r\\ Iteration: 2602 Loss: 1.8364717960357666 | saaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2603 Loss: 1.8740451335906982 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2604 Loss: 1.94862961769104 | saaaoaaaaaaaa \n",
            "r\\ Iteration: 2605 Loss: 1.9257643222808838 | soaaaaaaaararaaa \n",
            "r\\ Iteration: 2606 Loss: 1.8775813579559326 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 2607 Loss: 1.797267198562622 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2608 Loss: 2.1177659034729004 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2609 Loss: 1.898585319519043 | soaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2610 Loss: 2.0388238430023193 | soaaaaaararaaa \n",
            "r\\ Iteration: 2611 Loss: 1.7324719429016113 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2612 Loss: 2.0813565254211426 | saaaaaaaaa \n",
            "r\\ Iteration: 2613 Loss: 2.0289268493652344 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2614 Loss: 1.9583053588867188 | saaaaararaaa \n",
            "r\\ Iteration: 2615 Loss: 1.7080824375152588 | sooaaaaaaaaaaraaa \n",
            "r\\ Iteration: 2616 Loss: 1.7966980934143066 | soaaaaaaraaaaa \n",
            "r\\ Iteration: 2617 Loss: 1.7225782871246338 | saoaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2618 Loss: 1.6944072246551514 | soaaaaaaaaaaaa \n",
            "r\\ Iteration: 2619 Loss: 1.8073759078979492 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 2620 Loss: 1.8529446125030518 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2621 Loss: 1.9951975345611572 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2622 Loss: 1.7779724597930908 | soaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2623 Loss: 1.7933664321899414 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2624 Loss: 1.8876564502716064 | soaaaaaaaaaaaa \n",
            "r\\ Iteration: 2625 Loss: 1.840994119644165 | soaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2626 Loss: 1.7020764350891113 | soaaaaaaa \n",
            "r\\ Iteration: 2627 Loss: 1.82277512550354 | soaaaaaaa \n",
            "r\\ Iteration: 2628 Loss: 1.8799428939819336 | sooaaaaaaaaaaa \n",
            "r\\ Iteration: 2629 Loss: 1.8434443473815918 | saaaoaaaaaaaa \n",
            "r\\ Iteration: 2630 Loss: 1.7924690246582031 | soaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2631 Loss: 1.8449010848999023 | saaaaaa \n",
            "r\\ Iteration: 2632 Loss: 2.022477388381958 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2633 Loss: 1.7688333988189697 | soaaaaaaaa \n",
            "r\\ Iteration: 2634 Loss: 1.7537033557891846 | saoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2635 Loss: 1.8196518421173096 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2636 Loss: 1.774461269378662 | soaaaaaaaaaaaa \n",
            "r\\ Iteration: 2637 Loss: 1.813492774963379 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2638 Loss: 1.9514944553375244 | soaaaaaaaaa \n",
            "r\\ Iteration: 2639 Loss: 1.887122392654419 | saaaaaaaaaa \n",
            "r\\ Iteration: 2640 Loss: 1.8973236083984375 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2641 Loss: 1.7793548107147217 | soaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2642 Loss: 1.7984654903411865 | soaaaaaaaaaaa \n",
            "r\\ Iteration: 2643 Loss: 1.8948974609375 | sooaoaaaaaaaaaaaa \n",
            "r\\ Iteration: 2644 Loss: 1.7576322555541992 | sooaaaaaaaaaaaa \n",
            "r\\ Iteration: 2645 Loss: 1.8325917720794678 | saaaaaaaa \n",
            "r\\ Iteration: 2646 Loss: 2.0890657901763916 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 2647 Loss: 1.8467624187469482 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2648 Loss: 1.8431799411773682 | soaoaaaaaaaaaaa \n",
            "r\\ Iteration: 2649 Loss: 1.9196572303771973 | sooaaaaaaaaaaraaaaa \n",
            "r\\ Iteration: 2650 Loss: 1.7308199405670166 | saaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2651 Loss: 1.82169771194458 | soaaaaaaaraaaaa \n",
            "r\\ Iteration: 2652 Loss: 1.7068040370941162 | soaaaaaaaraaaaaaa \n",
            "r\\ Iteration: 2653 Loss: 1.7425599098205566 | sooaaaaaaaaraaaaa \n",
            "r\\ Iteration: 2654 Loss: 1.7586729526519775 | soaaaaraaaaa \n",
            "r\\ Iteration: 2655 Loss: 1.6124467849731445 | soaaaaaraaaaa \n",
            "r\\ Iteration: 2656 Loss: 1.7689063549041748 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 2657 Loss: 1.8982629776000977 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 2658 Loss: 1.904148817062378 | saaaaaaaaraaaaa \n",
            "r\\ Iteration: 2659 Loss: 1.682741641998291 | saaaaaaaaaaasaa \n",
            "r\\ Iteration: 2660 Loss: 1.7759873867034912 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2661 Loss: 1.8395206928253174 | sasaaaaaaaaaaa \n",
            "r\\ Iteration: 2662 Loss: 1.9119582176208496 | saasaaaaasararaaa \n",
            "r\\ Iteration: 2663 Loss: 1.7212095260620117 | soaaaaaaararaaa \n",
            "r\\ Iteration: 2664 Loss: 1.7947373390197754 | soaaaasaaararaaa \n",
            "r\\ Iteration: 2665 Loss: 1.7800309658050537 | soaaaaaaa \n",
            "r\\ Iteration: 2666 Loss: 2.1980350017547607 | saaaaasaaaaa \n",
            "r\\ Iteration: 2667 Loss: 1.8546271324157715 | saaoaaaaararaaa \n",
            "r\\ Iteration: 2668 Loss: 1.7617146968841553 | saaaaaaaaaa \n",
            "r\\ Iteration: 2669 Loss: 2.0937979221343994 | saaaaaasararaaa \n",
            "r\\ Iteration: 2670 Loss: 1.7403552532196045 | soaaaaasararaaa \n",
            "r\\ Iteration: 2671 Loss: 1.6791737079620361 | soaaaaararaaa \n",
            "r\\ Iteration: 2672 Loss: 1.7991962432861328 | soaaaararaaa \n",
            "r\\ Iteration: 2673 Loss: 1.6071515083312988 | soaaaaaararaaa \n",
            "r\\ Iteration: 2674 Loss: 1.7672789096832275 | soaaaaaararaaa \n",
            "r\\ Iteration: 2675 Loss: 1.6924819946289062 | soaaaararaaa \n",
            "r\\ Iteration: 2676 Loss: 1.6082170009613037 | seaaaaaararaaa \n",
            "r\\ Iteration: 2677 Loss: 1.6147902011871338 | seaaaararaaa \n",
            "r\\ Iteration: 2678 Loss: 1.70646333694458 | saaaaaaaaaaaaa \n",
            "r\\ Iteration: 2679 Loss: 1.8774075508117676 | seaaaaararaaa \n",
            "r\\ Iteration: 2680 Loss: 1.7677974700927734 | seaaaaaaa \n",
            "r\\ Iteration: 2681 Loss: 1.936347246170044 | saaaa \n",
            "r\\ Iteration: 2682 Loss: 2.707130193710327 | seaaaaararaaa \n",
            "r\\ Iteration: 2683 Loss: 1.8034229278564453 | saaaoaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2684 Loss: 1.974647045135498 | seaaaaaaaaaararaaa \n",
            "r\\ Iteration: 2685 Loss: 1.7922699451446533 | saaaaararaaa \n",
            "r\\ Iteration: 2686 Loss: 1.8827979564666748 | saaaaaaaararaaa \n",
            "r\\ Iteration: 2687 Loss: 1.7775390148162842 | seaaaaaaaaaa \n",
            "r\\ Iteration: 2688 Loss: 1.927339792251587 | saaaaaaaaa \n",
            "r\\ Iteration: 2689 Loss: 1.9840638637542725 | saaaaaaasaaaa \n",
            "r\\ Iteration: 2690 Loss: 1.8585004806518555 | seaaasaaaaaaaa \n",
            "r\\ Iteration: 2691 Loss: 2.0031116008758545 | saaaaaaararaaa \n",
            "r\\ Iteration: 2692 Loss: 1.824493408203125 | seaaasararaaa \n",
            "r\\ Iteration: 2693 Loss: 1.6561119556427002 | sasaaaaararaaa \n",
            "r\\ Iteration: 2694 Loss: 1.635850429534912 | saaaaaaaaasararaaa \n",
            "r\\ Iteration: 2695 Loss: 1.7828874588012695 | seaaasararaaa \n",
            "r\\ Iteration: 2696 Loss: 1.6801280975341797 | saaaaaasaraaaaa \n",
            "r\\ Iteration: 2697 Loss: 1.7499730587005615 | sasaaaaaaaaaraaaaa \n",
            "r\\ Iteration: 2698 Loss: 1.8600363731384277 | seeaaaasasaaa \n",
            "r\\ Iteration: 2699 Loss: 2.2187650203704834 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2700 Loss: 2.032473564147949 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2701 Loss: 1.9461684226989746 | seaaasasaaaasaa \n",
            "r\\ Iteration: 2702 Loss: 1.8890173435211182 | saaaaasaasaaaa \n",
            "r\\ Iteration: 2703 Loss: 1.9743871688842773 | saaaaasaraaaaa \n",
            "r\\ Iteration: 2704 Loss: 1.7021055221557617 | saaaaaaaaaaa \n",
            "r\\ Iteration: 2705 Loss: 2.2082228660583496 | seaaasaaaa \n",
            "r\\ Iteration: 2706 Loss: 1.9203214645385742 | saaaaaaaaasaaa \n",
            "r\\ Iteration: 2707 Loss: 2.0445191860198975 | sesasaasaaaaa \n",
            "r\\ Iteration: 2708 Loss: 1.8683397769927979 | saaaaaa \n",
            "r\\ Iteration: 2709 Loss: 2.0398991107940674 | sasaaaaaaaaaaa \n",
            "r\\ Iteration: 2710 Loss: 1.7904908657073975 | seaaasasaa \n",
            "r\\ Iteration: 2711 Loss: 1.885486364364624 | saassaaaaaaa \n",
            "r\\ Iteration: 2712 Loss: 1.771733283996582 | saaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2713 Loss: 1.9035007953643799 | saaaaa \n",
            "r\\ Iteration: 2714 Loss: 2.1304023265838623 | seaaaa \n",
            "r\\ Iteration: 2715 Loss: 2.1586062908172607 | sosasaaaaaaa \n",
            "r\\ Iteration: 2716 Loss: 1.621596097946167 | saaaaaaaasaa \n",
            "r\\ Iteration: 2717 Loss: 2.079030752182007 | saaaaaaaaaaaa \n",
            "r\\ Iteration: 2718 Loss: 1.8056678771972656 | saaaaaraaaaa \n",
            "r\\ Iteration: 2719 Loss: 1.67026686668396 | siaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2720 Loss: 1.9272072315216064 | soaaaaoaaraaaaa \n",
            "r\\ Iteration: 2721 Loss: 1.7819902896881104 | soaaaaaoaa \n",
            "r\\ Iteration: 2722 Loss: 1.9646568298339844 | seaaaaoaaaaaaa \n",
            "r\\ Iteration: 2723 Loss: 1.9973623752593994 | saaaaraaaaa \n",
            "r\\ Iteration: 2724 Loss: 1.740290880203247 | siaoaaaaaaaaaaaa \n",
            "r\\ Iteration: 2725 Loss: 2.0494017601013184 | siaaaaaaaaaaaa \n",
            "r\\ Iteration: 2726 Loss: 1.8939027786254883 | seaaaaaaaaaaaa \n",
            "r\\ Iteration: 2727 Loss: 1.8405444622039795 | siaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2728 Loss: 1.9251844882965088 | seaaaaaaaraaaaa \n",
            "r\\ Iteration: 2729 Loss: 1.724036693572998 | saaaasaaaaaa \n",
            "r\\ Iteration: 2730 Loss: 1.9849786758422852 | saaaaaaaasaaa \n",
            "r\\ Iteration: 2731 Loss: 2.0040934085845947 | saaaaaaaraaaaa \n",
            "r\\ Iteration: 2732 Loss: 1.914078950881958 | seaaaaraasaaaaaaa \n",
            "r\\ Iteration: 2733 Loss: 1.8429512977600098 | seaaaaaaa \n",
            "r\\ Iteration: 2734 Loss: 2.0227396488189697 | seaaaaraaaaa \n",
            "r\\ Iteration: 2735 Loss: 1.6671102046966553 | saaaaaaaraaaaa \n",
            "r\\ Iteration: 2736 Loss: 1.715059518814087 | seeaaaaaaaa \n",
            "r\\ Iteration: 2737 Loss: 1.8732209205627441 | saaaaaaaaraaaaa \n",
            "r\\ Iteration: 2738 Loss: 1.837627649307251 | seaaaaaaaaaaa \n",
            "r\\ Iteration: 2739 Loss: 1.8992946147918701 | seaaaaaaaraaaaa \n",
            "r\\ Iteration: 2740 Loss: 1.7129759788513184 | saoaaaaaaaa \n",
            "r\\ Iteration: 2741 Loss: 1.7626128196716309 | seaaaaaaaaraaaaa \n",
            "r\\ Iteration: 2742 Loss: 1.8529222011566162 | seaaaaaaaaa \n",
            "r\\ Iteration: 2743 Loss: 1.9834954738616943 | seaaaaararaaa \n",
            "r\\ Iteration: 2744 Loss: 1.8367178440093994 | seeaaaarararaaa \n",
            "r\\ Iteration: 2745 Loss: 1.742814540863037 | saaaaaraaaaaaar \n",
            "r\\ Iteration: 2746 Loss: 1.8052647113800049 | seararaaaraaaar \n",
            "r\\ Iteration: 2747 Loss: 1.9394497871398926 | saararaaaraa \n",
            "r\\ Iteration: 2748 Loss: 1.9526665210723877 | seaaaararaa \n",
            "r\\ Iteration: 2749 Loss: 1.8211843967437744 | seaaarararaar \n",
            "r\\ Iteration: 2750 Loss: 1.84415602684021 | seaararararaar \n",
            "r\\ Iteration: 2751 Loss: 1.8680059909820557 | seeaaaaaaarararaar \n",
            "r\\ Iteration: 2752 Loss: 1.8681154251098633 | saraararararaar \n",
            "r\\ Iteration: 2753 Loss: 1.7721731662750244 | seaaaaarrrar \n",
            "r\\ Iteration: 2754 Loss: 1.9448950290679932 | saraoaaaraararrr \n",
            "r\\ Iteration: 2755 Loss: 1.967334508895874 | saoaaararaararaara \n",
            "r\\ Iteration: 2756 Loss: 1.9157757759094238 | seaaaraaraararrrrrr \n",
            "r\\ Iteration: 2757 Loss: 1.7842352390289307 | sarrraarrrarrrrrr \n",
            "r\\ Iteration: 2758 Loss: 1.7467091083526611 | seeaaraaarrrrrr \n",
            "r\\ Iteration: 2759 Loss: 1.8364007472991943 | saoaaaaaararrrrrr \n",
            "r\\ Iteration: 2760 Loss: 1.7701842784881592 | sroaraararrrarrr \n",
            "r\\ Iteration: 2761 Loss: 1.998521327972412 | saararaararrrrrr \n",
            "r\\ Iteration: 2762 Loss: 1.8855581283569336 | searaarararara \n",
            "r\\ Iteration: 2763 Loss: 2.109318971633911 | saarrrarra \n",
            "r\\ Iteration: 2764 Loss: 1.9750988483428955 | searaarrararrrrrr \n",
            "r\\ Iteration: 2765 Loss: 1.805912971496582 | saaaararrra \n",
            "r\\ Iteration: 2766 Loss: 2.0032811164855957 | seaaaararrrrrr \n",
            "r\\ Iteration: 2767 Loss: 1.847580909729004 | seaoaararrrrrr \n",
            "r\\ Iteration: 2768 Loss: 1.7391233444213867 | seaaararararrrrrr \n",
            "r\\ Iteration: 2769 Loss: 1.728766918182373 | seaarararar \n",
            "r\\ Iteration: 2770 Loss: 1.786308765411377 | seaararrrrrr \n",
            "r\\ Iteration: 2771 Loss: 1.7777433395385742 | saaaraaraararrr \n",
            "r\\ Iteration: 2772 Loss: 1.8726584911346436 | seaarararrrrrr \n",
            "r\\ Iteration: 2773 Loss: 1.7043848037719727 | saeeaaraaararrrrrr \n",
            "r\\ Iteration: 2774 Loss: 1.7929012775421143 | seaoaaararaaa \n",
            "r\\ Iteration: 2775 Loss: 2.100907564163208 | seaaaarrarra \n",
            "r\\ Iteration: 2776 Loss: 2.1657555103302 | saaararaararar \n",
            "r\\ Iteration: 2777 Loss: 1.788558006286621 | saeararaarrr \n",
            "r\\ Iteration: 2778 Loss: 1.9974944591522217 | saaaraaaaarara \n",
            "r\\ Iteration: 2779 Loss: 1.8831090927124023 | sesosaraarara \n",
            "r\\ Iteration: 2780 Loss: 1.9816410541534424 | sesaararararaar \n",
            "r\\ Iteration: 2781 Loss: 1.7653825283050537 | seesaarraaaaaar \n",
            "r\\ Iteration: 2782 Loss: 1.9398951530456543 | sessaaarasaa \n",
            "r\\ Iteration: 2783 Loss: 1.8801155090332031 | sesarasasaa \n",
            "r\\ Iteration: 2784 Loss: 1.7223131656646729 | sesosaaaaararaar \n",
            "r\\ Iteration: 2785 Loss: 1.7703206539154053 | saaarararasaar \n",
            "r\\ Iteration: 2786 Loss: 1.7857475280761719 | sesasasararaar \n",
            "r\\ Iteration: 2787 Loss: 1.7104077339172363 | seaaasararaar \n",
            "r\\ Iteration: 2788 Loss: 1.7485992908477783 | sesoosaaraasaa \n",
            "r\\ Iteration: 2789 Loss: 1.9778826236724854 | sasoaaasra \n",
            "r\\ Iteration: 2790 Loss: 2.0290119647979736 | saaraosasaasararaaa \n",
            "r\\ Iteration: 2791 Loss: 1.7273588180541992 | sososarasasaaaa \n",
            "r\\ Iteration: 2792 Loss: 1.860762119293213 | sosaasararaaa \n",
            "r\\ Iteration: 2793 Loss: 1.7109699249267578 | soaaaaraaaaa \n",
            "r\\ Iteration: 2794 Loss: 2.072782278060913 | soasosaaa \n",
            "r\\ Iteration: 2795 Loss: 2.1003448963165283 | soaaaaaaaaasaaa \n",
            "r\\ Iteration: 2796 Loss: 2.0603222846984863 | soaosoaaararaaa \n",
            "r\\ Iteration: 2797 Loss: 1.8339903354644775 | soosasaasaaasaa \n",
            "r\\ Iteration: 2798 Loss: 1.9591972827911377 | saooosaraaaaa \n",
            "r\\ Iteration: 2799 Loss: 1.7299537658691406 | soososaraaaaa \n",
            "r\\ Iteration: 2800 Loss: 1.777867317199707 | saoaaaosaraaaaa \n",
            "r\\ Iteration: 2801 Loss: 1.767812728881836 | sooooosararaaa \n",
            "r\\ Iteration: 2802 Loss: 1.7274110317230225 | sosososaaaa \n",
            "r\\ Iteration: 2803 Loss: 1.7921290397644043 | saoaoosaaaraaa \n",
            "r\\ Iteration: 2804 Loss: 1.720151424407959 | soaooaoaaosaa \n",
            "r\\ Iteration: 2805 Loss: 1.765005350112915 | soaoaoaasaaaa \n",
            "r\\ Iteration: 2806 Loss: 1.8837699890136719 | soaooaoaaaasaa \n",
            "r\\ Iteration: 2807 Loss: 1.841580867767334 | sooooaaaaaasaaa \n",
            "r\\ Iteration: 2808 Loss: 1.7147974967956543 | sooaaoaaas|raaaaa \n",
            "r\\ Iteration: 2809 Loss: 1.7771365642547607 | sooaasaaaaasaaa \n",
            "r\\ Iteration: 2810 Loss: 1.798006296157837 | saaaoaaraaaaa \n",
            "r\\ Iteration: 2811 Loss: 1.7189416885375977 | soaaas|raaaaa \n",
            "r\\ Iteration: 2812 Loss: 1.7940139770507812 | sosaaaa|raaaaa \n",
            "r\\ Iteration: 2813 Loss: 1.762312412261963 | saaaosaaaa|a \n",
            "r\\ Iteration: 2814 Loss: 1.9353301525115967 | soaoa \n",
            "r\\ Iteration: 2815 Loss: 2.2205185890197754 | saaosaaaa \n",
            "r\\ Iteration: 2816 Loss: 2.056352376937866 | soaaas|aaaaaa \n",
            "r\\ Iteration: 2817 Loss: 1.7355892658233643 | soaaaaaaaaaa \n",
            "r\\ Iteration: 2818 Loss: 1.9554221630096436 | soaaaaas|aaaaaa \n",
            "r\\ Iteration: 2819 Loss: 1.737152338027954 | hoaaaaa|aaaaaa \n",
            "r\\ Iteration: 2820 Loss: 1.63496732711792 | hoaaaaaaraaaaa \n",
            "r\\ Iteration: 2821 Loss: 1.8880491256713867 | hoooaaaaaaaaaa \n",
            "r\\ Iteration: 2822 Loss: 1.7469825744628906 | heaaraaaaaaaa \n",
            "r\\ Iteration: 2823 Loss: 1.8191473484039307 | heoaaar|raraar \n",
            "r\\ Iteration: 2824 Loss: 1.7858808040618896 | heoaoaaaaaaaara \n",
            "r\\ Iteration: 2825 Loss: 2.0266213417053223 | heoaarraaar \n",
            "r\\ Iteration: 2826 Loss: 1.9644036293029785 | heaaaaaaarara \n",
            "r\\ Iteration: 2827 Loss: 2.2076416015625 | heoaararaa \n",
            "r\\ Iteration: 2828 Loss: 1.8430557250976562 | hhceaaarrrraarr \n",
            "r\\ Iteration: 2829 Loss: 2.042377471923828 | hedeehedhdddddd \n",
            "r\\ Iteration: 2830 Loss: 2.2404286861419678 | hhoaoaarrrrr \n",
            "r\\ Iteration: 2831 Loss: 1.9899663925170898 | heaaoaarrarrrrrrrr \n",
            "r\\ Iteration: 2832 Loss: 1.7839820384979248 | heaaaoaarrrrrrrr \n",
            "r\\ Iteration: 2833 Loss: 1.7729487419128418 | heaaoarrrrrrr \n",
            "r\\ Iteration: 2834 Loss: 1.661909580230713 | heaoaarrrrrrrr \n",
            "r\\ Iteration: 2835 Loss: 1.7894282341003418 | haoorrrr \n",
            "r\\ Iteration: 2836 Loss: 1.8594627380371094 | haaorrrrrrrrrrr \n",
            "r\\ Iteration: 2837 Loss: 1.712376356124878 | haooorrrrrrrrrr \n",
            "r\\ Iteration: 2838 Loss: 1.8033738136291504 | horrrrrrrrrrrrr \n",
            "r\\ Iteration: 2839 Loss: 1.7040154933929443 | haoraorrrrrrrrrrr \n",
            "r\\ Iteration: 2840 Loss: 1.8627307415008545 | horrrrrrrarrrr \n",
            "r\\ Iteration: 2841 Loss: 1.8469631671905518 | haaoorrrr \n",
            "r\\ Iteration: 2842 Loss: 2.1472387313842773 | harrrorrrrrrrrr \n",
            "r\\ Iteration: 2843 Loss: 1.9846854209899902 | horrrrrrrrrrr \n",
            "r\\ Iteration: 2844 Loss: 1.7843351364135742 | horoarrrrrrrrrrrrr \n",
            "r\\ Iteration: 2845 Loss: 1.8743739128112793 | hoorrrrrrrrr \n",
            "r\\ Iteration: 2846 Loss: 1.7893197536468506 | horourrrrrrrrr \n",
            "r\\ Iteration: 2847 Loss: 1.906512975692749 | hororrrrrrrrrrr \n",
            "r\\ Iteration: 2848 Loss: 2.039271831512451 | haaurrrrrrrrrr \n",
            "r\\ Iteration: 2849 Loss: 1.8590013980865479 | hourrrarrrrrrrr \n",
            "r\\ Iteration: 2850 Loss: 1.8465209007263184 | horarrrrrrrr \n",
            "r\\ Iteration: 2851 Loss: 1.7149808406829834 | horrrrrrrrrr \n",
            "r\\ Iteration: 2852 Loss: 1.6303296089172363 | harrrrrrarrr \n",
            "r\\ Iteration: 2853 Loss: 1.9739809036254883 | horrrrrrrrr \n",
            "r\\ Iteration: 2854 Loss: 1.6892495155334473 | horrrrrrrrrrrrrr \n",
            "r\\ Iteration: 2855 Loss: 1.7591462135314941 | haorrrrrrrrr \n",
            "r\\ Iteration: 2856 Loss: 1.7837183475494385 | horrarrrrrrrrrrr \n",
            "r\\ Iteration: 2857 Loss: 1.8411951065063477 | harrrrrrrrrrr \n",
            "r\\ Iteration: 2858 Loss: 1.8118581771850586 | horrarrrrrrrrrr \n",
            "r\\ Iteration: 2859 Loss: 1.7263836860656738 | harrorrrr \n",
            "r\\ Iteration: 2860 Loss: 2.0771307945251465 | horrrarrrrrrrrr \n",
            "r\\ Iteration: 2861 Loss: 1.7918317317962646 | haoorrrrrarrrr \n",
            "r\\ Iteration: 2862 Loss: 1.7885987758636475 | harrrrrrrrarrrr \n",
            "r\\ Iteration: 2863 Loss: 1.7129254341125488 | harrrrrrrrrrr \n",
            "r\\ Iteration: 2864 Loss: 1.88639235496521 | hororrrrrr \n",
            "r\\ Iteration: 2865 Loss: 2.042649269104004 | horrroorrrrrrrrrrr \n",
            "r\\ Iteration: 2866 Loss: 1.8193919658660889 | hororrrrrrr \n",
            "r\\ Iteration: 2867 Loss: 1.9999253749847412 | horrrrrr \n",
            "r\\ Iteration: 2868 Loss: 1.8233568668365479 | horaorrrrrrrrrrrrr \n",
            "r\\ Iteration: 2869 Loss: 1.7692081928253174 | hororrrrrararrr \n",
            "r\\ Iteration: 2870 Loss: 1.9270379543304443 | hoarrrrrrrrr \n",
            "r\\ Iteration: 2871 Loss: 2.0410916805267334 | horoorarrrrrrrrrrr \n",
            "r\\ Iteration: 2872 Loss: 1.8847291469573975 | haaaarrrrrrrrrrr \n",
            "r\\ Iteration: 2873 Loss: 1.8857624530792236 | horororrrrrrrrr \n",
            "r\\ Iteration: 2874 Loss: 1.8871748447418213 | horoororarrrrrr \n",
            "r\\ Iteration: 2875 Loss: 1.7100422382354736 | horoororarrrrrr \n",
            "r\\ Iteration: 2876 Loss: 1.8209397792816162 | horararrrrrr \n",
            "r\\ Iteration: 2877 Loss: 1.8461754322052002 | hoaorrarrrrrr \n",
            "r\\ Iteration: 2878 Loss: 1.797264814376831 | haarorarrrrrr \n",
            "r\\ Iteration: 2879 Loss: 1.7747154235839844 | haarroraar \n",
            "r\\ Iteration: 2880 Loss: 1.8366358280181885 | hiroararrrrr \n",
            "r\\ Iteration: 2881 Loss: 1.9576964378356934 | hiroararrrrrr \n",
            "r\\ Iteration: 2882 Loss: 1.6990835666656494 | hoaaorarrr \n",
            "r\\ Iteration: 2883 Loss: 1.8826749324798584 | hirorrrrararrr \n",
            "r\\ Iteration: 2884 Loss: 1.9868512153625488 | haoaarrarrrrrrrrr \n",
            "r\\ Iteration: 2885 Loss: 1.710846185684204 | hiaaraarrrrrrrr \n",
            "r\\ Iteration: 2886 Loss: 1.7875099182128906 | haoaorarrrrrr \n",
            "r\\ Iteration: 2887 Loss: 1.7095930576324463 | hiaorarrrrrr \n",
            "r\\ Iteration: 2888 Loss: 1.6218082904815674 | hoaarrarrrrrr \n",
            "r\\ Iteration: 2889 Loss: 1.655879259109497 | hiaorarrrrrarr \n",
            "r\\ Iteration: 2890 Loss: 1.829108715057373 | hooaorrrrrrrrrr \n",
            "r\\ Iteration: 2891 Loss: 1.6327967643737793 | hoaarrrrrrrr \n",
            "r\\ Iteration: 2892 Loss: 1.8473875522613525 | hoaaaorarrr \n",
            "r\\ Iteration: 2893 Loss: 1.9831137657165527 | haoaonrrarrrrrarr \n",
            "r\\ Iteration: 2894 Loss: 1.8346827030181885 | hoaorrrrrrrrrrr \n",
            "r\\ Iteration: 2895 Loss: 1.7047879695892334 | hoarorarr \n",
            "r\\ Iteration: 2896 Loss: 1.7525219917297363 | hoaorrrrrrrarrrr \n",
            "r\\ Iteration: 2897 Loss: 1.900249719619751 | hoaorrrrrrrrrrr \n",
            "r\\ Iteration: 2898 Loss: 1.7005174160003662 | hoaaorrrrrrr \n",
            "r\\ Iteration: 2899 Loss: 2.051055669784546 | hoaorrrrrrrrrrr \n",
            "r\\ Iteration: 2900 Loss: 1.7736990451812744 | hoaorraorrr \n",
            "r\\ Iteration: 2901 Loss: 1.8420896530151367 | hoaoarrrrrrrrrrrr \n",
            "r\\ Iteration: 2902 Loss: 1.8537201881408691 | hooaorrrrrrrr \n",
            "r\\ Iteration: 2903 Loss: 1.7135887145996094 | hoaororrrrr \n",
            "r\\ Iteration: 2904 Loss: 1.8615612983703613 | hoaoorrrrrrrrrr \n",
            "r\\ Iteration: 2905 Loss: 1.7467646598815918 | hoaoroarrrrrrrrr \n",
            "r\\ Iteration: 2906 Loss: 1.7171530723571777 | hoanorrorarrrrrrrr \n",
            "r\\ Iteration: 2907 Loss: 1.8317244052886963 | hoaorrrrrrrrrrrrrr \n",
            "r\\ Iteration: 2908 Loss: 1.7991316318511963 | hoaonrrrrrrrr \n",
            "r\\ Iteration: 2909 Loss: 1.6880760192871094 | hoooonrrrrrrrrrrrrrr \n",
            "r\\ Iteration: 2910 Loss: 2.0329084396362305 | hoanrrrrrrrr \n",
            "r\\ Iteration: 2911 Loss: 1.8047268390655518 | hoaorrrrrrrrrrrr \n",
            "r\\ Iteration: 2912 Loss: 1.7134573459625244 | hoaoarrrararrorr \n",
            "r\\ Iteration: 2913 Loss: 2.0476036071777344 | hoaarrrarnrrrrrr \n",
            "r\\ Iteration: 2914 Loss: 1.911144733428955 | hooaararrrrrrr \n",
            "r\\ Iteration: 2915 Loss: 1.7796313762664795 | hoaoararrarr \n",
            "r\\ Iteration: 2916 Loss: 2.045060634613037 | hoaaaararrr \n",
            "r\\ Iteration: 2917 Loss: 1.90669584274292 | hooaarrrrrrrrr \n",
            "r\\ Iteration: 2918 Loss: 1.7013413906097412 | hoaoaararar \n",
            "r\\ Iteration: 2919 Loss: 1.9840679168701172 | haoaaar|rrrrrr \n",
            "r\\ Iteration: 2920 Loss: 1.7940027713775635 | hoaoarar|rrrrrr \n",
            "r\\ Iteration: 2921 Loss: 1.7065036296844482 | hooaoaaarrarrrrrr \n",
            "r\\ Iteration: 2922 Loss: 1.8468279838562012 | hoaooaaaarrrrrr \n",
            "r\\ Iteration: 2923 Loss: 1.9292142391204834 | hoaoaaaraa \n",
            "r\\ Iteration: 2924 Loss: 1.9616785049438477 | haooaarrrrar \n",
            "r\\ Iteration: 2925 Loss: 1.7343857288360596 | hoaoaaaarararar \n",
            "r\\ Iteration: 2926 Loss: 1.9994423389434814 | hoaaaaaaarrrrar \n",
            "r\\ Iteration: 2927 Loss: 1.9029541015625 | hoaaaaarrrrar \n",
            "r\\ Iteration: 2928 Loss: 1.819458246231079 | haoaoaarar \n",
            "r\\ Iteration: 2929 Loss: 1.9255614280700684 | hoaaaoaaararrar \n",
            "r\\ Iteration: 2930 Loss: 1.7892143726348877 | hoaaaaararaar \n",
            "r\\ Iteration: 2931 Loss: 1.7996571063995361 | hoaooaararaa \n",
            "r\\ Iteration: 2932 Loss: 1.773224115371704 | hooaaarararaaa \n",
            "r\\ Iteration: 2933 Loss: 1.8025870323181152 | hoaaaraoaaa \n",
            "r\\ Iteration: 2934 Loss: 2.0072383880615234 | haaaoaararaaa \n",
            "r\\ Iteration: 2935 Loss: 1.7943649291992188 | hoaoaaararaaa \n",
            "r\\ Iteration: 2936 Loss: 1.87778639793396 | hoaooaaaaaaa \n",
            "r\\ Iteration: 2937 Loss: 1.8992457389831543 | hoaaoaoaoaa \n",
            "r\\ Iteration: 2938 Loss: 1.92280912399292 | hoaaoaaoaaaaaaaa \n",
            "r\\ Iteration: 2939 Loss: 1.8654048442840576 | haooaooaoaaaaaa \n",
            "r\\ Iteration: 2940 Loss: 2.1936192512512207 | haoaoaaoaaaaaaaaa \n",
            "r\\ Iteration: 2941 Loss: 1.7772235870361328 | haaaooaaaaaaaa \n",
            "r\\ Iteration: 2942 Loss: 1.6561126708984375 | hoaooaoaoaaa \n",
            "r\\ Iteration: 2943 Loss: 1.858295202255249 | haaoaoaoaoaaaa \n",
            "r\\ Iteration: 2944 Loss: 1.9492552280426025 | hoaaoaaaaaaaa \n",
            "r\\ Iteration: 2945 Loss: 1.8671276569366455 | haoooaoaaraaaaa \n",
            "r\\ Iteration: 2946 Loss: 1.886901617050171 | hooaaoaaaaa \n",
            "r\\ Iteration: 2947 Loss: 2.0369741916656494 | haaoaoaa \n",
            "r\\ Iteration: 2948 Loss: 2.012357234954834 | haoaaaaaraaaaa \n",
            "r\\ Iteration: 2949 Loss: 1.7830443382263184 | haoaoaaraaaaa \n",
            "r\\ Iteration: 2950 Loss: 1.699681043624878 | hoaaoaaaaaaaaa \n",
            "r\\ Iteration: 2951 Loss: 2.0041017532348633 | haaoaaaaaaa \n",
            "r\\ Iteration: 2952 Loss: 1.9711833000183105 | haoaaaaaa \n",
            "r\\ Iteration: 2953 Loss: 1.9547979831695557 | haaaaaaaraaaaa \n",
            "r\\ Iteration: 2954 Loss: 1.704763650894165 | haaaaaaaaa \n",
            "r\\ Iteration: 2955 Loss: 1.9952490329742432 | haaoaaaaaaa \n",
            "r\\ Iteration: 2956 Loss: 1.9008359909057617 | haaaaraaaaa \n",
            "r\\ Iteration: 2957 Loss: 1.702204942703247 | hoaaaaaararaaaaa \n",
            "r\\ Iteration: 2958 Loss: 1.770768404006958 | hooaaaaaaaraa \n",
            "r\\ Iteration: 2959 Loss: 1.9737942218780518 | haaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2960 Loss: 2.0707201957702637 | haoaoaaaaaaaraaaaa \n",
            "r\\ Iteration: 2961 Loss: 1.7970635890960693 | haaaaaaaaraaaaa \n",
            "r\\ Iteration: 2962 Loss: 1.7695369720458984 | hooaaaaaaaaaa \n",
            "r\\ Iteration: 2963 Loss: 1.9458835124969482 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 2964 Loss: 1.739884614944458 | haoaaaraaaaa \n",
            "r\\ Iteration: 2965 Loss: 1.7947137355804443 | haeoaaaaaaaa \n",
            "r\\ Iteration: 2966 Loss: 1.6977455615997314 | hiaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2967 Loss: 1.7576348781585693 | hiaoaaaaaaaa \n",
            "r\\ Iteration: 2968 Loss: 2.004136562347412 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 2969 Loss: 1.6051709651947021 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 2970 Loss: 1.6922879219055176 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 2971 Loss: 2.1022496223449707 | haaaaanaaaaaaa \n",
            "r\\ Iteration: 2972 Loss: 1.8067116737365723 | hiaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2973 Loss: 1.844468116760254 | haoaaaaaaaaa \n",
            "r\\ Iteration: 2974 Loss: 1.8827309608459473 | hoaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2975 Loss: 1.889498233795166 | haoaaaaaaa \n",
            "r\\ Iteration: 2976 Loss: 2.0665574073791504 | hiaaaasaaaaaaa \n",
            "r\\ Iteration: 2977 Loss: 1.6936187744140625 | hoaaaasaasasa \n",
            "r\\ Iteration: 2978 Loss: 2.1711819171905518 | haisaaaaaaaaaa \n",
            "r\\ Iteration: 2979 Loss: 1.8101403713226318 | haosaaaasaaa \n",
            "r\\ Iteration: 2980 Loss: 1.958989143371582 | hooaaaaaaaaa \n",
            "r\\ Iteration: 2981 Loss: 1.8694465160369873 | haaaaaaaaaasaaa \n",
            "r\\ Iteration: 2982 Loss: 1.985532283782959 | hiaaaaaaaaasaasasaa \n",
            "r\\ Iteration: 2983 Loss: 1.973984718322754 | haosasasaa \n",
            "r\\ Iteration: 2984 Loss: 1.739008903503418 | hoaaaasaaaaaa \n",
            "r\\ Iteration: 2985 Loss: 1.8832204341888428 | hosaasaaaaaaaaaa \n",
            "r\\ Iteration: 2986 Loss: 1.869743824005127 | hiaaaaaaaaaasaaa \n",
            "r\\ Iteration: 2987 Loss: 1.948204755783081 | haaaasaaaaasaaaaa \n",
            "r\\ Iteration: 2988 Loss: 1.9662654399871826 | hiaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2989 Loss: 1.938899040222168 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 2990 Loss: 1.769620656967163 | haaoaaaaaaaa \n",
            "r\\ Iteration: 2991 Loss: 1.6454379558563232 | haaaaasaaaaaaa \n",
            "r\\ Iteration: 2992 Loss: 1.7503244876861572 | haooaaaaaaaaaaa \n",
            "r\\ Iteration: 2993 Loss: 1.7458572387695312 | hoaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2994 Loss: 1.9385240077972412 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 2995 Loss: 1.7009193897247314 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 2996 Loss: 1.8238871097564697 | hoaoaaaaaaaaaa \n",
            "r\\ Iteration: 2997 Loss: 1.634253978729248 | haaoaaaaaaaa \n",
            "r\\ Iteration: 2998 Loss: 1.9786577224731445 | hoaoaaaaa \n",
            "r\\ Iteration: 2999 Loss: 1.9949893951416016 | hoaaaaaaaaa \n",
            "r\\ Iteration: 3000 Loss: 1.7355570793151855 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3001 Loss: 1.8431096076965332 | hooaaaaaaaaa \n",
            "r\\ Iteration: 3002 Loss: 1.8290343284606934 | hooaaaaaaaaaaa \n",
            "r\\ Iteration: 3003 Loss: 1.8033807277679443 | hoaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3004 Loss: 1.9214668273925781 | hoaoaaaaaaaaaa \n",
            "r\\ Iteration: 3005 Loss: 1.846627950668335 | hoaaaaa \n",
            "r\\ Iteration: 3006 Loss: 2.0395452976226807 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3007 Loss: 1.7754580974578857 | hoaoaaaa \n",
            "r\\ Iteration: 3008 Loss: 1.8523383140563965 | haaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3009 Loss: 1.9349358081817627 | hoaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3010 Loss: 1.9577336311340332 | hoooaaaaaaaaaa \n",
            "r\\ Iteration: 3011 Loss: 1.8530604839324951 | haoaaaaaa \n",
            "r\\ Iteration: 3012 Loss: 2.0156359672546387 | aoaaa \n",
            "r\\ Iteration: 3013 Loss: 2.240037441253662 | aaoaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3014 Loss: 1.7630772590637207 | aaoaaaaaaaaa \n",
            "r\\ Iteration: 3015 Loss: 1.9020447731018066 | aoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3016 Loss: 1.9876737594604492 | aoaaaaaaaaaaa \n",
            "r\\ Iteration: 3017 Loss: 1.7709684371948242 | aoaaaaaaaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3018 Loss: 1.799994707107544 | aaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3019 Loss: 1.9494950771331787 | aoaoaaaaaa \n",
            "r\\ Iteration: 3020 Loss: 1.821180820465088 | aaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3021 Loss: 1.8592820167541504 | haaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3022 Loss: 1.709333896636963 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3023 Loss: 1.729741096496582 | hoaaoaaaaaa \n",
            "r\\ Iteration: 3024 Loss: 1.869581937789917 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3025 Loss: 1.8657653331756592 | hiaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3026 Loss: 1.9019007682800293 | haoaaaaaa \n",
            "r\\ Iteration: 3027 Loss: 1.8423259258270264 | haaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3028 Loss: 1.7667512893676758 | hoaaaaaaaaa \n",
            "r\\ Iteration: 3029 Loss: 2.0261330604553223 | haaaaaaaaaaaa \n",
            "r\\ Iteration: 3030 Loss: 1.6976048946380615 | haaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3031 Loss: 1.7972769737243652 | haoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3032 Loss: 1.9324791431427002 | hooaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3033 Loss: 1.7249994277954102 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3034 Loss: 1.7912991046905518 | hoaoaaaaaaaa \n",
            "r\\ Iteration: 3035 Loss: 1.9488472938537598 | haoaaaaaaraaaaaaa \n",
            "r\\ Iteration: 3036 Loss: 1.7043561935424805 | hoaaiaaaaaaaa \n",
            "r\\ Iteration: 3037 Loss: 1.733337640762329 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3038 Loss: 1.8943448066711426 | hoaiaaaaaaaaaa \n",
            "r\\ Iteration: 3039 Loss: 1.689908742904663 | hiaoiaaaaaaaaa \n",
            "r\\ Iteration: 3040 Loss: 1.8069722652435303 | hoaoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3041 Loss: 1.8651401996612549 | hoaoaaaaaaaaa \n",
            "r\\ Iteration: 3042 Loss: 1.952350378036499 | hoaaoaaaaaaaa \n",
            "r\\ Iteration: 3043 Loss: 1.7107818126678467 | hooaoaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3044 Loss: 1.9510834217071533 | haaaaoaaauaaa \n",
            "r\\ Iteration: 3045 Loss: 1.8467562198638916 | hooaaoaaraaaaa \n",
            "r\\ Iteration: 3046 Loss: 2.0379629135131836 | haooaoaaaraaaaaaa \n",
            "r\\ Iteration: 3047 Loss: 1.9605281352996826 | haoaoaaaa \n",
            "r\\ Iteration: 3048 Loss: 1.948376178741455 | hoaaooaaaa \n",
            "r\\ Iteration: 3049 Loss: 2.0218803882598877 | haoaoaaraa \n",
            "r\\ Iteration: 3050 Loss: 1.8426704406738281 | hoooaaaaaaaa \n",
            "r\\ Iteration: 3051 Loss: 2.0430867671966553 | eooooaaaaaaaaa \n",
            "r\\ Iteration: 3052 Loss: 1.816333293914795 | eooooaaraaaaaa \n",
            "r\\ Iteration: 3053 Loss: 1.9460222721099854 | eoaoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3054 Loss: 1.7613229751586914 | eooaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3055 Loss: 1.999753713607788 | eooaaaaaaaaaaa \n",
            "r\\ Iteration: 3056 Loss: 1.9117395877838135 | eoaoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3057 Loss: 1.8545253276824951 | eoaaoaaaaaaaaa \n",
            "r\\ Iteration: 3058 Loss: 1.7042646408081055 | eaoaaaaaaa \n",
            "r\\ Iteration: 3059 Loss: 1.7960047721862793 | eoooaaaaaaaa \n",
            "r\\ Iteration: 3060 Loss: 1.6139655113220215 | eoaaaaaaaaaaa \n",
            "r\\ Iteration: 3061 Loss: 1.91424560546875 | eoaaaaaa \n",
            "r\\ Iteration: 3062 Loss: 1.9918625354766846 | eooaaaaaaaaa \n",
            "r\\ Iteration: 3063 Loss: 1.8567602634429932 | eoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3064 Loss: 1.7552006244659424 | eooaaaasaaaaaaa \n",
            "r\\ Iteration: 3065 Loss: 1.7823197841644287 | eoaaaaaaaaaaa \n",
            "r\\ Iteration: 3066 Loss: 1.920069932937622 | eooaasaaaaaaa \n",
            "r\\ Iteration: 3067 Loss: 1.6932744979858398 | eaoaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3068 Loss: 1.8388915061950684 | eoaaaaaaaa \n",
            "r\\ Iteration: 3069 Loss: 2.0153591632843018 | eoaaaraaaaaaaa \n",
            "r\\ Iteration: 3070 Loss: 1.8295807838439941 | eoaasasaaaa \n",
            "r\\ Iteration: 3071 Loss: 1.7979235649108887 | eoaaaaasaasaasaaaa \n",
            "r\\ Iteration: 3072 Loss: 1.9204680919647217 | eoaaaaasaaasaa \n",
            "r\\ Iteration: 3073 Loss: 1.942434549331665 | eoaaaaasasaaaaaaa \n",
            "r\\ Iteration: 3074 Loss: 1.7024214267730713 | eaaaaaaaasaa \n",
            "r\\ Iteration: 3075 Loss: 1.862123727798462 | eoaaaaasaa \n",
            "r\\ Iteration: 3076 Loss: 1.7376182079315186 | eoaaaaaasasaaaaa \n",
            "r\\ Iteration: 3077 Loss: 1.9372804164886475 | eoaaaaaaaaaa \n",
            "r\\ Iteration: 3078 Loss: 1.7550435066223145 | eoaraaaaaaaaa \n",
            "r\\ Iteration: 3079 Loss: 1.7082087993621826 | eoaaaaaaaaaa \n",
            "r\\ Iteration: 3080 Loss: 1.8298280239105225 | eoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3081 Loss: 1.8768925666809082 | eoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3082 Loss: 1.695446252822876 | eooaaaaasaaaaaaa \n",
            "r\\ Iteration: 3083 Loss: 1.7473807334899902 | eoaaaaaraaaaaaaaa \n",
            "r\\ Iteration: 3084 Loss: 1.7589077949523926 | eoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3085 Loss: 1.746929407119751 | eoaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3086 Loss: 1.9666335582733154 | eoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3087 Loss: 1.6988778114318848 | eoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3088 Loss: 1.7807307243347168 | eoaaaaaaaa \n",
            "r\\ Iteration: 3089 Loss: 1.9948229789733887 | eoaaaaaaaaaaa \n",
            "r\\ Iteration: 3090 Loss: 1.8936195373535156 | eoaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3091 Loss: 1.7947583198547363 | eoaaaaaaaaaa \n",
            "r\\ Iteration: 3092 Loss: 1.8201971054077148 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3093 Loss: 1.7858872413635254 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3094 Loss: 1.737041711807251 | hoaaaaaasaaaaaaa \n",
            "r\\ Iteration: 3095 Loss: 1.7096991539001465 | hoaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3096 Loss: 1.7748217582702637 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3097 Loss: 1.7562031745910645 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3098 Loss: 2.0728447437286377 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3099 Loss: 1.7643277645111084 | hoaaaaaaaaasaaa \n",
            "r\\ Iteration: 3100 Loss: 1.7572987079620361 | hoaaaaaaaaa \n",
            "r\\ Iteration: 3101 Loss: 1.929569959640503 | hoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3102 Loss: 1.769230604171753 | hoaaaaaaaasaaaaaa \n",
            "r\\ Iteration: 3103 Loss: 1.81431245803833 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3104 Loss: 1.7444372177124023 | hoaaaaaaaaasaa \n",
            "r\\ Iteration: 3105 Loss: 1.8093185424804688 | eooaaaaaaaaaaa \n",
            "r\\ Iteration: 3106 Loss: 1.8439812660217285 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3107 Loss: 1.9105854034423828 | hooaaaaaaaaaaa \n",
            "r\\ Iteration: 3108 Loss: 1.8346781730651855 | hoaaaaaaaaa \n",
            "r\\ Iteration: 3109 Loss: 2.047119379043579 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3110 Loss: 1.6878056526184082 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3111 Loss: 1.8118586540222168 | hoaaaaaaaa \n",
            "r\\ Iteration: 3112 Loss: 2.071507453918457 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3113 Loss: 1.9761388301849365 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3114 Loss: 1.763612985610962 | hoaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3115 Loss: 1.9238049983978271 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3116 Loss: 1.8154613971710205 | hoaaaaaaaaa \n",
            "r\\ Iteration: 3117 Loss: 1.7716381549835205 | haaaaaaaaaaaa \n",
            "r\\ Iteration: 3118 Loss: 1.877105712890625 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3119 Loss: 1.7614061832427979 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3120 Loss: 1.9036016464233398 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3121 Loss: 2.013633966445923 | hoaaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3122 Loss: 1.8779199123382568 | honaaaaaaaaaa \n",
            "r\\ Iteration: 3123 Loss: 1.8160154819488525 | honanaaaaaaaaaa \n",
            "r\\ Iteration: 3124 Loss: 1.7892119884490967 | honaaaaaaaaaa \n",
            "r\\ Iteration: 3125 Loss: 1.9560775756835938 | honansshashsaa \n",
            "r\\ Iteration: 3126 Loss: 2.0281686782836914 | honaasaaaa \n",
            "r\\ Iteration: 3127 Loss: 1.872995138168335 | haraanasaaa \n",
            "r\\ Iteration: 3128 Loss: 1.978940725326538 | honarraaaaaaa \n",
            "r\\ Iteration: 3129 Loss: 1.7258186340332031 | hoaaaaaaaaasaaa \n",
            "r\\ Iteration: 3130 Loss: 1.7542555332183838 | hoonaraaaaasaaa \n",
            "r\\ Iteration: 3131 Loss: 1.799349069595337 | horaraaaaaaa \n",
            "r\\ Iteration: 3132 Loss: 1.8406457901000977 | horaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3133 Loss: 1.6516306400299072 | honaaaaaaaaaaaa \n",
            "r\\ Iteration: 3134 Loss: 1.934802532196045 | hooaaaa \n",
            "r\\ Iteration: 3135 Loss: 2.067704916000366 | hoaaaaaasaaaoaaa \n",
            "r\\ Iteration: 3136 Loss: 1.9779739379882812 | hooaaaaaaaaaaauaaa \n",
            "r\\ Iteration: 3137 Loss: 1.774282455444336 | hooaaaaaaaa \n",
            "r\\ Iteration: 3138 Loss: 1.902780532836914 | hooraaaaaauaaa \n",
            "r\\ Iteration: 3139 Loss: 1.6426312923431396 | hooaaaaoaaaa \n",
            "r\\ Iteration: 3140 Loss: 1.9869349002838135 | hoaoaaaaaaa \n",
            "r\\ Iteration: 3141 Loss: 1.9422461986541748 | hooaaoaaaauaaa \n",
            "r\\ Iteration: 3142 Loss: 1.826770305633545 | hoaaoaaaaaaaa \n",
            "r\\ Iteration: 3143 Loss: 1.8959782123565674 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3144 Loss: 1.7798254489898682 | hoaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3145 Loss: 1.7956573963165283 | hoaaaaoaaaa \n",
            "r\\ Iteration: 3146 Loss: 2.008812189102173 | hoaoaaaaaaaaa \n",
            "r\\ Iteration: 3147 Loss: 1.6737871170043945 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3148 Loss: 1.7695884704589844 | hoaaaoaaaaaa \n",
            "r\\ Iteration: 3149 Loss: 1.8831589221954346 | hooaaaaaaaauaaaaa \n",
            "r\\ Iteration: 3150 Loss: 1.7875280380249023 | hoaaaaaaaa \n",
            "r\\ Iteration: 3151 Loss: 1.7441792488098145 | hoaaaaauauaaa \n",
            "r\\ Iteration: 3152 Loss: 1.7564003467559814 | hooaaaaaaaaaaaa \n",
            "r\\ Iteration: 3153 Loss: 1.7611784934997559 | hoaaaaaaauauaaa \n",
            "r\\ Iteration: 3154 Loss: 1.6297717094421387 | hoaaaaaaaa \n",
            "r\\ Iteration: 3155 Loss: 2.1017749309539795 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3156 Loss: 1.9180448055267334 | hoaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3157 Loss: 1.8271534442901611 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3158 Loss: 1.833582878112793 | hoaaaaaaaa \n",
            "r\\ Iteration: 3159 Loss: 1.951828956604004 | eoaaaaaaaauauaau \n",
            "r\\ Iteration: 3160 Loss: 1.7607653141021729 | eraaaaaaaaau \n",
            "r\\ Iteration: 3161 Loss: 1.7923614978790283 | eraaaaauauaau \n",
            "r\\ Iteration: 3162 Loss: 1.7114498615264893 | eoraaaaaaaaaaau \n",
            "r\\ Iteration: 3163 Loss: 1.8965790271759033 | eeraaauaau \n",
            "r\\ Iteration: 3164 Loss: 1.744011640548706 | eeaaaaaaaaauauaau \n",
            "r\\ Iteration: 3165 Loss: 1.7057271003723145 | eoaaaauaaauauaau \n",
            "r\\ Iteration: 3166 Loss: 1.7519240379333496 | eoaaaauauaau \n",
            "r\\ Iteration: 3167 Loss: 1.6178665161132812 | eraaaaauaau \n",
            "r\\ Iteration: 3168 Loss: 1.9559433460235596 | eoaurasauauaau \n",
            "r\\ Iteration: 3169 Loss: 1.7773234844207764 | eraaaaauaaaa \n",
            "r\\ Iteration: 3170 Loss: 1.9104440212249756 | eraaaaraauauaau \n",
            "r\\ Iteration: 3171 Loss: 1.733170986175537 | eaaaaaaasauauaau \n",
            "r\\ Iteration: 3172 Loss: 1.7651925086975098 | eoaaaaaasauaaau \n",
            "r\\ Iteration: 3173 Loss: 1.8937408924102783 | earararaaauaau \n",
            "r\\ Iteration: 3174 Loss: 1.7522706985473633 | eoanaaraaaaasaau \n",
            "r\\ Iteration: 3175 Loss: 1.84641695022583 | eranaaaauauaau \n",
            "r\\ Iteration: 3176 Loss: 1.7556877136230469 | eoraaraaaa \n",
            "r\\ Iteration: 3177 Loss: 2.0358335971832275 | eraaaaauaau \n",
            "r\\ Iteration: 3178 Loss: 1.9562246799468994 | eoaaaaaauauaau \n",
            "r\\ Iteration: 3179 Loss: 1.8110718727111816 | honaaaauauaau \n",
            "r\\ Iteration: 3180 Loss: 1.61460280418396 | hoaaaaaauaaa \n",
            "r\\ Iteration: 3181 Loss: 1.969754695892334 | hraauaauauaau \n",
            "r\\ Iteration: 3182 Loss: 1.730658769607544 | hoaaaaaaauauaa \n",
            "r\\ Iteration: 3183 Loss: 1.7300145626068115 | hoaaaaaaa \n",
            "r\\ Iteration: 3184 Loss: 2.2269673347473145 | haaaaaauauaau \n",
            "r\\ Iteration: 3185 Loss: 1.6130399703979492 | hooausauauaau \n",
            "r\\ Iteration: 3186 Loss: 1.6736419200897217 | hoaaauauaau \n",
            "r\\ Iteration: 3187 Loss: 1.6948630809783936 | haaaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3188 Loss: 1.9254250526428223 | hlaaaaauaaaau \n",
            "r\\ Iteration: 3189 Loss: 1.6278607845306396 | hhaaaaaaaaaa \n",
            "r\\ Iteration: 3190 Loss: 1.9625639915466309 | hraaaaaaasaaaaaau \n",
            "r\\ Iteration: 3191 Loss: 1.8708415031433105 | hoaaaaaaaaaaaau \n",
            "r\\ Iteration: 3192 Loss: 1.8556749820709229 | hraaauaaaau \n",
            "r\\ Iteration: 3193 Loss: 1.6849162578582764 | hhaaaaaaaaaaaau \n",
            "r\\ Iteration: 3194 Loss: 1.7560527324676514 | haaaaaaaaaaa \n",
            "r\\ Iteration: 3195 Loss: 1.8592965602874756 | hhoaaaaaaaa \n",
            "r\\ Iteration: 3196 Loss: 1.9289746284484863 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3197 Loss: 1.736971378326416 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3198 Loss: 1.6220653057098389 | hooaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3199 Loss: 1.7039735317230225 | haoaaaaaaaaaaa \n",
            "r\\ Iteration: 3200 Loss: 1.8945846557617188 | hooaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3201 Loss: 1.6724989414215088 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3202 Loss: 1.731132984161377 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3203 Loss: 1.6391451358795166 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3204 Loss: 1.8332819938659668 | hooaaaaaaaaaaa \n",
            "r\\ Iteration: 3205 Loss: 1.9211804866790771 | hoaaaaaaaaaa \n",
            "r\\ Iteration: 3206 Loss: 1.7020814418792725 | hoaaaaaaasaaaaaaa \n",
            "r\\ Iteration: 3207 Loss: 1.8247802257537842 | hoaaasaaaaaaa \n",
            "r\\ Iteration: 3208 Loss: 1.7630727291107178 | hoaaasaaaaaaaaaa \n",
            "r\\ Iteration: 3209 Loss: 1.8316075801849365 | hoaaaaaaaa \n",
            "r\\ Iteration: 3210 Loss: 1.8956806659698486 | hoaaaaaaaaaaa \n",
            "r\\ Iteration: 3211 Loss: 1.7277650833129883 | hoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3212 Loss: 1.942859172821045 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3213 Loss: 1.6966350078582764 | hoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3214 Loss: 1.7835710048675537 | hoaaaaaaasaaaaaaa \n",
            "r\\ Iteration: 3215 Loss: 1.7764158248901367 | hoaaaasaaaaaaaaaa \n",
            "r\\ Iteration: 3216 Loss: 1.9876275062561035 | hoasasaaaasaa \n",
            "r\\ Iteration: 3217 Loss: 1.9163033962249756 | hoasaaaaaaa \n",
            "r\\ Iteration: 3218 Loss: 1.609565258026123 | hoaasasaasaaaaaaa \n",
            "r\\ Iteration: 3219 Loss: 1.6176090240478516 | hooaaaaaaasaaaaaaa \n",
            "r\\ Iteration: 3220 Loss: 1.8343641757965088 | hoaasaaaaasaaa \n",
            "r\\ Iteration: 3221 Loss: 1.6920080184936523 | hooaaaasaaaa \n",
            "r\\ Iteration: 3222 Loss: 1.8432295322418213 | hoaaaaaaaaaaaa \n",
            "r\\ Iteration: 3223 Loss: 1.8159050941467285 | hoaaasaaaaasaa \n",
            "r\\ Iteration: 3224 Loss: 1.8697865009307861 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3225 Loss: 1.8112289905548096 | hroaaaaaaaaa \n",
            "r\\ Iteration: 3226 Loss: 1.67106032371521 | horoaaasaaaaaaa \n",
            "r\\ Iteration: 3227 Loss: 1.7489521503448486 | hoaaaasaasaaaoaaa \n",
            "r\\ Iteration: 3228 Loss: 1.9277915954589844 | hoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3229 Loss: 1.6437911987304688 | hoaoaasaaaaaaa \n",
            "r\\ Iteration: 3230 Loss: 1.6928632259368896 | hoaraaaaaaaaa \n",
            "r\\ Iteration: 3231 Loss: 1.875950813293457 | hoaoaaaaaaoaaa \n",
            "r\\ Iteration: 3232 Loss: 1.978151798248291 | honaaaaaaaaa \n",
            "r\\ Iteration: 3233 Loss: 1.8684062957763672 | hoaaraaaaaaaaa \n",
            "r\\ Iteration: 3234 Loss: 1.6254642009735107 | hraanaaaaaaaaaa \n",
            "r\\ Iteration: 3235 Loss: 1.8840148448944092 | hoaaraaaa \n",
            "r\\ Iteration: 3236 Loss: 1.937880039215088 | honaaraasaaaaaaa \n",
            "r\\ Iteration: 3237 Loss: 1.924628496170044 | hoaaasasaaaaaaa \n",
            "r\\ Iteration: 3238 Loss: 1.9247829914093018 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3239 Loss: 1.9202046394348145 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3240 Loss: 1.6732957363128662 | hoaaaaaasasaa \n",
            "r\\ Iteration: 3241 Loss: 1.89495849609375 | hoaaaaaaaaaau \n",
            "r\\ Iteration: 3242 Loss: 1.8424503803253174 | horanaaaaaaaaau \n",
            "r\\ Iteration: 3243 Loss: 1.7785465717315674 | honanaaaaaaaa \n",
            "r\\ Iteration: 3244 Loss: 2.156644821166992 | hooaaaaaaaaaau \n",
            "r\\ Iteration: 3245 Loss: 1.7553443908691406 | horaaaaaaaaaaaau \n",
            "r\\ Iteration: 3246 Loss: 1.6155760288238525 | hoaaaaasauaaaau \n",
            "r\\ Iteration: 3247 Loss: 1.7733099460601807 | hoaaaaaaaaau \n",
            "r\\ Iteration: 3248 Loss: 1.902388572692871 | hoaaaasaasaaaaaaau \n",
            "r\\ Iteration: 3249 Loss: 1.8801743984222412 | hoaranauauaau \n",
            "r\\ Iteration: 3250 Loss: 1.6937923431396484 | hoaaaaasauauaau \n",
            "r\\ Iteration: 3251 Loss: 1.706247091293335 | hooaasauaaaaau \n",
            "r\\ Iteration: 3252 Loss: 1.7797136306762695 | hooaaaarauauaau \n",
            "r\\ Iteration: 3253 Loss: 1.7596993446350098 | horaaaussaaau \n",
            "r\\ Iteration: 3254 Loss: 1.8690826892852783 | hoaaanasaaa \n",
            "r\\ Iteration: 3255 Loss: 2.1340060234069824 | hoaaaaaaaarau \n",
            "r\\ Iteration: 3256 Loss: 1.9436111450195312 | hoaaanaaaaaasaa \n",
            "r\\ Iteration: 3257 Loss: 1.8151395320892334 | honarauausau \n",
            "r\\ Iteration: 3258 Loss: 1.616222620010376 | hooaaansaususau \n",
            "r\\ Iteration: 3259 Loss: 1.8328609466552734 | hoanaraaausaa \n",
            "r\\ Iteration: 3260 Loss: 1.6425342559814453 | hroraaaasaaaauaaa \n",
            "r\\ Iteration: 3261 Loss: 1.8309147357940674 | hoonaanaaaaauaaa \n",
            "r\\ Iteration: 3262 Loss: 1.7789466381072998 | heaaaaaaaaaaa \n",
            "r\\ Iteration: 3263 Loss: 1.9196045398712158 | heaaasaaauaaa \n",
            "r\\ Iteration: 3264 Loss: 1.8213331699371338 | hooaaaaaaa \n",
            "r\\ Iteration: 3265 Loss: 1.9138455390930176 | hooaaaaaaaasaa \n",
            "r\\ Iteration: 3266 Loss: 1.8517189025878906 | hoaaaaaaaauaaa \n",
            "r\\ Iteration: 3267 Loss: 1.9293341636657715 | hoaasaaa \n",
            "r\\ Iteration: 3268 Loss: 1.8777267932891846 | hooaasaaauaaa \n",
            "r\\ Iteration: 3269 Loss: 1.6959211826324463 | hooasasaa|a \n",
            "r\\ Iteration: 3270 Loss: 1.7813968658447266 | hioaaaaaas|aaaaaa \n",
            "r\\ Iteration: 3271 Loss: 1.8201408386230469 | hoaassaaaaaaaa \n",
            "r\\ Iteration: 3272 Loss: 2.0219738483428955 | hooaaaaas|aaaa|a \n",
            "r\\ Iteration: 3273 Loss: 1.961890697479248 | hooaaasaaaaaa|a \n",
            "r\\ Iteration: 3274 Loss: 1.8589341640472412 | hooaaaaaaa|aaaaa \n",
            "r\\ Iteration: 3275 Loss: 1.832859754562378 | hooaaaasasaa \n",
            "r\\ Iteration: 3276 Loss: 1.7667388916015625 | hooaaaaaaaaaaa|aaaa|a \n",
            "r\\ Iteration: 3277 Loss: 1.829026460647583 | hooaoaaaaasa|aaaa|a \n",
            "r\\ Iteration: 3278 Loss: 1.8354966640472412 | hooraaas|aaaa|a \n",
            "r\\ Iteration: 3279 Loss: 1.6857259273529053 | hooaaaosasaa|aa|a \n",
            "r\\ Iteration: 3280 Loss: 1.9098260402679443 | hoooaosaaaaa|a \n",
            "r\\ Iteration: 3281 Loss: 1.7631492614746094 | hooaoaosaaaaa|a \n",
            "r\\ Iteration: 3282 Loss: 1.7681825160980225 | hoonaaaos|aaaaaa \n",
            "r\\ Iteration: 3283 Loss: 1.7891204357147217 | hioooaas|aaaaaa \n",
            "r\\ Iteration: 3284 Loss: 1.7160069942474365 | hooooaaaoaosa|a \n",
            "r\\ Iteration: 3285 Loss: 1.7131612300872803 | hiooraa \n",
            "r\\ Iteration: 3286 Loss: 1.7036001682281494 | hooooraoraaaaaaa \n",
            "r\\ Iteration: 3287 Loss: 1.901167392730713 | hoooaraaaaaaa \n",
            "r\\ Iteration: 3288 Loss: 1.6358978748321533 | hooonaoroosoaaa \n",
            "r\\ Iteration: 3289 Loss: 1.9450337886810303 | hooaoraoaoaaa \n",
            "r\\ Iteration: 3290 Loss: 1.8624002933502197 | hirooaaaanoaa \n",
            "r\\ Iteration: 3291 Loss: 1.9751863479614258 | hooaoaoraaaaaaa \n",
            "r\\ Iteration: 3292 Loss: 1.7746074199676514 | doooaaaaaaaa \n",
            "r\\ Iteration: 3293 Loss: 1.6552438735961914 | doooaaroaoos|a \n",
            "r\\ Iteration: 3294 Loss: 1.8741340637207031 | dooorauauaaa \n",
            "r\\ Iteration: 3295 Loss: 1.6974992752075195 | dooooaauaua|a \n",
            "r\\ Iteration: 3296 Loss: 1.7516334056854248 | doooaar|uaua|u \n",
            "r\\ Iteration: 3297 Loss: 1.7021276950836182 | dooaaoaa|uaua|u \n",
            "r\\ Iteration: 3298 Loss: 1.8127272129058838 | doooaaaaraa|u \n",
            "r\\ Iteration: 3299 Loss: 1.865095853805542 | doooraaaaaa \n",
            "r\\ Iteration: 3300 Loss: 1.9405195713043213 | dooooaaoaaa \n",
            "r\\ Iteration: 3301 Loss: 2.1789815425872803 | dooooaaaaaaa \n",
            "r\\ Iteration: 3302 Loss: 1.8991479873657227 | doooaaaauaau \n",
            "r\\ Iteration: 3303 Loss: 1.8014628887176514 | dooooaaauaau \n",
            "r\\ Iteration: 3304 Loss: 1.801630973815918 | dooooauaurau \n",
            "r\\ Iteration: 3305 Loss: 1.7632761001586914 | doooooaoaaaur|u \n",
            "r\\ Iteration: 3306 Loss: 1.9584698677062988 | doororor|ururau \n",
            "r\\ Iteration: 3307 Loss: 1.6567230224609375 | doooraaaururau \n",
            "r\\ Iteration: 3308 Loss: 1.7292814254760742 | dooooaar|ururau \n",
            "r\\ Iteration: 3309 Loss: 1.8562583923339844 | dooooor|ururau \n",
            "r\\ Iteration: 3310 Loss: 1.62974214553833 | doooaorauaar|ururau \n",
            "r\\ Iteration: 3311 Loss: 1.8300471305847168 | dooooaaaurau \n",
            "r\\ Iteration: 3312 Loss: 1.9126098155975342 | dooooraraa \n",
            "r\\ Iteration: 3313 Loss: 1.7771282196044922 | dooooaaaaurau \n",
            "r\\ Iteration: 3314 Loss: 1.9291436672210693 | dooooraauaaraau \n",
            "r\\ Iteration: 3315 Loss: 1.7295200824737549 | deoooooraururau \n",
            "r\\ Iteration: 3316 Loss: 1.7113029956817627 | deoaooraar|ururau \n",
            "r\\ Iteration: 3317 Loss: 1.762960433959961 | doooooaauaau \n",
            "r\\ Iteration: 3318 Loss: 1.7783982753753662 | dooooorauauaau \n",
            "r\\ Iteration: 3319 Loss: 1.6476991176605225 | dooooroaauauaau \n",
            "r\\ Iteration: 3320 Loss: 1.7088901996612549 | dooooorauauaau \n",
            "r\\ Iteration: 3321 Loss: 1.725862979888916 | doooaaauraraa \n",
            "r\\ Iteration: 3322 Loss: 1.867224931716919 | dooaoaaaauauaau \n",
            "r\\ Iteration: 3323 Loss: 1.83915376663208 | deoaooaaaauauaau \n",
            "r\\ Iteration: 3324 Loss: 1.7236950397491455 | dooaearaaa \n",
            "r\\ Iteration: 3325 Loss: 2.196762800216675 | deaooar|uausau \n",
            "r\\ Iteration: 3326 Loss: 1.7027194499969482 | doooaoauauauaau \n",
            "r\\ Iteration: 3327 Loss: 1.818253755569458 | doaoaar|uaus|u \n",
            "r\\ Iteration: 3328 Loss: 1.700395107269287 | dooaasuaasa|u \n",
            "r\\ Iteration: 3329 Loss: 1.8436057567596436 | dooaaususa|au \n",
            "r\\ Iteration: 3330 Loss: 1.957510232925415 | dooaasaa|aas|u \n",
            "r\\ Iteration: 3331 Loss: 1.8710458278656006 | dooaaaaua|a \n",
            "r\\ Iteration: 3332 Loss: 2.030527114868164 | doasa|aaaa|a \n",
            "r\\ Iteration: 3333 Loss: 1.9755668640136719 | dooaas||uaua|u \n",
            "r\\ Iteration: 3334 Loss: 1.6720876693725586 | doaaaus|uaua|u \n",
            "r\\ Iteration: 3335 Loss: 1.7105433940887451 | dooaa \n",
            "r\\ Iteration: 3336 Loss: 2.745530605316162 | dooaunas|aaaus|an|u \n",
            "r\\ Iteration: 3337 Loss: 2.0295188426971436 | droaanas|uaua|u \n",
            "r\\ Iteration: 3338 Loss: 1.8790805339813232 | doois|uaua|u \n",
            "r\\ Iteration: 3339 Loss: 1.8576719760894775 | donaaasaaaunia|u \n",
            "r\\ Iteration: 3340 Loss: 1.903947353363037 | donais|uaua|u \n",
            "r\\ Iteration: 3341 Loss: 1.7472248077392578 | dooas|aaia|u \n",
            "r\\ Iteration: 3342 Loss: 1.9928956031799316 | deoanaan|inanniaua|u \n",
            "r\\ Iteration: 3343 Loss: 1.8774104118347168 | doaiaa|uaua|u \n",
            "r\\ Iteration: 3344 Loss: 1.6697063446044922 | donn|unaiaan|uaua|u \n",
            "r\\ Iteration: 3345 Loss: 1.7695682048797607 | doinaain|uaua|u \n",
            "r\\ Iteration: 3346 Loss: 1.6400513648986816 | driaaiinanaia|u \n",
            "r\\ Iteration: 3347 Loss: 1.9047420024871826 | doanoiaa|usua|u \n",
            "r\\ Iteration: 3348 Loss: 1.8113834857940674 | donnoaaunaan|a \n",
            "r\\ Iteration: 3349 Loss: 1.8729374408721924 | doinoinaun|u \n",
            "r\\ Iteration: 3350 Loss: 1.9871184825897217 | dorauaiinan|usur|u \n",
            "r\\ Iteration: 3351 Loss: 1.7067160606384277 | donanaianausua|u \n",
            "r\\ Iteration: 3352 Loss: 1.7608072757720947 | dooaas|asaasoa|u \n",
            "r\\ Iteration: 3353 Loss: 2.0149385929107666 | dosauaaunais|u \n",
            "r\\ Iteration: 3354 Loss: 1.9348475933074951 | donaraa|urur|u \n",
            "r\\ Iteration: 3355 Loss: 1.7886221408843994 | doonaasanasaau \n",
            "r\\ Iteration: 3356 Loss: 1.949692964553833 | dosaaunaaurur|u \n",
            "r\\ Iteration: 3357 Loss: 1.7434630393981934 | dosnaaaras|usurau \n",
            "r\\ Iteration: 3358 Loss: 1.862393856048584 | doonasosasanasaau \n",
            "r\\ Iteration: 3359 Loss: 1.9035253524780273 | dosaasaaususau \n",
            "r\\ Iteration: 3360 Loss: 1.8505003452301025 | dosnasasaraa \n",
            "r\\ Iteration: 3361 Loss: 1.93731689453125 | dosasanaususaa \n",
            "r\\ Iteration: 3362 Loss: 1.6291594505310059 | daraassaususau \n",
            "r\\ Iteration: 3363 Loss: 1.746246576309204 | dooaasssasaasaususau \n",
            "r\\ Iteration: 3364 Loss: 1.7829492092132568 | doosaususossusau \n",
            "r\\ Iteration: 3365 Loss: 1.7345547676086426 | doosaasaosaususau \n",
            "r\\ Iteration: 3366 Loss: 1.7955272197723389 | dossosaususau \n",
            "r\\ Iteration: 3367 Loss: 1.6870543956756592 | doaaosasaossusau \n",
            "r\\ Iteration: 3368 Loss: 1.760894775390625 | doososaususau \n",
            "r\\ Iteration: 3369 Loss: 1.708319902420044 | dosoaususaosua \n",
            "r\\ Iteration: 3370 Loss: 1.8503267765045166 | dosaaros|usus|u \n",
            "r\\ Iteration: 3371 Loss: 1.8125243186950684 | dosauos|usus|u \n",
            "r\\ Iteration: 3372 Loss: 1.617544412612915 | dosossasau \n",
            "r\\ Iteration: 3373 Loss: 2.019662857055664 | dooososonos|usus|u \n",
            "r\\ Iteration: 3374 Loss: 1.754164218902588 | dorosss|usosoo \n",
            "r\\ Iteration: 3375 Loss: 1.9980697631835938 | doorason|ususa \n",
            "r\\ Iteration: 3376 Loss: 1.8204946517944336 | doronoausus|u \n",
            "r\\ Iteration: 3377 Loss: 1.7472307682037354 | donsos|usus|u \n",
            "r\\ Iteration: 3378 Loss: 1.640458106994629 | droonaos|a \n",
            "r\\ Iteration: 3379 Loss: 1.9761765003204346 | donsonnaona|usus|u \n",
            "r\\ Iteration: 3380 Loss: 1.73807954788208 | dooonos|usus|u \n",
            "r\\ Iteration: 3381 Loss: 1.6828577518463135 | doonar|usur|u \n",
            "r\\ Iteration: 3382 Loss: 1.7472248077392578 | dooror|r|urur|u \n",
            "r\\ Iteration: 3383 Loss: 1.6355156898498535 | dorsorus|uru|ar|u \n",
            "r\\ Iteration: 3384 Loss: 1.6824543476104736 | doroanorus|a \n",
            "r\\ Iteration: 3385 Loss: 1.9338414669036865 | doooranaoor|urur|u \n",
            "r\\ Iteration: 3386 Loss: 1.7703120708465576 | donorar|urur|u \n",
            "r\\ Iteration: 3387 Loss: 1.757140874862671 | dorrau||r| \n",
            "r\\ Iteration: 3388 Loss: 2.1937496662139893 | dooaunr|as|u \n",
            "r\\ Iteration: 3389 Loss: 1.9081554412841797 | dooror|urur|u \n",
            "r\\ Iteration: 3390 Loss: 1.6914327144622803 | dooraasaar|u \n",
            "r\\ Iteration: 3391 Loss: 1.915766716003418 | doraroraonor|u \n",
            "r\\ Iteration: 3392 Loss: 1.8963682651519775 | dororrar|or|urur|u \n",
            "r\\ Iteration: 3393 Loss: 1.7302970886230469 | haorar|urur|u \n",
            "r\\ Iteration: 3394 Loss: 1.7638826370239258 | horooraor|u \n",
            "r\\ Iteration: 3395 Loss: 1.9718520641326904 | hooonoor|urur|u \n",
            "r\\ Iteration: 3396 Loss: 1.7562305927276611 | hoooor|r|u \n",
            "r\\ Iteration: 3397 Loss: 2.015235424041748 | horoonooor|oo \n",
            "r\\ Iteration: 3398 Loss: 2.098844289779663 | horrr|r|urur|u \n",
            "r\\ Iteration: 3399 Loss: 1.744917869567871 | honooroor|roor|u \n",
            "r\\ Iteration: 3400 Loss: 2.026512861251831 | honon|oroon| \n",
            "r\\ Iteration: 3401 Loss: 2.0453834533691406 | hoor|urur|u \n",
            "r\\ Iteration: 3402 Loss: 1.733330249786377 | hoonrurononoo \n",
            "r\\ Iteration: 3403 Loss: 1.8823823928833008 | hooononoroo \n",
            "r\\ Iteration: 3404 Loss: 1.788403034210205 | hortauor|onorau \n",
            "r\\ Iteration: 3405 Loss: 1.9713492393493652 | honooraraorau \n",
            "r\\ Iteration: 3406 Loss: 1.9166886806488037 | hoornororoo \n",
            "r\\ Iteration: 3407 Loss: 1.9381446838378906 | hoororaoortonrau \n",
            "r\\ Iteration: 3408 Loss: 1.9011545181274414 | hoortororonoau \n",
            "r\\ Iteration: 3409 Loss: 1.9439566135406494 | horononororau \n",
            "r\\ Iteration: 3410 Loss: 1.8389930725097656 | hooraononno \n",
            "r\\ Iteration: 3411 Loss: 1.872274398803711 | hononounoororou \n",
            "r\\ Iteration: 3412 Loss: 1.9254794120788574 | hooranrooraururau \n",
            "r\\ Iteration: 3413 Loss: 1.7677640914916992 | hoononrartunorau \n",
            "r\\ Iteration: 3414 Loss: 1.855583906173706 | hororrto \n",
            "r\\ Iteration: 3415 Loss: 1.9103755950927734 | honotrau \n",
            "r\\ Iteration: 3416 Loss: 1.8208253383636475 | horrtooraururau \n",
            "r\\ Iteration: 3417 Loss: 1.7816441059112549 | horrrnoutto \n",
            "r\\ Iteration: 3418 Loss: 1.9324040412902832 | hooraunonraurur|u \n",
            "r\\ Iteration: 3419 Loss: 1.6715857982635498 | heononurur|u \n",
            "r\\ Iteration: 3420 Loss: 1.8432388305664062 | horaotur|uutau \n",
            "r\\ Iteration: 3421 Loss: 1.912522554397583 | hoonunotaurur|u \n",
            "r\\ Iteration: 3422 Loss: 1.8248836994171143 | hoonaautarutoraau \n",
            "r\\ Iteration: 3423 Loss: 1.9116504192352295 | hoorusurau \n",
            "r\\ Iteration: 3424 Loss: 1.9935650825500488 | hornuur|urur|u \n",
            "r\\ Iteration: 3425 Loss: 1.7550506591796875 | horaaanaau \n",
            "r\\ Iteration: 3426 Loss: 1.914393424987793 | horauruu||urur|u \n",
            "r\\ Iteration: 3427 Loss: 1.7374763488769531 | hoaurusu|ar|saur|u \n",
            "r\\ Iteration: 3428 Loss: 1.9344780445098877 | harour|urur|u \n",
            "r\\ Iteration: 3429 Loss: 1.674182653427124 | horaar|us|u \n",
            "r\\ Iteration: 3430 Loss: 2.0114171504974365 | horruurh|uu \n",
            "r\\ Iteration: 3431 Loss: 2.0332391262054443 | horros|au|||usus|u \n",
            "r\\ Iteration: 3432 Loss: 1.7579035758972168 | horoas|s|| \n",
            "r\\ Iteration: 3433 Loss: 1.935591697692871 | horar|usr|u \n",
            "r\\ Iteration: 3434 Loss: 1.8295295238494873 | horaasas|a \n",
            "r\\ Iteration: 3435 Loss: 1.701277494430542 | horutana|asaa \n",
            "r\\ Iteration: 3436 Loss: 1.865485429763794 | harausasusau \n",
            "r\\ Iteration: 3437 Loss: 1.8705189228057861 | haraaaaa|asaau \n",
            "r\\ Iteration: 3438 Loss: 1.897707223892212 | harasasausaususau \n",
            "r\\ Iteration: 3439 Loss: 1.6773779392242432 | honaaasaa|a \n",
            "r\\ Iteration: 3440 Loss: 1.8855493068695068 | haonsaasasaaa \n",
            "r\\ Iteration: 3441 Loss: 1.9925899505615234 | hooaaasaau \n",
            "r\\ Iteration: 3442 Loss: 2.0067877769470215 | haaaaauaaaaa \n",
            "r\\ Iteration: 3443 Loss: 1.7187798023223877 | haaaasaasaasaaaaaaa \n",
            "r\\ Iteration: 3444 Loss: 1.8461198806762695 | hiaaasaaaaasaa \n",
            "r\\ Iteration: 3445 Loss: 1.8859758377075195 | haaaauaaaaa \n",
            "r\\ Iteration: 3446 Loss: 1.7551872730255127 | haaaaaasaaaaaaa \n",
            "r\\ Iteration: 3447 Loss: 1.8412225246429443 | haraasaaaaasaau \n",
            "r\\ Iteration: 3448 Loss: 1.7004776000976562 | daaaauaaauaaaaa \n",
            "r\\ Iteration: 3449 Loss: 1.7010979652404785 | daraaa \n",
            "r\\ Iteration: 3450 Loss: 2.088033437728882 | daaasauaaaaa \n",
            "r\\ Iteration: 3451 Loss: 1.710360050201416 | daaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3452 Loss: 1.7331957817077637 | daraaaaaaaaa \n",
            "r\\ Iteration: 3453 Loss: 1.9695014953613281 | daraasaaaaaasaa \n",
            "r\\ Iteration: 3454 Loss: 1.6310877799987793 | daraaaaaasaa \n",
            "r\\ Iteration: 3455 Loss: 1.8737218379974365 | daaaasasaaaa \n",
            "r\\ Iteration: 3456 Loss: 1.7755210399627686 | daraaaaaaaaaa \n",
            "r\\ Iteration: 3457 Loss: 1.9713118076324463 | daraasaaaasaa \n",
            "r\\ Iteration: 3458 Loss: 1.761960744857788 | daraaaaaaaaaa \n",
            "r\\ Iteration: 3459 Loss: 2.1792850494384766 | daaasaaaaaaa \n",
            "r\\ Iteration: 3460 Loss: 1.797823190689087 | daaaasaaaaaaa \n",
            "r\\ Iteration: 3461 Loss: 1.8144960403442383 | daraaaaaaa \n",
            "r\\ Iteration: 3462 Loss: 1.8423161506652832 | daaaaaaaaasaaaaaaa \n",
            "r\\ Iteration: 3463 Loss: 2.0181102752685547 | daraaaa|asaaaaaaa \n",
            "r\\ Iteration: 3464 Loss: 1.7645199298858643 | daasaaaaaaa \n",
            "r\\ Iteration: 3465 Loss: 1.8120019435882568 | daraaaaaaa \n",
            "r\\ Iteration: 3466 Loss: 1.8218717575073242 | daaaaaasasaaasaaa \n",
            "r\\ Iteration: 3467 Loss: 1.8463492393493652 | daraaasaaaaaaaa \n",
            "r\\ Iteration: 3468 Loss: 1.896390438079834 | dasaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3469 Loss: 1.7510507106781006 | daraassauaaaaa \n",
            "r\\ Iteration: 3470 Loss: 1.806563377380371 | daaaaaaaaasaaasaaa \n",
            "r\\ Iteration: 3471 Loss: 1.9161713123321533 | dasaasasauaaaaa \n",
            "r\\ Iteration: 3472 Loss: 1.720038652420044 | daaaaaaasauaaaaa \n",
            "r\\ Iteration: 3473 Loss: 1.7516248226165771 | dasaaaaaaasauaaaaa \n",
            "r\\ Iteration: 3474 Loss: 1.743990182876587 | dasaasaaaaasaa \n",
            "r\\ Iteration: 3475 Loss: 1.8834428787231445 | daasaaaaaaasaaa \n",
            "r\\ Iteration: 3476 Loss: 2.0322177410125732 | daaaaaaaaaaaaa \n",
            "r\\ Iteration: 3477 Loss: 1.7428088188171387 | daaaasasauaaaaa \n",
            "r\\ Iteration: 3478 Loss: 1.630411148071289 | daaaaaaaaaaa \n",
            "r\\ Iteration: 3479 Loss: 1.870232105255127 | daaaaaaaaaaaa \n",
            "r\\ Iteration: 3480 Loss: 1.888258695602417 | daaasaaaaaaa \n",
            "r\\ Iteration: 3481 Loss: 1.7715647220611572 | daaaaaaaaasasaa \n",
            "r\\ Iteration: 3482 Loss: 1.766164779663086 | daaaaasaaaaaaa \n",
            "r\\ Iteration: 3483 Loss: 1.674635648727417 | daaaaaaaaasaa \n",
            "r\\ Iteration: 3484 Loss: 1.9582812786102295 | daraaaasaaaaaa \n",
            "r\\ Iteration: 3485 Loss: 1.8613686561584473 | daraaaaaaaasaa \n",
            "r\\ Iteration: 3486 Loss: 1.8638932704925537 | daaasaaaaaaa \n",
            "r\\ Iteration: 3487 Loss: 1.7398569583892822 | daaaaaaaaaasaaaaaaa \n",
            "r\\ Iteration: 3488 Loss: 1.8391304016113281 | daaaaaaaaaaaa \n",
            "r\\ Iteration: 3489 Loss: 1.7852938175201416 | daaaaasaasaaaaaaaa \n",
            "r\\ Iteration: 3490 Loss: 1.8528633117675781 | haaaaaaaaaaaa \n",
            "r\\ Iteration: 3491 Loss: 1.7574634552001953 | haaaaaaaaaraaaa \n",
            "r\\ Iteration: 3492 Loss: 1.9614789485931396 | haaaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3493 Loss: 1.8996963500976562 | haraaaaaaaraaaa \n",
            "r\\ Iteration: 3494 Loss: 1.9475157260894775 | haaaaaaaaaraaaaa \n",
            "r\\ Iteration: 3495 Loss: 2.0462963581085205 | haraaaaaaaaa \n",
            "r\\ Iteration: 3496 Loss: 1.603290319442749 | haaaaaraaaaaaa \n",
            "r\\ Iteration: 3497 Loss: 1.7900798320770264 | haaaaaraaaaaaa \n",
            "r\\ Iteration: 3498 Loss: 1.891010046005249 | haraaaaaaaraa \n",
            "r\\ Iteration: 3499 Loss: 1.9598910808563232 | haaaaaaaaraa \n",
            "r\\ Iteration: 3500 Loss: 1.8863108158111572 | haraaraaaaaaa \n",
            "r\\ Iteration: 3501 Loss: 1.68636155128479 | hararaanauauaaa \n",
            "r\\ Iteration: 3502 Loss: 1.8356881141662598 | hararraraarauauaaa \n",
            "r\\ Iteration: 3503 Loss: 1.7211170196533203 | haraaaaaaa \n",
            "r\\ Iteration: 3504 Loss: 1.904871940612793 | horaaarauauaaaaaa \n",
            "r\\ Iteration: 3505 Loss: 1.824336051940918 | hoaraaaraaauauaaa \n",
            "r\\ Iteration: 3506 Loss: 1.7732207775115967 | hararauauaaa \n",
            "r\\ Iteration: 3507 Loss: 1.6177923679351807 | haaraaaaaaaaa \n",
            "r\\ Iteration: 3508 Loss: 2.0451409816741943 | haaaaraaaaaa \n",
            "r\\ Iteration: 3509 Loss: 1.9077205657958984 | horaarauauaaaaaa \n",
            "r\\ Iteration: 3510 Loss: 1.8209669589996338 | haaaaaaauauaaa \n",
            "r\\ Iteration: 3511 Loss: 1.8504595756530762 | haaaararauauaaa \n",
            "r\\ Iteration: 3512 Loss: 1.6964192390441895 | haraaaaaaaa \n",
            "r\\ Iteration: 3513 Loss: 2.017434597015381 | hoaaaraauauaaa \n",
            "r\\ Iteration: 3514 Loss: 1.7593863010406494 | hararaaaaaaraa \n",
            "r\\ Iteration: 3515 Loss: 1.8339097499847412 | hararaaaaaaaa \n",
            "r\\ Iteration: 3516 Loss: 2.135650634765625 | hararaaaa \n",
            "r\\ Iteration: 3517 Loss: 1.7969462871551514 | haaaaaaauaaaaa \n",
            "r\\ Iteration: 3518 Loss: 1.8295695781707764 | haaaaaaaauaaaaa \n",
            "r\\ Iteration: 3519 Loss: 1.8844215869903564 | hararaaaa \n",
            "r\\ Iteration: 3520 Loss: 1.9374003410339355 | hararaaaa \n",
            "r\\ Iteration: 3521 Loss: 1.7938153743743896 | haaaauaaaaa \n",
            "r\\ Iteration: 3522 Loss: 1.7178425788879395 | haaaaaarauaaaaa \n",
            "r\\ Iteration: 3523 Loss: 1.7777631282806396 | hoaaaaaaauaaaaa \n",
            "r\\ Iteration: 3524 Loss: 1.8780722618103027 | haaaaraaaaaraaa \n",
            "r\\ Iteration: 3525 Loss: 1.7600350379943848 | hoaaararaa \n",
            "r\\ Iteration: 3526 Loss: 1.8576550483703613 | haaaaaaraaaaaa \n",
            "r\\ Iteration: 3527 Loss: 2.1105916500091553 | hoaaaaaaaaa \n",
            "r\\ Iteration: 3528 Loss: 1.8467237949371338 | hoaaaarauaaaaa \n",
            "r\\ Iteration: 3529 Loss: 1.692004680633545 | haaaaraaaa \n",
            "r\\ Iteration: 3530 Loss: 1.798262596130371 | haaarauaaaaa \n",
            "r\\ Iteration: 3531 Loss: 1.691735029220581 | haaaaaaaaaaraa \n",
            "r\\ Iteration: 3532 Loss: 1.7498300075531006 | haaaaaaaraarauaaaaa \n",
            "r\\ Iteration: 3533 Loss: 1.7252671718597412 | haaaraaaaaasaa \n",
            "r\\ Iteration: 3534 Loss: 1.8141279220581055 | haaaaauaaaaa \n",
            "r\\ Iteration: 3535 Loss: 1.606348991394043 | haaaauaaaaa \n",
            "r\\ Iteration: 3536 Loss: 1.9465911388397217 | haaaaaaaaaaasaa \n",
            "r\\ Iteration: 3537 Loss: 1.8047375679016113 | haaaaaaasaasaaaaaaa \n",
            "r\\ Iteration: 3538 Loss: 1.7101452350616455 | haraaaaaaaaaa \n",
            "r\\ Iteration: 3539 Loss: 1.8011200428009033 | haaaasaaaaaaa \n",
            "r\\ Iteration: 3540 Loss: 1.9503505229949951 | haraaaaaaa \n",
            "r\\ Iteration: 3541 Loss: 1.9012823104858398 | haaaaaaaaaa \n",
            "r\\ Iteration: 3542 Loss: 2.0811383724212646 | haraaaaaaaaaa \n",
            "r\\ Iteration: 3543 Loss: 1.67714524269104 | haaaaaaaraaaaa \n",
            "r\\ Iteration: 3544 Loss: 1.7356364727020264 | haraaaaraaaaaaa \n",
            "r\\ Iteration: 3545 Loss: 1.770097017288208 | haaaraaaaaaaaaaa \n",
            "r\\ Iteration: 3546 Loss: 1.8557276725769043 | haaaaaaaaaaraa \n",
            "r\\ Iteration: 3547 Loss: 1.982053279876709 | haaaaraaaaaaaa \n",
            "r\\ Iteration: 3548 Loss: 1.857189655303955 | haaaaaaaaaa \n",
            "r\\ Iteration: 3549 Loss: 2.17844820022583 | haaaaaaaaaraaaaaaa \n",
            "r\\ Iteration: 3550 Loss: 1.8335840702056885 | haraaraaaaaaa \n",
            "r\\ Iteration: 3551 Loss: 1.7584648132324219 | haaaaaaar|aaaaaaa \n",
            "r\\ Iteration: 3552 Loss: 2.084038734436035 | haaaaraaaaaa \n",
            "r\\ Iteration: 3553 Loss: 1.769054651260376 | haaaaraaaa \n",
            "r\\ Iteration: 3554 Loss: 1.8368823528289795 | haaaaaaaraaaaa \n",
            "r\\ Iteration: 3555 Loss: 1.952728033065796 | haaaaaaraaraaaa \n",
            "r\\ Iteration: 3556 Loss: 1.9589614868164062 | haraaaaaaaaaaaa \n",
            "r\\ Iteration: 3557 Loss: 2.093071460723877 | haaaaaaaaaraaaaaaa \n",
            "r\\ Iteration: 3558 Loss: 1.7741031646728516 | haaaaaaaaaa \n",
            "r\\ Iteration: 3559 Loss: 1.9384164810180664 | haraaraaaaaaa \n",
            "r\\ Iteration: 3560 Loss: 1.8343393802642822 | haaaaaaaa \n",
            "r\\ Iteration: 3561 Loss: 2.1438546180725098 | haaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3562 Loss: 1.913546085357666 | haaaaaaaaaaa \n",
            "r\\ Iteration: 3563 Loss: 1.812044382095337 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3564 Loss: 1.6282849311828613 | haaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3565 Loss: 1.7222120761871338 | haaaaaaaaaaaa \n",
            "r\\ Iteration: 3566 Loss: 1.7788994312286377 | haaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3567 Loss: 1.809704303741455 | haaaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3568 Loss: 2.038007974624634 | haaaaaaa \n",
            "r\\ Iteration: 3569 Loss: 1.8294742107391357 | haaaaaaaaaaaa \n",
            "r\\ Iteration: 3570 Loss: 1.7625906467437744 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3571 Loss: 1.9718670845031738 | haaaaaaaaa \n",
            "r\\ Iteration: 3572 Loss: 1.8308696746826172 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3573 Loss: 1.9642000198364258 | hoaaaaaaaaaaaaa \n",
            "r\\ Iteration: 3574 Loss: 1.7591369152069092 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3575 Loss: 1.819474458694458 | haaaaaaaaasaa \n",
            "r\\ Iteration: 3576 Loss: 1.9979524612426758 | haaaasaaaaaaa \n",
            "r\\ Iteration: 3577 Loss: 1.8442981243133545 | haaaaasaaaaaaa \n",
            "r\\ Iteration: 3578 Loss: 1.759967565536499 | haaaaasaaaaasaaa \n",
            "r\\ Iteration: 3579 Loss: 1.7339532375335693 | haaaasaaaaaa \n",
            "r\\ Iteration: 3580 Loss: 1.9223549365997314 | haaaaaasaaaaaaa \n",
            "r\\ Iteration: 3581 Loss: 1.666696310043335 | horaaaaaaaaaaaa \n",
            "r\\ Iteration: 3582 Loss: 1.7391822338104248 | haaaasaaaaasaaaaaaa \n",
            "r\\ Iteration: 3583 Loss: 1.879941463470459 | haaaasaaaa \n",
            "r\\ Iteration: 3584 Loss: 1.8842246532440186 | haaaaasaaaaaaa \n",
            "r\\ Iteration: 3585 Loss: 1.7526869773864746 | haaaraaaaaaa \n",
            "r\\ Iteration: 3586 Loss: 1.6859095096588135 | haaaaaaaaaaaasaaa \n",
            "r\\ Iteration: 3587 Loss: 1.8129301071166992 | haaaaaaaaa \n",
            "r\\ Iteration: 3588 Loss: 1.865713357925415 | haaraaaaaraaaaaaa \n",
            "r\\ Iteration: 3589 Loss: 1.7590382099151611 | haaaaasaaa \n",
            "r\\ Iteration: 3590 Loss: 2.1508588790893555 | haaaaraaraaaaaaa \n",
            "r\\ Iteration: 3591 Loss: 1.8141939640045166 | haaaaaararaa \n",
            "r\\ Iteration: 3592 Loss: 1.9933817386627197 | haaaaaauaaaaa \n",
            "r\\ Iteration: 3593 Loss: 1.5822441577911377 | haaaaaaarauauaaa \n",
            "r\\ Iteration: 3594 Loss: 1.7683866024017334 | haraaaaauauaaa \n",
            "r\\ Iteration: 3595 Loss: 1.6675212383270264 | haaaraaaaaa \n",
            "r\\ Iteration: 3596 Loss: 1.9185495376586914 | haaaararaaaaaa \n",
            "r\\ Iteration: 3597 Loss: 1.864229440689087 | haaraaaaaaauauaaa \n",
            "r\\ Iteration: 3598 Loss: 1.8094449043273926 | haraaaaaaaa \n",
            "r\\ Iteration: 3599 Loss: 1.6775147914886475 | haaaaaaauaaaa \n",
            "r\\ Iteration: 3600 Loss: 1.9792978763580322 | haaaarauauaau \n",
            "r\\ Iteration: 3601 Loss: 1.7473804950714111 | haaaaaaaaaa \n",
            "r\\ Iteration: 3602 Loss: 1.8597350120544434 | haaaaarauauaau \n",
            "r\\ Iteration: 3603 Loss: 1.597367763519287 | haaaaaaaaaaaa \n",
            "r\\ Iteration: 3604 Loss: 2.177900552749634 | harararauauaau \n",
            "r\\ Iteration: 3605 Loss: 1.6056649684906006 | haaaaarauauaau \n",
            "r\\ Iteration: 3606 Loss: 1.64577317237854 | haaaaaurauauaau \n",
            "r\\ Iteration: 3607 Loss: 1.6892123222351074 | haaauraaraau \n",
            "r\\ Iteration: 3608 Loss: 1.6881623268127441 | haaararaarauauaau \n",
            "r\\ Iteration: 3609 Loss: 1.7075238227844238 | haaarauauaau \n",
            "r\\ Iteration: 3610 Loss: 1.6200850009918213 | haaaaaaaraaaau \n",
            "r\\ Iteration: 3611 Loss: 1.9466450214385986 | haaaaaaaaraaa \n",
            "r\\ Iteration: 3612 Loss: 1.9851710796356201 | hoaaaaaaaaauauaa \n",
            "r\\ Iteration: 3613 Loss: 1.9660797119140625 | haaaaaaaaaaraau \n",
            "r\\ Iteration: 3614 Loss: 1.857546329498291 | haaaaaauauaau \n",
            "r\\ Iteration: 3615 Loss: 1.727487564086914 | haaaaraaaaaa \n",
            "r\\ Iteration: 3616 Loss: 1.7460978031158447 | haaaaa \n",
            "r\\ Iteration: 3617 Loss: 1.9310436248779297 | haaarauauraaaaaaa \n",
            "r\\ Iteration: 3618 Loss: 1.7871451377868652 | haaaaraaaa \n",
            "r\\ Iteration: 3619 Loss: 1.969848871231079 | haaaaaaaaraaa \n",
            "r\\ Iteration: 3620 Loss: 1.8994815349578857 | hoaaaaaaa|a \n",
            "r\\ Iteration: 3621 Loss: 1.850954294204712 | haaaaarauauaaa \n",
            "r\\ Iteration: 3622 Loss: 1.6921970844268799 | haaaaaaaarauaaaaa \n",
            "r\\ Iteration: 3623 Loss: 1.745284080505371 | hoaaaaraaaaaaa \n",
            "r\\ Iteration: 3624 Loss: 1.7915472984313965 | hoaaaaararauaaaaa \n",
            "r\\ Iteration: 3625 Loss: 1.7679998874664307 | haaaaaaaaaraaa \n",
            "r\\ Iteration: 3626 Loss: 1.8237338066101074 | haaaaaaaaaaaa \n",
            "r\\ Iteration: 3627 Loss: 2.099303960800171 | haaaaraaa \n",
            "r\\ Iteration: 3628 Loss: 1.8167917728424072 | haaaaraaauaaa \n",
            "r\\ Iteration: 3629 Loss: 1.6970908641815186 | haoaaaaraaaauaaa \n",
            "r\\ Iteration: 3630 Loss: 1.7398133277893066 | haaaaraaauaaa \n",
            "r\\ Iteration: 3631 Loss: 1.6932156085968018 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3632 Loss: 1.9095780849456787 | haoaaaaaaaaasa \n",
            "r\\ Iteration: 3633 Loss: 1.698298454284668 | hoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3634 Loss: 1.684894323348999 | haaaasaaaaaaa \n",
            "r\\ Iteration: 3635 Loss: 1.680980920791626 | haaaaaaaaasaaaaa \n",
            "r\\ Iteration: 3636 Loss: 1.9906578063964844 | hoaasaaaaasaaa \n",
            "r\\ Iteration: 3637 Loss: 1.710345983505249 | haaaasaaaaaaa \n",
            "r\\ Iteration: 3638 Loss: 1.6990330219268799 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3639 Loss: 1.73712158203125 | haaaaaaaaaa \n",
            "r\\ Iteration: 3640 Loss: 1.9208626747131348 | haaaaaaaasasaa \n",
            "r\\ Iteration: 3641 Loss: 1.854386568069458 | haaaaaasaaaaasaaa \n",
            "r\\ Iteration: 3642 Loss: 1.8130006790161133 | haaaaaaaaaaaaa \n",
            "r\\ Iteration: 3643 Loss: 1.6855814456939697 | hoaaaaasaaaaaaa \n",
            "r\\ Iteration: 3644 Loss: 1.7990171909332275 | haaaaaasaaaaasaa \n",
            "r\\ Iteration: 3645 Loss: 1.8595607280731201 | haaaaaaasasaaaa \n",
            "r\\ Iteration: 3646 Loss: 1.9622626304626465 | haaaaasaasaaaaaaa \n",
            "r\\ Iteration: 3647 Loss: 1.683274745941162 | haaaaaasasaaaaaaa \n",
            "r\\ Iteration: 3648 Loss: 1.719721794128418 | haaaaasasaasasaa \n",
            "r\\ Iteration: 3649 Loss: 1.6690926551818848 | haaaaaaasasasaaa \n",
            "r\\ Iteration: 3650 Loss: 1.762510061264038 | haaaaaassaasasaa \n",
            "r\\ Iteration: 3651 Loss: 1.7302937507629395 | haaaaaaaaasaa \n",
            "r\\ Iteration: 3652 Loss: 1.9074442386627197 | haaasaassaa \n",
            "r\\ Iteration: 3653 Loss: 1.936811923980713 | haaaaaaaaaa \n",
            "r\\ Iteration: 3654 Loss: 1.6377654075622559 | haaaasasaaaaaaa \n",
            "r\\ Iteration: 3655 Loss: 1.8206920623779297 | haaaaasaa \n",
            "r\\ Iteration: 3656 Loss: 2.0263006687164307 | haaaaasasaaaaa \n",
            "r\\ Iteration: 3657 Loss: 1.7898976802825928 | haaaaaaauaaa \n",
            "r\\ Iteration: 3658 Loss: 1.7121362686157227 | haaaaasaasaasauauaaa \n",
            "r\\ Iteration: 3659 Loss: 1.8054313659667969 | haaaaaaauaaa \n",
            "r\\ Iteration: 3660 Loss: 1.6038987636566162 | haaaaaaaaauaaa \n",
            "r\\ Iteration: 3661 Loss: 1.7758293151855469 | haaaaaaaaasasaa \n",
            "r\\ Iteration: 3662 Loss: 1.9616482257843018 | haaaasasaa \n",
            "r\\ Iteration: 3663 Loss: 1.8813748359680176 | haaaaaaasauausau \n",
            "r\\ Iteration: 3664 Loss: 1.8180038928985596 | hoaaaaaaaasaasaaa \n",
            "r\\ Iteration: 3665 Loss: 1.976301670074463 | haaaaasaaaaaaa \n",
            "r\\ Iteration: 3666 Loss: 1.9270787239074707 | hlaaraaasaa \n",
            "r\\ Iteration: 3667 Loss: 1.8655338287353516 | haaaraaa \n",
            "r\\ Iteration: 3668 Loss: 2.0897128582000732 | haaaraaaaarauauaau \n",
            "r\\ Iteration: 3669 Loss: 1.7206099033355713 | haaararaa \n",
            "r\\ Iteration: 3670 Loss: 1.72221040725708 | hoaaarau|ara \n",
            "r\\ Iteration: 3671 Loss: 1.9416038990020752 | hooaaaaaa|a \n",
            "r\\ Iteration: 3672 Loss: 1.9116129875183105 | hoaaaaa|aurur|u \n",
            "r\\ Iteration: 3673 Loss: 1.669151782989502 | haaraaananaraa \n",
            "r\\ Iteration: 3674 Loss: 2.00956392288208 | horarraaaa \n",
            "r\\ Iteration: 3675 Loss: 1.9339399337768555 | hoaraaraau \n",
            "r\\ Iteration: 3676 Loss: 1.9256784915924072 | haaanaaaaaaa \n",
            "r\\ Iteration: 3677 Loss: 1.993351697921753 | horaaanaraau \n",
            "r\\ Iteration: 3678 Loss: 1.699455738067627 | rraaar|urur|u \n",
            "r\\ Iteration: 3679 Loss: 1.701244592666626 | rorarar|urur|u \n",
            "r\\ Iteration: 3680 Loss: 1.6222939491271973 | roranaar|a \n",
            "r\\ Iteration: 3681 Loss: 1.9595286846160889 | roraraaaanar|urur|u \n",
            "r\\ Iteration: 3682 Loss: 1.740844488143921 | roranar|a \n",
            "r\\ Iteration: 3683 Loss: 1.962092399597168 | roraananraa|a \n",
            "r\\ Iteration: 3684 Loss: 2.067063093185425 | rarar|ururau \n",
            "r\\ Iteration: 3685 Loss: 1.7383363246917725 | raaaaara|ana \n",
            "r\\ Iteration: 3686 Loss: 1.8903980255126953 | roranaururau \n",
            "r\\ Iteration: 3687 Loss: 1.7014477252960205 | raraar|ururau \n",
            "r\\ Iteration: 3688 Loss: 1.7522614002227783 | raaaaraaaraaarau \n",
            "r\\ Iteration: 3689 Loss: 1.8689842224121094 | roanar|araururau \n",
            "r\\ Iteration: 3690 Loss: 1.8222415447235107 | horaanaaraaururau \n",
            "r\\ Iteration: 3691 Loss: 1.7691173553466797 | horararaururau \n",
            "r\\ Iteration: 3692 Loss: 1.7097406387329102 | hoonaraararau \n",
            "r\\ Iteration: 3693 Loss: 1.9854400157928467 | haararaururau \n",
            "r\\ Iteration: 3694 Loss: 1.7649662494659424 | horanaraarau \n",
            "r\\ Iteration: 3695 Loss: 1.8094673156738281 | haranararaau \n",
            "r\\ Iteration: 3696 Loss: 1.697463035583496 | haoaraururau \n",
            "r\\ Iteration: 3697 Loss: 1.7022230625152588 | honaaraaururau \n",
            "r\\ Iteration: 3698 Loss: 1.759840726852417 | hroararaarau \n",
            "r\\ Iteration: 3699 Loss: 1.9998772144317627 | horaaaaraanaasau \n",
            "r\\ Iteration: 3700 Loss: 1.947204828262329 | horaaraaraururau \n",
            "r\\ Iteration: 3701 Loss: 1.8091790676116943 | hanaaaaraururau \n",
            "r\\ Iteration: 3702 Loss: 1.8053879737854004 | horaanaaururau \n",
            "r\\ Iteration: 3703 Loss: 1.8162188529968262 | hrarauaurau \n",
            "r\\ Iteration: 3704 Loss: 1.7045044898986816 | hoaaaasaraaaaraaau \n",
            "r\\ Iteration: 3705 Loss: 1.8401706218719482 | haoaanaaasasauauaau \n",
            "r\\ Iteration: 3706 Loss: 1.8255889415740967 | horaaaasauauaau \n",
            "r\\ Iteration: 3707 Loss: 1.6850340366363525 | hararsasasaasa \n",
            "r\\ Iteration: 3708 Loss: 2.052915096282959 | hornaaasasauausau \n",
            "r\\ Iteration: 3709 Loss: 1.8618736267089844 | haonaaasasauausau \n",
            "r\\ Iteration: 3710 Loss: 1.7591099739074707 | haraaausaau \n",
            "r\\ Iteration: 3711 Loss: 1.9567842483520508 | horaaaassa \n",
            "r\\ Iteration: 3712 Loss: 1.9192802906036377 | hooaasaaasasaususau \n",
            "r\\ Iteration: 3713 Loss: 1.8133618831634521 | henaaraususaasau \n",
            "r\\ Iteration: 3714 Loss: 1.7779481410980225 | horaaasaasaaa \n",
            "r\\ Iteration: 3715 Loss: 1.9835453033447266 | henasssaasaasau \n",
            "r\\ Iteration: 3716 Loss: 1.901562213897705 | hoanaaususau \n",
            "r\\ Iteration: 3717 Loss: 1.7351386547088623 | horaasaususau \n",
            "r\\ Iteration: 3718 Loss: 1.6069972515106201 | haasasasasau \n",
            "r\\ Iteration: 3719 Loss: 1.8436369895935059 | hoaaaasasasau \n",
            "r\\ Iteration: 3720 Loss: 1.967963457107544 | hoonaaaasasaususau \n",
            "r\\ Iteration: 3721 Loss: 1.7372982501983643 | horaasaasaususau \n",
            "r\\ Iteration: 3722 Loss: 1.7848632335662842 | honasaaa \n",
            "r\\ Iteration: 3723 Loss: 2.24163818359375 | hoaaasasaususau \n",
            "r\\ Iteration: 3724 Loss: 1.732696533203125 | henanasaasaususau \n",
            "r\\ Iteration: 3725 Loss: 1.8154208660125732 | honauasasaususau \n",
            "r\\ Iteration: 3726 Loss: 1.7621779441833496 | hoaaaasasaasasaasa \n",
            "r\\ Iteration: 3727 Loss: 2.010685920715332 | hoossasaasau \n",
            "r\\ Iteration: 3728 Loss: 1.8315050601959229 | hroaassassa \n",
            "r\\ Iteration: 3729 Loss: 2.177109956741333 | hoaassassa \n",
            "r\\ Iteration: 3730 Loss: 1.8579072952270508 | henaasassas|u \n",
            "r\\ Iteration: 3731 Loss: 1.9052619934082031 | haonaasaas|usus|u \n",
            "r\\ Iteration: 3732 Loss: 1.8020415306091309 | horaaasaas|usus|u \n",
            "r\\ Iteration: 3733 Loss: 1.7740967273712158 | hoausasasasau \n",
            "r\\ Iteration: 3734 Loss: 1.8924148082733154 | honauaas|usus|u \n",
            "r\\ Iteration: 3735 Loss: 1.8469421863555908 | hoorsasau \n",
            "r\\ Iteration: 3736 Loss: 1.8321950435638428 | hurasashasus|u \n",
            "r\\ Iteration: 3737 Loss: 1.9068477153778076 | huaroasosasau \n",
            "r\\ Iteration: 3738 Loss: 2.018944025039673 | herars|||u \n",
            "r\\ Iteration: 3739 Loss: 1.9134917259216309 | hona|ussuos|usus|u \n",
            "r\\ Iteration: 3740 Loss: 1.8469829559326172 | honos|usus|u \n",
            "r\\ Iteration: 3741 Loss: 1.5786144733428955 | hononhso|oss|u \n",
            "r\\ Iteration: 3742 Loss: 1.828723669052124 | horaushso|oss|u \n",
            "r\\ Iteration: 3743 Loss: 1.781050443649292 | heorauos||usus|u \n",
            "r\\ Iteration: 3744 Loss: 1.71494460105896 | heornosoos|usus|u \n",
            "r\\ Iteration: 3745 Loss: 1.6544265747070312 | horronaor|urur|u \n",
            "r\\ Iteration: 3746 Loss: 1.7369256019592285 | haorror|u \n",
            "r\\ Iteration: 3747 Loss: 2.0215227603912354 | horoos|ssosor|u \n",
            "r\\ Iteration: 3748 Loss: 2.1056785583496094 | horaroos|a \n",
            "r\\ Iteration: 3749 Loss: 1.9155056476593018 | heoraorrushor|u \n",
            "r\\ Iteration: 3750 Loss: 1.9616971015930176 | horoanarosors|u \n",
            "r\\ Iteration: 3751 Loss: 1.7913975715637207 | heoaror|ror|u \n",
            "r\\ Iteration: 3752 Loss: 2.021618604660034 | hoooanorus|a \n",
            "r\\ Iteration: 3753 Loss: 1.909271478652954 | hororarsaurur|u \n",
            "r\\ Iteration: 3754 Loss: 1.8234992027282715 | hrorar|urur|u \n",
            "r\\ Iteration: 3755 Loss: 1.6794030666351318 | huonaroronau \n",
            "r\\ Iteration: 3756 Loss: 1.8313355445861816 | haoraonar|a \n",
            "r\\ Iteration: 3757 Loss: 1.7404332160949707 | huoouonaurur|u \n",
            "r\\ Iteration: 3758 Loss: 1.8059654235839844 | hoooraraaurur|u \n",
            "r\\ Iteration: 3759 Loss: 1.8550870418548584 | hoaoraoor|urur|u \n",
            "r\\ Iteration: 3760 Loss: 1.6823697090148926 | horororor|a \n",
            "r\\ Iteration: 3761 Loss: 1.888251781463623 | hoorararaa \n",
            "r\\ Iteration: 3762 Loss: 2.0153250694274902 | hrrooraraata \n",
            "r\\ Iteration: 3763 Loss: 2.0685784816741943 | hooonaraaur|u \n",
            "r\\ Iteration: 3764 Loss: 1.8208637237548828 | honaur|urur|u \n",
            "r\\ Iteration: 3765 Loss: 1.7663593292236328 | haororonatoraa \n",
            "r\\ Iteration: 3766 Loss: 1.9999711513519287 | hronaaurur|u \n",
            "r\\ Iteration: 3767 Loss: 1.9017069339752197 | hootanaonraar|u \n",
            "r\\ Iteration: 3768 Loss: 1.8534584045410156 | hortarorturaraa \n",
            "r\\ Iteration: 3769 Loss: 1.8869948387145996 | honaroror|urur|u \n",
            "r\\ Iteration: 3770 Loss: 1.784257173538208 | hornaorr|urur|u \n",
            "r\\ Iteration: 3771 Loss: 1.8102991580963135 | hrooosnor|urur|u \n",
            "r\\ Iteration: 3772 Loss: 1.9297356605529785 | horrusoonar|urur|u \n",
            "r\\ Iteration: 3773 Loss: 1.6959307193756104 | honarnon|urur|u \n",
            "r\\ Iteration: 3774 Loss: 1.712007761001587 | honoroor|urur|u \n",
            "r\\ Iteration: 3775 Loss: 1.6069729328155518 | horouorarhur|u \n",
            "r\\ Iteration: 3776 Loss: 1.9498646259307861 | hnonar|urur|u \n",
            "r\\ Iteration: 3777 Loss: 1.6656608581542969 | honarororao \n",
            "r\\ Iteration: 3778 Loss: 1.8490302562713623 | rronor|urur|u \n",
            "r\\ Iteration: 3779 Loss: 1.6767489910125732 | roornarorao \n",
            "r\\ Iteration: 3780 Loss: 1.9043238162994385 | ronaoorsunsr|u \n",
            "r\\ Iteration: 3781 Loss: 1.8985273838043213 | ronaanossa \n",
            "r\\ Iteration: 3782 Loss: 1.9161412715911865 | reornaasaraoa \n",
            "r\\ Iteration: 3783 Loss: 1.9406404495239258 | roronaosta \n",
            "r\\ Iteration: 3784 Loss: 1.9195137023925781 | rornrtau \n",
            "r\\ Iteration: 3785 Loss: 1.8507091999053955 | henoraur|urur|u \n",
            "r\\ Iteration: 3786 Loss: 1.766561508178711 | horonananar|a \n",
            "r\\ Iteration: 3787 Loss: 1.83026123046875 | honanr|urur|u \n",
            "r\\ Iteration: 3788 Loss: 1.7255122661590576 | hoonarrasaus|u \n",
            "r\\ Iteration: 3789 Loss: 1.8909730911254883 | honaaraaurur|u \n",
            "r\\ Iteration: 3790 Loss: 1.7461256980895996 | haonotaranatar|a \n",
            "r\\ Iteration: 3791 Loss: 1.906944751739502 | hoonraurur|u \n",
            "r\\ Iteration: 3792 Loss: 1.6958887577056885 | hornnaraaurur|u \n",
            "r\\ Iteration: 3793 Loss: 1.8326852321624756 | hoooar|ar|oror|u \n",
            "r\\ Iteration: 3794 Loss: 1.9571714401245117 | honaur|urur|u \n",
            "r\\ Iteration: 3795 Loss: 1.6654024124145508 | honnaorsosor|urur|u \n",
            "r\\ Iteration: 3796 Loss: 1.7600326538085938 | hoooorusanosorh|u \n",
            "r\\ Iteration: 3797 Loss: 1.783428430557251 | hooraonoooro|aor|u \n",
            "r\\ Iteration: 3798 Loss: 2.0793468952178955 | hoooooraosos|o \n",
            "r\\ Iteration: 3799 Loss: 2.0673892498016357 | roonr|urur|u \n",
            "r\\ Iteration: 3800 Loss: 1.6113965511322021 | rooooos|ususo \n",
            "r\\ Iteration: 3801 Loss: 1.801053762435913 | honoror|u \n",
            "r\\ Iteration: 3802 Loss: 1.8489713668823242 | hoooonooonos|usus|u \n",
            "r\\ Iteration: 3803 Loss: 1.8582477569580078 | hononon|usus|u \n",
            "r\\ Iteration: 3804 Loss: 1.61076021194458 | hooorooo \n",
            "r\\ Iteration: 3805 Loss: 2.1141107082366943 | honoona|usus|u \n",
            "r\\ Iteration: 3806 Loss: 1.7657511234283447 | huoorosos|u \n",
            "r\\ Iteration: 3807 Loss: 1.71677827835083 | hooooauos|usus|u \n",
            "r\\ Iteration: 3808 Loss: 1.7469799518585205 | henooonosos|os|usus|u \n",
            "r\\ Iteration: 3809 Loss: 1.748175859451294 | hooooauos|usus|u \n",
            "r\\ Iteration: 3810 Loss: 1.7301838397979736 | hooooranosos|u \n",
            "r\\ Iteration: 3811 Loss: 1.8512475490570068 | hoonosusausus|u \n",
            "r\\ Iteration: 3812 Loss: 1.6177704334259033 | hooooosausus|u \n",
            "r\\ Iteration: 3813 Loss: 1.8191888332366943 | hooonaos|usus|u \n",
            "r\\ Iteration: 3814 Loss: 1.7555999755859375 | hononansosau \n",
            "r\\ Iteration: 3815 Loss: 1.8493130207061768 | honoraoussuss|u \n",
            "r\\ Iteration: 3816 Loss: 1.8835089206695557 | hoooosussos|u \n",
            "r\\ Iteration: 3817 Loss: 1.8427932262420654 | hooranss|usussosau \n",
            "r\\ Iteration: 3818 Loss: 1.8769872188568115 | hoorsasus|u \n",
            "r\\ Iteration: 3819 Loss: 1.9359619617462158 | hoooaaaus|usus|u \n",
            "r\\ Iteration: 3820 Loss: 1.8502867221832275 | honaasassa \n",
            "r\\ Iteration: 3821 Loss: 1.8351373672485352 | hooaaass|usus|u \n",
            "r\\ Iteration: 3822 Loss: 1.8067893981933594 | haoaorss|u \n",
            "r\\ Iteration: 3823 Loss: 1.7934839725494385 | hororsassas|s \n",
            "r\\ Iteration: 3824 Loss: 1.9615261554718018 | hooreosaas|usus|u \n",
            "r\\ Iteration: 3825 Loss: 1.7869586944580078 | hoooasasarasaa \n",
            "r\\ Iteration: 3826 Loss: 1.8513553142547607 | hooossaasaasaassa \n",
            "r\\ Iteration: 3827 Loss: 1.9701132774353027 | honaraas|usus|u \n",
            "r\\ Iteration: 3828 Loss: 1.7318665981292725 | hororaas|usus|u \n",
            "r\\ Iteration: 3829 Loss: 1.5988938808441162 | horoesasassau \n",
            "r\\ Iteration: 3830 Loss: 1.8471157550811768 | hranorausus|u \n",
            "r\\ Iteration: 3831 Loss: 1.7663323879241943 | hororausus|u \n",
            "r\\ Iteration: 3832 Loss: 1.682387351989746 | heonaarsushas|a \n",
            "r\\ Iteration: 3833 Loss: 1.9332261085510254 | hooraasass|usus|u \n",
            "r\\ Iteration: 3834 Loss: 1.6568939685821533 | huarnasusassau \n",
            "r\\ Iteration: 3835 Loss: 1.744983434677124 | hoooasas|u \n",
            "r\\ Iteration: 3836 Loss: 1.8947257995605469 | huanaurus|u \n",
            "r\\ Iteration: 3837 Loss: 1.6868200302124023 | heonas|asasasau \n",
            "r\\ Iteration: 3838 Loss: 1.750342845916748 | harnasaushsaa \n",
            "r\\ Iteration: 3839 Loss: 1.7988958358764648 | huoeasausus|u \n",
            "r\\ Iteration: 3840 Loss: 1.6712512969970703 | horoar|urur|u \n",
            "r\\ Iteration: 3841 Loss: 1.7356090545654297 | horastasar|a \n",
            "r\\ Iteration: 3842 Loss: 2.0369718074798584 | hooeasasasaa \n",
            "r\\ Iteration: 3843 Loss: 1.724278450012207 | hoorar|asau \n",
            "r\\ Iteration: 3844 Loss: 1.8805351257324219 | hootrasusassau \n",
            "r\\ Iteration: 3845 Loss: 1.7109591960906982 | haeorurusar|u \n",
            "r\\ Iteration: 3846 Loss: 2.0083420276641846 | hooaatasasassau \n",
            "r\\ Iteration: 3847 Loss: 1.6961071491241455 | hoortassau \n",
            "r\\ Iteration: 3848 Loss: 1.9435691833496094 | hoooass|urusar|u \n",
            "r\\ Iteration: 3849 Loss: 1.7500383853912354 | hoooasos|urur|u \n",
            "r\\ Iteration: 3850 Loss: 1.731788158416748 | hraraotaporaa \n",
            "r\\ Iteration: 3851 Loss: 1.9835021495819092 | hooaraaraata \n",
            "r\\ Iteration: 3852 Loss: 1.9174375534057617 | hnonar|urur|u \n",
            "r\\ Iteration: 3853 Loss: 1.6758642196655273 | haooasaaurur|u \n",
            "r\\ Iteration: 3854 Loss: 1.78953218460083 | huoar|urur|u \n",
            "r\\ Iteration: 3855 Loss: 1.6924965381622314 | hhonaaasaaaraaa \n",
            "r\\ Iteration: 3856 Loss: 2.1236801147460938 | hooaa|aarsasr|u \n",
            "r\\ Iteration: 3857 Loss: 2.009719133377075 | hoorasar|urur|u \n",
            "r\\ Iteration: 3858 Loss: 1.673647165298462 | hroaasaaa \n",
            "r\\ Iteration: 3859 Loss: 2.2160236835479736 | dhnosasusass|u \n",
            "r\\ Iteration: 3860 Loss: 1.8781647682189941 | huortsasos|a \n",
            "r\\ Iteration: 3861 Loss: 1.7721490859985352 | hunaassus|urur|u \n",
            "r\\ Iteration: 3862 Loss: 1.7037959098815918 | hmoosarar|u \n",
            "r\\ Iteration: 3863 Loss: 1.9733285903930664 | hroanasaasar|u \n",
            "r\\ Iteration: 3864 Loss: 1.9594717025756836 | hhhstar|usus|u \n",
            "r\\ Iteration: 3865 Loss: 1.7337467670440674 | hunassarur|u \n",
            "r\\ Iteration: 3866 Loss: 2.0342886447906494 | hunorasas|u \n",
            "r\\ Iteration: 3867 Loss: 1.8020966053009033 | hunoaass|usus|u \n",
            "r\\ Iteration: 3868 Loss: 1.8254969120025635 | hhnosasssassa \n",
            "r\\ Iteration: 3869 Loss: 1.9168717861175537 | hunaasaas|usus|u \n",
            "r\\ Iteration: 3870 Loss: 1.7388086318969727 | hmroraasau \n",
            "r\\ Iteration: 3871 Loss: 1.8117737770080566 | hhnasasas|a \n",
            "r\\ Iteration: 3872 Loss: 1.7172837257385254 | hhrasaasaau|usus|u \n",
            "r\\ Iteration: 3873 Loss: 1.8148069381713867 | hurssaas|usus|u \n",
            "r\\ Iteration: 3874 Loss: 1.8011631965637207 | hhnaasas|asaasasau \n",
            "r\\ Iteration: 3875 Loss: 1.962914228439331 | hhrnaasaususau \n",
            "r\\ Iteration: 3876 Loss: 1.7701125144958496 | hhnaaassaususau \n",
            "r\\ Iteration: 3877 Loss: 1.7349684238433838 | hhorasaasaasaa \n",
            "r\\ Iteration: 3878 Loss: 1.932175874710083 | hhnasassasaa \n",
            "r\\ Iteration: 3879 Loss: 1.8410537242889404 | hhaassaaususau \n",
            "r\\ Iteration: 3880 Loss: 1.7452352046966553 | hhraasssaasaususaa \n",
            "r\\ Iteration: 3881 Loss: 1.8942217826843262 | hhaaaassaususaa \n",
            "r\\ Iteration: 3882 Loss: 1.7993462085723877 | hhaaasaasasa \n",
            "r\\ Iteration: 3883 Loss: 1.9957735538482666 | huraaasaraaraa \n",
            "r\\ Iteration: 3884 Loss: 1.9208226203918457 | hhraaasaasasaa \n",
            "r\\ Iteration: 3885 Loss: 2.049288749694824 | hhasasaususaa \n",
            "r\\ Iteration: 3886 Loss: 1.69264817237854 | hhoasaasaususaa \n",
            "r\\ Iteration: 3887 Loss: 1.7009961605072021 | hhraa \n",
            "r\\ Iteration: 3888 Loss: 2.290773391723633 | hhrasasasashaa \n",
            "r\\ Iteration: 3889 Loss: 1.7776541709899902 | hhrasasasasashaa \n",
            "r\\ Iteration: 3890 Loss: 1.7096731662750244 | hhsassshasasaa \n",
            "r\\ Iteration: 3891 Loss: 1.9510562419891357 | hhrasaraaraa \n",
            "r\\ Iteration: 3892 Loss: 1.8154735565185547 | hhsasassasas|o \n",
            "r\\ Iteration: 3893 Loss: 1.7838304042816162 | hhrasas|usus|u \n",
            "r\\ Iteration: 3894 Loss: 1.7357685565948486 | hraaasas|usus|u \n",
            "r\\ Iteration: 3895 Loss: 1.7887194156646729 | hhrasaraar|a \n",
            "r\\ Iteration: 3896 Loss: 1.790956735610962 | hhrnrsaas|usus|u \n",
            "r\\ Iteration: 3897 Loss: 1.7258515357971191 | hhrarauasasassaa \n",
            "r\\ Iteration: 3898 Loss: 1.8241705894470215 | hhraasraurus|u \n",
            "r\\ Iteration: 3899 Loss: 1.821608066558838 | hhasaasaaurus|u \n",
            "r\\ Iteration: 3900 Loss: 1.8835208415985107 | huraaars|urus|u \n",
            "r\\ Iteration: 3901 Loss: 1.7863976955413818 | hucaarssa|urus|u \n",
            "r\\ Iteration: 3902 Loss: 1.8968276977539062 | horascar|urus|u \n",
            "r\\ Iteration: 3903 Loss: 1.674267053604126 | hhaar|hasar|u \n",
            "r\\ Iteration: 3904 Loss: 1.9746973514556885 | hhaaas|urus|u \n",
            "r\\ Iteration: 3905 Loss: 1.6765727996826172 | hhrar|shas|r \n",
            "r\\ Iteration: 3906 Loss: 1.818922996520996 | huraurassr|u \n",
            "r\\ Iteration: 3907 Loss: 2.0008275508880615 | hucasasasas|r \n",
            "r\\ Iteration: 3908 Loss: 1.7316734790802002 | huaras|urus|u \n",
            "r\\ Iteration: 3909 Loss: 1.6447863578796387 | horasasasaa \n",
            "r\\ Iteration: 3910 Loss: 1.6630454063415527 | hucasarsasasaa \n",
            "r\\ Iteration: 3911 Loss: 1.8284344673156738 | hussas|oss|as|u \n",
            "r\\ Iteration: 3912 Loss: 1.8880748748779297 | hhasaausauss|usus|u \n",
            "r\\ Iteration: 3913 Loss: 1.8175773620605469 | hosaosas|usus|u \n",
            "r\\ Iteration: 3914 Loss: 1.6606159210205078 | hursas|osaas|a \n",
            "r\\ Iteration: 3915 Loss: 1.84621262550354 | huraasasass|u \n",
            "r\\ Iteration: 3916 Loss: 1.8790619373321533 | hurasos|usus|u \n",
            "r\\ Iteration: 3917 Loss: 1.7805109024047852 | huassususar|u \n",
            "r\\ Iteration: 3918 Loss: 2.0127954483032227 | hucarsaos|usus| \n",
            "r\\ Iteration: 3919 Loss: 1.8928990364074707 | haasos|usus|u \n",
            "r\\ Iteration: 3920 Loss: 1.723344087600708 | horasasaas|os|u \n",
            "r\\ Iteration: 3921 Loss: 1.902604341506958 | hasashnaasssosarao \n",
            "r\\ Iteration: 3922 Loss: 1.8799922466278076 | hastasoosas|a \n",
            "r\\ Iteration: 3923 Loss: 1.873335599899292 | hastasos|a \n",
            "r\\ Iteration: 3924 Loss: 1.900350570678711 | honaas|urur|u \n",
            "r\\ Iteration: 3925 Loss: 1.6528174877166748 | horanasta \n",
            "r\\ Iteration: 3926 Loss: 2.0444531440734863 | harrsaasasaurur|u \n",
            "r\\ Iteration: 3927 Loss: 1.8483922481536865 | huaasaasar|o \n",
            "r\\ Iteration: 3928 Loss: 1.9072277545928955 | hoartar|urur|o \n",
            "r\\ Iteration: 3929 Loss: 1.6771249771118164 | huaasaasar|o \n",
            "r\\ Iteration: 3930 Loss: 1.835374116897583 | horasaaar|aa \n",
            "r\\ Iteration: 3931 Loss: 1.9380409717559814 | hararrar|urur|a \n",
            "r\\ Iteration: 3932 Loss: 1.6679606437683105 | horrasarasaa \n",
            "r\\ Iteration: 3933 Loss: 1.8512084484100342 | hurarar|urur|a \n",
            "r\\ Iteration: 3934 Loss: 1.603219747543335 | hurrtarartasar|o \n",
            "r\\ Iteration: 3935 Loss: 1.9280035495758057 | hhrarrrarasaa \n",
            "r\\ Iteration: 3936 Loss: 1.8176968097686768 | hor|arar|urur|u \n",
            "r\\ Iteration: 3937 Loss: 1.7437541484832764 | hhr|rr|urur|u \n",
            "r\\ Iteration: 3938 Loss: 1.663846492767334 | hursr|urur|u \n",
            "r\\ Iteration: 3939 Loss: 1.7559607028961182 | hhrsaaarar|urur|u \n",
            "r\\ Iteration: 3940 Loss: 1.7123386859893799 | hhrnaaar|urur|u \n",
            "r\\ Iteration: 3941 Loss: 1.666011095046997 | huana|r|rrtorar|r \n",
            "r\\ Iteration: 3942 Loss: 1.9967033863067627 | hhrt|uar|u \n",
            "r\\ Iteration: 3943 Loss: 1.8721017837524414 | hurtor|r|o \n",
            "r\\ Iteration: 3944 Loss: 1.8947980403900146 | hhrnaourar|urur|u \n",
            "r\\ Iteration: 3945 Loss: 1.686964750289917 | huaranarna \n",
            "r\\ Iteration: 3946 Loss: 1.860898733139038 | hurnarosorh|u \n",
            "r\\ Iteration: 3947 Loss: 1.772491216659546 | huroaraor|urur|u \n",
            "r\\ Iteration: 3948 Loss: 1.8123846054077148 | hurn|urur|u \n",
            "r\\ Iteration: 3949 Loss: 1.6612637042999268 | hhrr|unaaurur|u \n",
            "r\\ Iteration: 3950 Loss: 1.7950870990753174 | huaaru \n",
            "r\\ Iteration: 3951 Loss: 2.216275691986084 | huranorar|oa \n",
            "r\\ Iteration: 3952 Loss: 1.8903083801269531 | huanaononanar|u \n",
            "r\\ Iteration: 3953 Loss: 1.753920316696167 | hhonarr|urur|u \n",
            "r\\ Iteration: 3954 Loss: 1.6595284938812256 | huanunan|urur|u \n",
            "r\\ Iteration: 3955 Loss: 1.6720290184020996 | hurun|urur|u \n",
            "r\\ Iteration: 3956 Loss: 1.5856361389160156 | hhrnrunornuouur|u \n",
            "r\\ Iteration: 3957 Loss: 2.0014710426330566 | hurnournanunors|u \n",
            "r\\ Iteration: 3958 Loss: 1.8806118965148926 | hhruuruun|urur|u \n",
            "r\\ Iteration: 3959 Loss: 1.7823948860168457 | hhraonar|urur|u \n",
            "r\\ Iteration: 3960 Loss: 1.6607089042663574 | hhruanaauno \n",
            "r\\ Iteration: 3961 Loss: 2.125283718109131 | hururnur|urur|u \n",
            "r\\ Iteration: 3962 Loss: 1.6677954196929932 | hurarun|urur|u \n",
            "r\\ Iteration: 3963 Loss: 1.5956828594207764 | hurnarnar|uuna \n",
            "r\\ Iteration: 3964 Loss: 2.097522735595703 | hhruaranrur|u \n",
            "r\\ Iteration: 3965 Loss: 1.8017632961273193 | hururar|urur|u \n",
            "r\\ Iteration: 3966 Loss: 1.768413782119751 | hurnar|uursunr|u \n",
            "r\\ Iteration: 3967 Loss: 1.9145643711090088 | hhrunarrraa \n",
            "r\\ Iteration: 3968 Loss: 1.7330262660980225 | hharaarar|urur|u \n",
            "r\\ Iteration: 3969 Loss: 1.645435094833374 | hhaaraarrnaur|u \n",
            "r\\ Iteration: 3970 Loss: 1.973238468170166 | hurarararanarsau \n",
            "r\\ Iteration: 3971 Loss: 1.7816522121429443 | hharaarraaraurur|u \n",
            "r\\ Iteration: 3972 Loss: 1.884995937347412 | herus|rr|urur|u \n",
            "r\\ Iteration: 3973 Loss: 1.6716578006744385 | hurarus|urusu \n",
            "r\\ Iteration: 3974 Loss: 1.698228120803833 | huruararanaruu \n",
            "r\\ Iteration: 3975 Loss: 1.828782320022583 | hurusuan|urur|u \n",
            "r\\ Iteration: 3976 Loss: 1.753479242324829 | huraaaanar|urur|u \n",
            "r\\ Iteration: 3977 Loss: 1.8333675861358643 | hhaaraarurursar|u \n",
            "r\\ Iteration: 3978 Loss: 2.0983006954193115 | herasar|urur|u \n",
            "r\\ Iteration: 3979 Loss: 1.5999188423156738 | hhrarus|an|a \n",
            "r\\ Iteration: 3980 Loss: 2.0323243141174316 | huaaaurur|u \n",
            "r\\ Iteration: 3981 Loss: 1.8663361072540283 | hhruasaaurur|u \n",
            "r\\ Iteration: 3982 Loss: 1.9074819087982178 | hhraaaasar|urur|u \n",
            "r\\ Iteration: 3983 Loss: 1.8107919692993164 | hharaasar|urur|u \n",
            "r\\ Iteration: 3984 Loss: 1.7254624366760254 | huararsraraa \n",
            "r\\ Iteration: 3985 Loss: 1.9663481712341309 | hharrarsar|urur|u \n",
            "r\\ Iteration: 3986 Loss: 1.8007574081420898 | huraasar|sr|rrar|u \n",
            "r\\ Iteration: 3987 Loss: 1.95316481590271 | huraaraarsasa \n",
            "r\\ Iteration: 3988 Loss: 2.148024320602417 | hhrarrarrur|u \n",
            "r\\ Iteration: 3989 Loss: 1.654886245727539 | hlararrs|u \n",
            "r\\ Iteration: 3990 Loss: 1.9290170669555664 | hurarsur|urur|u \n",
            "r\\ Iteration: 3991 Loss: 1.7812812328338623 | hrrasar|urur|u \n",
            "r\\ Iteration: 3992 Loss: 1.753431797027588 | hharsarrusar| \n",
            "r\\ Iteration: 3993 Loss: 1.9965248107910156 | huraasaar|raur|u \n",
            "r\\ Iteration: 3994 Loss: 2.0542635917663574 | huroauar|urur|u \n",
            "r\\ Iteration: 3995 Loss: 1.738274335861206 | huraar|urur|u \n",
            "r\\ Iteration: 3996 Loss: 1.6642515659332275 | hursaoarur|urur|u \n",
            "r\\ Iteration: 3997 Loss: 1.8171544075012207 | hhrarar|urur|u \n",
            "r\\ Iteration: 3998 Loss: 1.5802247524261475 | huroaauaoraorar|u \n",
            "r\\ Iteration: 3999 Loss: 1.967116117477417 | heasarrsaor|urur|u \n",
            "r\\ Iteration: 4000 Loss: 1.703927993774414 | hhrsaasaurur|u \n",
            "r\\ Iteration: 4001 Loss: 1.6891958713531494 | hharssarsar|urur|u \n",
            "r\\ Iteration: 4002 Loss: 1.655123233795166 | huaasarsas|urur|u \n",
            "r\\ Iteration: 4003 Loss: 1.6660997867584229 | heraos|oss|u \n",
            "r\\ Iteration: 4004 Loss: 1.8442997932434082 | hhrasss|usus|ar|u \n",
            "r\\ Iteration: 4005 Loss: 1.7813000679016113 | hurasaasaosso \n",
            "r\\ Iteration: 4006 Loss: 2.208570718765259 | hursaauaosaosar|u \n",
            "r\\ Iteration: 4007 Loss: 1.9345757961273193 | hurosass|usus|u \n",
            "r\\ Iteration: 4008 Loss: 1.7980563640594482 | huaasasasossao \n",
            "r\\ Iteration: 4009 Loss: 1.7640271186828613 | huuras|usus|u \n",
            "r\\ Iteration: 4010 Loss: 1.6434884071350098 | huosaasas|osasos|u \n",
            "r\\ Iteration: 4011 Loss: 1.8873579502105713 | hasaasasas|u \n",
            "r\\ Iteration: 4012 Loss: 1.9182474613189697 | hourussaos|usus|u \n",
            "r\\ Iteration: 4013 Loss: 1.7517848014831543 | harasas|s|usus|u \n",
            "r\\ Iteration: 4014 Loss: 1.5954585075378418 | hosas|usus|u \n",
            "r\\ Iteration: 4015 Loss: 1.5550730228424072 | horaas|oa \n",
            "r\\ Iteration: 4016 Loss: 2.0519118309020996 | harasosasaas|u \n",
            "r\\ Iteration: 4017 Loss: 1.925598382949829 | honasasasossau \n",
            "r\\ Iteration: 4018 Loss: 1.8443894386291504 | harssassasasa \n",
            "r\\ Iteration: 4019 Loss: 2.0276715755462646 | hoauasasasasossau \n",
            "r\\ Iteration: 4020 Loss: 1.8073997497558594 | harasasassas|o \n",
            "r\\ Iteration: 4021 Loss: 1.8864145278930664 | hanassos|usus|u \n",
            "r\\ Iteration: 4022 Loss: 1.6402709484100342 | housasasasoosoos|u \n",
            "r\\ Iteration: 4023 Loss: 1.9716472625732422 | hanasossosaa \n",
            "r\\ Iteration: 4024 Loss: 1.9034929275512695 | hausaraososaa \n",
            "r\\ Iteration: 4025 Loss: 1.888319969177246 | haasasos|urur|o \n",
            "r\\ Iteration: 4026 Loss: 1.7205595970153809 | hanoossosaa \n",
            "r\\ Iteration: 4027 Loss: 1.8178062438964844 | haraos|urur|o \n",
            "r\\ Iteration: 4028 Loss: 1.5829789638519287 | hanasosoas|urur|o \n",
            "r\\ Iteration: 4029 Loss: 1.7669909000396729 | hausnosaosao \n",
            "r\\ Iteration: 4030 Loss: 1.791811227798462 | harorar|urur|o \n",
            "r\\ Iteration: 4031 Loss: 1.5892443656921387 | hororaoo \n",
            "r\\ Iteration: 4032 Loss: 1.9991238117218018 | hanoororororoo \n",
            "r\\ Iteration: 4033 Loss: 1.9184200763702393 | hanoossor|urur|o \n",
            "r\\ Iteration: 4034 Loss: 1.7867534160614014 | honosr|urur|o \n",
            "r\\ Iteration: 4035 Loss: 1.5971786975860596 | horsoranooor|urur|o \n",
            "r\\ Iteration: 4036 Loss: 1.7066679000854492 | hoorso \n",
            "r\\ Iteration: 4037 Loss: 1.9342715740203857 | horosanooorsos|o \n",
            "r\\ Iteration: 4038 Loss: 1.883345127105713 | horoo|or|urur|o \n",
            "r\\ Iteration: 4039 Loss: 1.753889799118042 | haocorsor|r|urur|o \n",
            "r\\ Iteration: 4040 Loss: 1.6742033958435059 | haantor|r|o \n",
            "r\\ Iteration: 4041 Loss: 1.9790019989013672 | horaroonoosto \n",
            "r\\ Iteration: 4042 Loss: 2.0503387451171875 | hoontoor|urur|u \n",
            "r\\ Iteration: 4043 Loss: 1.6652140617370605 | hoasosor|o \n",
            "r\\ Iteration: 4044 Loss: 1.9908316135406494 | horaoor|roor|u \n",
            "r\\ Iteration: 4045 Loss: 1.892223834991455 | hourtr|urur|u \n",
            "r\\ Iteration: 4046 Loss: 1.727529764175415 | hruosooron||r|u \n",
            "r\\ Iteration: 4047 Loss: 2.019076108932495 | hooso|osost|or|urur|u \n",
            "r\\ Iteration: 4048 Loss: 1.8140339851379395 | hararurhus|os|urur|u \n",
            "r\\ Iteration: 4049 Loss: 1.7826378345489502 | hoarur|urur|u \n",
            "r\\ Iteration: 4050 Loss: 1.7342767715454102 | horarr|urur|u \n",
            "r\\ Iteration: 4051 Loss: 1.647191047668457 | houraororr|urur|u \n",
            "r\\ Iteration: 4052 Loss: 1.6918292045593262 | hooros|s|urur|u \n",
            "r\\ Iteration: 4053 Loss: 1.7158617973327637 | haraor|urur|u \n",
            "r\\ Iteration: 4054 Loss: 1.7076730728149414 | houonar|urur|u \n",
            "r\\ Iteration: 4055 Loss: 1.8695857524871826 | hortoo|r|urur|u \n",
            "r\\ Iteration: 4056 Loss: 1.8924407958984375 | horooroar|urur|u \n",
            "r\\ Iteration: 4057 Loss: 1.6707582473754883 | haurototor|urur|u \n",
            "r\\ Iteration: 4058 Loss: 1.777796745300293 | horoor|urur|u \n",
            "r\\ Iteration: 4059 Loss: 1.662879228591919 | horor|otto \n",
            "r\\ Iteration: 4060 Loss: 1.880617618560791 | harorar|urur|u \n",
            "r\\ Iteration: 4061 Loss: 1.7564051151275635 | hoartoror|o \n",
            "r\\ Iteration: 4062 Loss: 1.8835158348083496 | horaruaurur|u \n",
            "r\\ Iteration: 4063 Loss: 1.7939910888671875 | hoaraoraor|urur|u \n",
            "r\\ Iteration: 4064 Loss: 1.780376672744751 | haurtoorruoor|u \n",
            "r\\ Iteration: 4065 Loss: 2.1184022426605225 | huaataartar|urur|u \n",
            "r\\ Iteration: 4066 Loss: 1.8415324687957764 | huaraor|ot|u \n",
            "r\\ Iteration: 4067 Loss: 1.9517850875854492 | honaoarr|urur|u \n",
            "r\\ Iteration: 4068 Loss: 1.7226474285125732 | huraarur|urur|u \n",
            "r\\ Iteration: 4069 Loss: 1.7808592319488525 | hortaat|urur|u \n",
            "r\\ Iteration: 4070 Loss: 1.7777595520019531 | hanausos|astuts|u \n",
            "r\\ Iteration: 4071 Loss: 1.7547097206115723 | hutaosaas|uhur|u \n",
            "r\\ Iteration: 4072 Loss: 1.9358232021331787 | heataasatous|u \n",
            "r\\ Iteration: 4073 Loss: 1.8650636672973633 | hatautaaurur|u \n",
            "r\\ Iteration: 4074 Loss: 1.7557072639465332 | hararatatau \n",
            "r\\ Iteration: 4075 Loss: 1.717911958694458 | haraas|urur|u \n",
            "r\\ Iteration: 4076 Loss: 1.7691729068756104 | huarar|urur|u \n",
            "r\\ Iteration: 4077 Loss: 1.694875955581665 | hunaraa \n",
            "r\\ Iteration: 4078 Loss: 1.894934892654419 | heanarutauuataur|u \n",
            "r\\ Iteration: 4079 Loss: 1.9926986694335938 | haaras|urur|u \n",
            "r\\ Iteration: 4080 Loss: 1.6553585529327393 | haattataus|urur|u \n",
            "r\\ Iteration: 4081 Loss: 1.7320332527160645 | haataaussuthos|u \n",
            "r\\ Iteration: 4082 Loss: 1.8863334655761719 | hetas|s|urur|u \n",
            "r\\ Iteration: 4083 Loss: 1.6140315532684326 | haataauaus|urur|u \n",
            "r\\ Iteration: 4084 Loss: 1.7065613269805908 | huaanatasan|u \n",
            "r\\ Iteration: 4085 Loss: 1.8519487380981445 | hanatas|hs|onar|u \n",
            "r\\ Iteration: 4086 Loss: 1.9564740657806396 | hhanattas||usus|u \n",
            "r\\ Iteration: 4087 Loss: 1.8542852401733398 | hertaununhos|u \n",
            "r\\ Iteration: 4088 Loss: 1.8825724124908447 | hhnaranaru \n",
            "r\\ Iteration: 4089 Loss: 2.172037363052368 | hhntnaaoos|usus|u \n",
            "r\\ Iteration: 4090 Loss: 1.6862311363220215 | hhaarurusus|u \n",
            "r\\ Iteration: 4091 Loss: 1.9769458770751953 | hhnraours|usus|u \n",
            "r\\ Iteration: 4092 Loss: 1.7970037460327148 | hhaunanos|u \n",
            "r\\ Iteration: 4093 Loss: 1.8649871349334717 | hhnarosos|u \n",
            "r\\ Iteration: 4094 Loss: 1.8237895965576172 | hunaos|a|u \n",
            "r\\ Iteration: 4095 Loss: 1.8135309219360352 | hhnonon|usus|u \n",
            "r\\ Iteration: 4096 Loss: 1.7411775588989258 | hhruanonon|u \n",
            "r\\ Iteration: 4097 Loss: 1.8473360538482666 | hhanusonon|u \n",
            "r\\ Iteration: 4098 Loss: 1.8324053287506104 | hunon|usus|u \n",
            "r\\ Iteration: 4099 Loss: 1.674494743347168 | hururn|usus|u \n",
            "r\\ Iteration: 4100 Loss: 1.8139629364013672 | huaurus|usus|u \n",
            "r\\ Iteration: 4101 Loss: 1.7289986610412598 | hhan|usus|u \n",
            "r\\ Iteration: 4102 Loss: 1.5687129497528076 | hhnonon|our|u \n",
            "r\\ Iteration: 4103 Loss: 1.8792507648468018 | hharnurus|u \n",
            "r\\ Iteration: 4104 Loss: 2.022714376449585 | huainusu|usus|u \n",
            "r\\ Iteration: 4105 Loss: 1.8824927806854248 | huaus|urus|u \n",
            "r\\ Iteration: 4106 Loss: 1.7394843101501465 | hhinss||u|urur|u \n",
            "r\\ Iteration: 4107 Loss: 1.898353099822998 | huinishrusoss|u \n",
            "r\\ Iteration: 4108 Loss: 1.84395432472229 | huraousososhr|u \n",
            "r\\ Iteration: 4109 Loss: 1.8947625160217285 | hhrotussosuu \n",
            "r\\ Iteration: 4110 Loss: 1.873281717300415 | hhraunos|s|urur|u \n",
            "r\\ Iteration: 4111 Loss: 1.710585355758667 | hharaaurur|u \n",
            "r\\ Iteration: 4112 Loss: 1.7771177291870117 | hhrraraaa \n",
            "r\\ Iteration: 4113 Loss: 2.0489306449890137 | hhrnaaraaa \n",
            "r\\ Iteration: 4114 Loss: 1.9174933433532715 | hhanararaurur|u \n",
            "r\\ Iteration: 4115 Loss: 1.744899034500122 | hhaararaaaurur|u \n",
            "r\\ Iteration: 4116 Loss: 1.7334673404693604 | hhaaaaararaaraa \n",
            "r\\ Iteration: 4117 Loss: 1.9939086437225342 | hhaaaaarararaa \n",
            "r\\ Iteration: 4118 Loss: 1.9847607612609863 | hhraararar|urur|a \n",
            "r\\ Iteration: 4119 Loss: 1.8985326290130615 | hhaaar|raaraa \n",
            "r\\ Iteration: 4120 Loss: 1.8880980014801025 | hharaaar|ra \n",
            "r\\ Iteration: 4121 Loss: 1.9514594078063965 | hhraaaaurur|a \n",
            "r\\ Iteration: 4122 Loss: 1.7545051574707031 | hhraarasasaaraa \n",
            "r\\ Iteration: 4123 Loss: 1.6816439628601074 | hhranar|a \n",
            "r\\ Iteration: 4124 Loss: 1.9511828422546387 | hhraaarsaarar|a \n",
            "r\\ Iteration: 4125 Loss: 2.005369186401367 | hhrar|urur|u \n",
            "r\\ Iteration: 4126 Loss: 1.711432933807373 | hharaaarr|urur|u \n",
            "r\\ Iteration: 4127 Loss: 1.7702810764312744 | hhaaas|urur|u \n",
            "r\\ Iteration: 4128 Loss: 1.7598352432250977 | hhrar|raarrr|a \n",
            "r\\ Iteration: 4129 Loss: 1.8010203838348389 | hhraauasr|u \n",
            "r\\ Iteration: 4130 Loss: 1.9852328300476074 | hhtaar|ar|u \n",
            "r\\ Iteration: 4131 Loss: 1.986851692199707 | hhnaa|rr|rsa \n",
            "r\\ Iteration: 4132 Loss: 2.060208320617676 | hhanar|urur|u \n",
            "r\\ Iteration: 4133 Loss: 1.5778272151947021 | hharar|urur|u \n",
            "r\\ Iteration: 4134 Loss: 1.6914663314819336 | hhnasarar|urur|u \n",
            "r\\ Iteration: 4135 Loss: 1.7058727741241455 | hhaaraarasaar|u \n",
            "r\\ Iteration: 4136 Loss: 2.033214569091797 | hhnaas|aaasasaa \n",
            "r\\ Iteration: 4137 Loss: 1.9339890480041504 | hhanaarrr|urur|u \n",
            "r\\ Iteration: 4138 Loss: 1.6494674682617188 | hharar|hr|arar|u \n",
            "r\\ Iteration: 4139 Loss: 1.9269378185272217 | hhnaraa \n",
            "r\\ Iteration: 4140 Loss: 1.8829066753387451 | hhaan|urur|u \n",
            "r\\ Iteration: 4141 Loss: 1.7243006229400635 | hhaan|aar|urur|u \n",
            "r\\ Iteration: 4142 Loss: 1.8214004039764404 | hhnaanan|raar|u \n",
            "r\\ Iteration: 4143 Loss: 1.8544518947601318 | hhnannarar|u \n",
            "r\\ Iteration: 4144 Loss: 1.9951448440551758 | hhaan|an|urur|u \n",
            "r\\ Iteration: 4145 Loss: 1.7706046104431152 | hhnananana \n",
            "r\\ Iteration: 4146 Loss: 2.0075085163116455 | hhanan|nna \n",
            "r\\ Iteration: 4147 Loss: 1.8525633811950684 | hhntnaon|urur|u \n",
            "r\\ Iteration: 4148 Loss: 1.7512145042419434 | hhnaonanan|uruna \n",
            "r\\ Iteration: 4149 Loss: 1.7792308330535889 | hhnaan|on|onar|u \n",
            "r\\ Iteration: 4150 Loss: 1.9390921592712402 | hhnarnaan|urur|u \n",
            "r\\ Iteration: 4151 Loss: 1.7880418300628662 | hhnanhnaananar|u \n",
            "r\\ Iteration: 4152 Loss: 1.9670219421386719 | hhtnan|urur|u \n",
            "r\\ Iteration: 4153 Loss: 1.6805617809295654 | hunaanaanaanna \n",
            "r\\ Iteration: 4154 Loss: 2.0649096965789795 | hhnaan|annaan|u \n",
            "r\\ Iteration: 4155 Loss: 1.871021032333374 | hhnannan|urur|u \n",
            "r\\ Iteration: 4156 Loss: 1.7038085460662842 | hhnanan|urur|u \n",
            "r\\ Iteration: 4157 Loss: 1.6646380424499512 | hhaananhan|urur|u \n",
            "r\\ Iteration: 4158 Loss: 1.6591453552246094 | hhnanananaa \n",
            "r\\ Iteration: 4159 Loss: 1.676938533782959 | hhaananaaurur|u \n",
            "r\\ Iteration: 4160 Loss: 1.8584461212158203 | hhnaanaanauruna \n",
            "r\\ Iteration: 4161 Loss: 1.7818567752838135 | hhnnaaaanan|urur|u \n",
            "r\\ Iteration: 4162 Loss: 1.8114452362060547 | hhannaaaan|urur|u \n",
            "r\\ Iteration: 4163 Loss: 1.6632897853851318 | hhalaranaa \n",
            "r\\ Iteration: 4164 Loss: 1.9382433891296387 | hhalaaar|urur|u \n",
            "r\\ Iteration: 4165 Loss: 1.7411842346191406 | hharaararanaau \n",
            "r\\ Iteration: 4166 Loss: 1.947178840637207 | hhnaarar|urur|u \n",
            "r\\ Iteration: 4167 Loss: 1.6809289455413818 | hhnananar|urur|u \n",
            "r\\ Iteration: 4168 Loss: 1.6755614280700684 | hhnaraararaa \n",
            "r\\ Iteration: 4169 Loss: 1.9194862842559814 | hhnanlr|uruaaar|u \n",
            "r\\ Iteration: 4170 Loss: 1.8248138427734375 | hhnaararaa|a \n",
            "r\\ Iteration: 4171 Loss: 2.094154119491577 | hhralaraasaasaurur|u \n",
            "r\\ Iteration: 4172 Loss: 1.773033857345581 | hhtaaar|urur|u \n",
            "r\\ Iteration: 4173 Loss: 1.628295660018921 | hhnananaurur|u \n",
            "r\\ Iteration: 4174 Loss: 1.623248815536499 | hhnaannaar|urur|u \n",
            "r\\ Iteration: 4175 Loss: 1.8535573482513428 | hhnaanananaa \n",
            "r\\ Iteration: 4176 Loss: 1.794337511062622 | hhnatanaurur|u \n",
            "r\\ Iteration: 4177 Loss: 1.6254653930664062 | hhanaraa|urur|u \n",
            "r\\ Iteration: 4178 Loss: 1.7233867645263672 | hhanaurur|u \n",
            "r\\ Iteration: 4179 Loss: 1.714860439300537 | hhanaaransaar|u \n",
            "r\\ Iteration: 4180 Loss: 1.9498896598815918 | hhtarar|u \n",
            "r\\ Iteration: 4181 Loss: 1.9073984622955322 | hhnanasaa|urur|u \n",
            "r\\ Iteration: 4182 Loss: 1.7477219104766846 | hhanaaraar|urur|u \n",
            "r\\ Iteration: 4183 Loss: 1.7413203716278076 | hhnaan|urur|u \n",
            "r\\ Iteration: 4184 Loss: 1.6735553741455078 | hhtanaar|urur|u \n",
            "r\\ Iteration: 4185 Loss: 1.6703360080718994 | hhnarosasar|u \n",
            "r\\ Iteration: 4186 Loss: 1.871433973312378 | hutttr|s|urur|u \n",
            "r\\ Iteration: 4187 Loss: 1.7069377899169922 | hhntas||as|urur|u \n",
            "r\\ Iteration: 4188 Loss: 1.8591265678405762 | hlaan|urur|u \n",
            "r\\ Iteration: 4189 Loss: 1.707634449005127 | hhanr|urur|u \n",
            "r\\ Iteration: 4190 Loss: 1.7726826667785645 | honasaasantt| \n",
            "r\\ Iteration: 4191 Loss: 2.023427724838257 | hhntas|usus|u \n",
            "r\\ Iteration: 4192 Loss: 1.638763189315796 | hhaustas|ts|oras|u \n",
            "r\\ Iteration: 4193 Loss: 1.982956886291504 | hlarusanatast|u \n",
            "r\\ Iteration: 4194 Loss: 1.924736499786377 | hlasanan|as| \n",
            "r\\ Iteration: 4195 Loss: 2.0614144802093506 | hhrnsus|st \n",
            "r\\ Iteration: 4196 Loss: 2.218256950378418 | hlatasas|u \n",
            "r\\ Iteration: 4197 Loss: 2.0063929557800293 | hhnaatttaat|usus|u \n",
            "r\\ Iteration: 4198 Loss: 1.9029037952423096 | hharaaasaas|usus|u \n",
            "r\\ Iteration: 4199 Loss: 1.8122539520263672 | hhnsaataasaaususau \n",
            "r\\ Iteration: 4200 Loss: 1.7602558135986328 | hltaanaususau \n",
            "r\\ Iteration: 4201 Loss: 1.6943943500518799 | hlaaasataususau \n",
            "r\\ Iteration: 4202 Loss: 1.6669268608093262 | hhasasaaasaataasau \n",
            "r\\ Iteration: 4203 Loss: 2.030179023742676 | huanaasasaa \n",
            "r\\ Iteration: 4204 Loss: 1.8904995918273926 | hunasaususau \n",
            "r\\ Iteration: 4205 Loss: 1.6091458797454834 | haaasasaasaasasau \n",
            "r\\ Iteration: 4206 Loss: 1.9788720607757568 | hlnaasaasaususau \n",
            "r\\ Iteration: 4207 Loss: 1.7254765033721924 | honaasaaaasau \n",
            "r\\ Iteration: 4208 Loss: 1.8885815143585205 | hlnasasaasau \n",
            "r\\ Iteration: 4209 Loss: 1.8471813201904297 | hhanaasaasaasasssaa \n",
            "r\\ Iteration: 4210 Loss: 1.8950746059417725 | hhasasasassau \n",
            "r\\ Iteration: 4211 Loss: 1.733658790588379 | haaaasasasasaa \n",
            "r\\ Iteration: 4212 Loss: 1.8139686584472656 | haaasusasasau \n",
            "r\\ Iteration: 4213 Loss: 1.9763495922088623 | harasasaususau \n",
            "r\\ Iteration: 4214 Loss: 1.7361817359924316 | hhansaususau \n",
            "r\\ Iteration: 4215 Loss: 1.7560296058654785 | hhnasasasau \n",
            "r\\ Iteration: 4216 Loss: 1.736551284790039 | hhnasarasau \n",
            "r\\ Iteration: 4217 Loss: 1.8198812007904053 | hhnasasaususau \n",
            "r\\ Iteration: 4218 Loss: 1.654465675354004 | hhnaasasaususau \n",
            "r\\ Iteration: 4219 Loss: 1.639146089553833 | hhrasashusaasaususau \n",
            "r\\ Iteration: 4220 Loss: 1.7868735790252686 | hhraasaaasa \n",
            "r\\ Iteration: 4221 Loss: 2.014594554901123 | hhrsasaaa \n",
            "r\\ Iteration: 4222 Loss: 2.113900899887085 | hhnaas|usus|hs|u \n",
            "r\\ Iteration: 4223 Loss: 1.7777163982391357 | hhnsoshasar|u \n",
            "r\\ Iteration: 4224 Loss: 2.0359504222869873 | haaras|rhus|usus|u \n",
            "r\\ Iteration: 4225 Loss: 1.703028917312622 | haaaas|aa \n",
            "r\\ Iteration: 4226 Loss: 2.06080961227417 | hhoasas|usus|u \n",
            "r\\ Iteration: 4227 Loss: 1.7269911766052246 | haraasas|hs|osas|u \n",
            "r\\ Iteration: 4228 Loss: 1.8984589576721191 | hlaaas|usus|u \n",
            "r\\ Iteration: 4229 Loss: 1.634613037109375 | harroshssas|u \n",
            "r\\ Iteration: 4230 Loss: 1.9144179821014404 | hanns|u|usus|u \n",
            "r\\ Iteration: 4231 Loss: 1.8099501132965088 | harasas|usus| \n",
            "r\\ Iteration: 4232 Loss: 1.7163722515106201 | haonashrusoss|u \n",
            "r\\ Iteration: 4233 Loss: 1.8476243019104004 | haonaos|usus|u \n",
            "r\\ Iteration: 4234 Loss: 1.7479326725006104 | haoanoos|| \n",
            "r\\ Iteration: 4235 Loss: 1.9057800769805908 | haraus|usus|u \n",
            "r\\ Iteration: 4236 Loss: 1.7759616374969482 | hartsaus|urur|u \n",
            "r\\ Iteration: 4237 Loss: 1.749589204788208 | haoartas|urur|u \n",
            "r\\ Iteration: 4238 Loss: 1.7836635112762451 | haanararosarsau \n",
            "r\\ Iteration: 4239 Loss: 1.7730050086975098 | haaaaraastraasa \n",
            "r\\ Iteration: 4240 Loss: 2.112985849380493 | haarnaaasss|urur|u \n",
            "r\\ Iteration: 4241 Loss: 1.780874252319336 | haacaar|urur|u \n",
            "r\\ Iteration: 4242 Loss: 1.8040616512298584 | haaarsasasasau \n",
            "r\\ Iteration: 4243 Loss: 1.8465886116027832 | harnaaasaar|urur|u \n",
            "r\\ Iteration: 4244 Loss: 1.7451801300048828 | haaasasasa \n",
            "r\\ Iteration: 4245 Loss: 1.8803088665008545 | laaararassa \n",
            "r\\ Iteration: 4246 Loss: 1.8901076316833496 | laaarsarsa \n",
            "r\\ Iteration: 4247 Loss: 1.956017017364502 | laraasararaasara \n",
            "r\\ Iteration: 4248 Loss: 1.9799120426177979 | laaarararsa \n",
            "r\\ Iteration: 4249 Loss: 1.872497797012329 | laaaaaurur|u \n",
            "r\\ Iteration: 4250 Loss: 1.6309890747070312 | laraosarursa \n",
            "r\\ Iteration: 4251 Loss: 1.9221413135528564 | laarraurur|u \n",
            "r\\ Iteration: 4252 Loss: 1.6551659107208252 | laaarar|urur|u \n",
            "r\\ Iteration: 4253 Loss: 1.7281064987182617 | laaaarr|urur|u \n",
            "r\\ Iteration: 4254 Loss: 1.7505378723144531 | loaotarasartao \n",
            "r\\ Iteration: 4255 Loss: 1.8679239749908447 | laataaosar|aar|urur|u \n",
            "r\\ Iteration: 4256 Loss: 1.8146634101867676 | laartrtarasar|a \n",
            "r\\ Iteration: 4257 Loss: 1.8218457698822021 | lonaaaarasartau \n",
            "r\\ Iteration: 4258 Loss: 1.7150471210479736 | laaoarararoraa \n",
            "r\\ Iteration: 4259 Loss: 1.8442561626434326 | laarataaasar|urur|u \n",
            "r\\ Iteration: 4260 Loss: 1.8484878540039062 | laaataos|urur|u \n",
            "r\\ Iteration: 4261 Loss: 1.8228652477264404 | laararrur|u \n",
            "r\\ Iteration: 4262 Loss: 1.6884963512420654 | laaatar|urur|u \n",
            "r\\ Iteration: 4263 Loss: 1.6095759868621826 | laaoorar|o \n",
            "r\\ Iteration: 4264 Loss: 2.164029598236084 | laaoaaraosaorartsao \n",
            "r\\ Iteration: 4265 Loss: 1.8487069606781006 | laaaaarr|urur|u \n",
            "r\\ Iteration: 4266 Loss: 1.7282741069793701 | loaoaoroaurur|u \n",
            "r\\ Iteration: 4267 Loss: 1.8956985473632812 | laaonaror|o \n",
            "r\\ Iteration: 4268 Loss: 1.8726601600646973 | lonaoaaosos|a \n",
            "r\\ Iteration: 4269 Loss: 1.7934935092926025 | laaaortsaorartasar|urur|u \n",
            "r\\ Iteration: 4270 Loss: 1.7523376941680908 | laaooraurur|u \n",
            "r\\ Iteration: 4271 Loss: 1.6808483600616455 | loaoarasasao \n",
            "r\\ Iteration: 4272 Loss: 1.7315340042114258 | laaaatar|urur|u \n",
            "r\\ Iteration: 4273 Loss: 1.595797061920166 | naaoortr|usor|o \n",
            "r\\ Iteration: 4274 Loss: 1.9059865474700928 | naaraaraaarosortau \n",
            "r\\ Iteration: 4275 Loss: 1.8532912731170654 | noaraas|or|rair|u \n",
            "r\\ Iteration: 4276 Loss: 1.8020963668823242 | naaanrr|urus|ar|u \n",
            "r\\ Iteration: 4277 Loss: 1.7823858261108398 | naarararasortau \n",
            "r\\ Iteration: 4278 Loss: 1.7459208965301514 | naaanaasar|u \n",
            "r\\ Iteration: 4279 Loss: 1.8021197319030762 | naaaoarar|urur|u \n",
            "r\\ Iteration: 4280 Loss: 1.7760775089263916 | naaanaurur|u \n",
            "r\\ Iteration: 4281 Loss: 1.6744349002838135 | nananaaa|a \n",
            "r\\ Iteration: 4282 Loss: 1.8589723110198975 | naoonar|ror|u \n",
            "r\\ Iteration: 4283 Loss: 1.8016784191131592 | naaaatas|urur|u \n",
            "r\\ Iteration: 4284 Loss: 1.671881914138794 | naaantasasau \n",
            "r\\ Iteration: 4285 Loss: 1.7580621242523193 | naaoraaaas|urur|u \n",
            "r\\ Iteration: 4286 Loss: 1.6621713638305664 | naaraanaas|urur|u \n",
            "r\\ Iteration: 4287 Loss: 1.7687814235687256 | naananos|urur|u \n",
            "r\\ Iteration: 4288 Loss: 1.7326858043670654 | noaanaurur|u \n",
            "r\\ Iteration: 4289 Loss: 1.671574354171753 | naaaraasaussisau \n",
            "r\\ Iteration: 4290 Loss: 2.080610752105713 | naaanaaurur|u \n",
            "r\\ Iteration: 4291 Loss: 1.743842363357544 | naaraasurur|u \n",
            "r\\ Iteration: 4292 Loss: 1.7840442657470703 | naanaastis|u \n",
            "r\\ Iteration: 4293 Loss: 2.0860068798065186 | naaaasas|urur|u \n",
            "r\\ Iteration: 4294 Loss: 1.6059269905090332 | noaanaurus|u \n",
            "r\\ Iteration: 4295 Loss: 1.63204026222229 | noaaasausus|u \n",
            "r\\ Iteration: 4296 Loss: 1.6005079746246338 | noaanausus|u \n",
            "r\\ Iteration: 4297 Loss: 1.6938221454620361 | nanasas|usus|u \n",
            "r\\ Iteration: 4298 Loss: 1.7310762405395508 | naanasaassa \n",
            "r\\ Iteration: 4299 Loss: 1.929901123046875 | naaaosas|usus|u \n",
            "r\\ Iteration: 4300 Loss: 1.8657934665679932 | naaanas|usus|u \n",
            "r\\ Iteration: 4301 Loss: 1.670151710510254 | nanoas|aussass|u \n",
            "r\\ Iteration: 4302 Loss: 1.8794569969177246 | naaanasas|as \n",
            "r\\ Iteration: 4303 Loss: 2.0025482177734375 | naaaaasas|a \n",
            "r\\ Iteration: 4304 Loss: 1.9868688583374023 | naaaosasas|a \n",
            "r\\ Iteration: 4305 Loss: 2.0098772048950195 | nanaanausus|u \n",
            "r\\ Iteration: 4306 Loss: 1.6027677059173584 | naaoanaasaas|a \n",
            "r\\ Iteration: 4307 Loss: 1.9402644634246826 | laananasasass|u \n",
            "r\\ Iteration: 4308 Loss: 1.7574131488800049 | laaaanausus|u \n",
            "r\\ Iteration: 4309 Loss: 1.7034416198730469 | lanaaausus|u \n",
            "r\\ Iteration: 4310 Loss: 1.710700273513794 | llananausus|u \n",
            "r\\ Iteration: 4311 Loss: 1.605900764465332 | laaanaas|usus|u \n",
            "r\\ Iteration: 4312 Loss: 1.6547715663909912 | laaaaaas|usus|u \n",
            "r\\ Iteration: 4313 Loss: 1.6206753253936768 | llaaaaasas|u \n",
            "r\\ Iteration: 4314 Loss: 1.9818315505981445 | lacacas|usus|u \n",
            "r\\ Iteration: 4315 Loss: 1.5808939933776855 | laaaraaa \n",
            "r\\ Iteration: 4316 Loss: 1.870694637298584 | laaanars|usus|u \n",
            "r\\ Iteration: 4317 Loss: 1.848867416381836 | lacanausus|u \n",
            "r\\ Iteration: 4318 Loss: 1.6739180088043213 | laaara \n",
            "r\\ Iteration: 4319 Loss: 2.347313404083252 | laaaaaus|s|usus|u \n",
            "r\\ Iteration: 4320 Loss: 1.8491876125335693 | laaraasaaasasash|u \n",
            "r\\ Iteration: 4321 Loss: 1.8521368503570557 | laccasas|usus|u \n",
            "r\\ Iteration: 4322 Loss: 1.629438877105713 | lcaaas|s|as|usus|u \n",
            "r\\ Iteration: 4323 Loss: 1.844682216644287 | laaashnaaashasar|u \n",
            "r\\ Iteration: 4324 Loss: 1.8705084323883057 | laacas|||usus|u \n",
            "r\\ Iteration: 4325 Loss: 1.6989922523498535 | locaasas|usus|u \n",
            "r\\ Iteration: 4326 Loss: 1.80218505859375 | laacaaaaaa|a \n",
            "r\\ Iteration: 4327 Loss: 2.1106574535369873 | locarasosao \n",
            "r\\ Iteration: 4328 Loss: 1.8832592964172363 | lacanaossa \n",
            "r\\ Iteration: 4329 Loss: 1.8594279289245605 | laacarhososao \n",
            "r\\ Iteration: 4330 Loss: 1.9129149913787842 | loconasosao \n",
            "r\\ Iteration: 4331 Loss: 1.78948974609375 | lacaasaurur|u \n",
            "r\\ Iteration: 4332 Loss: 1.6674168109893799 | laaaasoss|usur|u \n",
            "r\\ Iteration: 4333 Loss: 1.705082654953003 | laaorasoaaurur|u \n",
            "r\\ Iteration: 4334 Loss: 1.7611312866210938 | laaoaosoos|usur|u \n",
            "r\\ Iteration: 4335 Loss: 1.7434642314910889 | loanasoa|or|u \n",
            "r\\ Iteration: 4336 Loss: 1.833000898361206 | looaaosos|osososau \n",
            "r\\ Iteration: 4337 Loss: 1.8345921039581299 | lacoassoss|urur|u \n",
            "r\\ Iteration: 4338 Loss: 1.7801222801208496 | lacoaanos|urur|u \n",
            "r\\ Iteration: 4339 Loss: 1.600989580154419 | hoaoras|urur|u \n",
            "r\\ Iteration: 4340 Loss: 1.7552683353424072 | hocoroosos|urur|u \n",
            "r\\ Iteration: 4341 Loss: 1.700648307800293 | haraanasosoo \n",
            "r\\ Iteration: 4342 Loss: 1.8014421463012695 | hoarna \n",
            "r\\ Iteration: 4343 Loss: 1.9742062091827393 | hococasruo \n",
            "r\\ Iteration: 4344 Loss: 2.071572780609131 | haoooras|usus|u \n",
            "r\\ Iteration: 4345 Loss: 1.7308809757232666 | hocorarao \n",
            "r\\ Iteration: 4346 Loss: 1.960097074508667 | hoaooonausus|u \n",
            "r\\ Iteration: 4347 Loss: 1.798992395401001 | haaraoraos|u \n",
            "r\\ Iteration: 4348 Loss: 1.9419691562652588 | hacaroanaos|o \n",
            "r\\ Iteration: 4349 Loss: 2.204350233078003 | haraoanrs|usus|u \n",
            "r\\ Iteration: 4350 Loss: 1.8154776096343994 | hararoasoussos|u \n",
            "r\\ Iteration: 4351 Loss: 1.934784173965454 | haaroaraurus|u \n",
            "r\\ Iteration: 4352 Loss: 1.86641526222229 | haronnasanos|u \n",
            "r\\ Iteration: 4353 Loss: 1.7722947597503662 | haaronaous|usus|u \n",
            "r\\ Iteration: 4354 Loss: 1.7510323524475098 | hararausus|u \n",
            "r\\ Iteration: 4355 Loss: 1.694943904876709 | hararsanas|usus|u \n",
            "r\\ Iteration: 4356 Loss: 1.7289042472839355 | harorussau \n",
            "r\\ Iteration: 4357 Loss: 1.9079453945159912 | haraaosushos|u \n",
            "r\\ Iteration: 4358 Loss: 1.7900731563568115 | harrorsisosasau \n",
            "r\\ Iteration: 4359 Loss: 1.8536648750305176 | haroraususassis|u \n",
            "r\\ Iteration: 4360 Loss: 1.7232983112335205 | haararaos|usus|u \n",
            "r\\ Iteration: 4361 Loss: 1.7777900695800781 | hararas|usus|u \n",
            "r\\ Iteration: 4362 Loss: 1.742504358291626 | haararsaos|usus|u \n",
            "r\\ Iteration: 4363 Loss: 1.7961022853851318 | haarrsssos|usus|u \n",
            "r\\ Iteration: 4364 Loss: 1.777700424194336 | harao \n",
            "r\\ Iteration: 4365 Loss: 2.058396816253662 | hararaoss|u \n",
            "r\\ Iteration: 4366 Loss: 1.9267017841339111 | haraasausus|u \n",
            "r\\ Iteration: 4367 Loss: 1.621466875076294 | haraaass|usus|u \n",
            "r\\ Iteration: 4368 Loss: 1.7247164249420166 | hararasasasa \n",
            "r\\ Iteration: 4369 Loss: 2.119206428527832 | haarsasosaau \n",
            "r\\ Iteration: 4370 Loss: 1.9146912097930908 | haaarsausus|u \n",
            "r\\ Iteration: 4371 Loss: 1.6792042255401611 | haarnasos|u \n",
            "r\\ Iteration: 4372 Loss: 1.8915510177612305 | harararusossau \n",
            "r\\ Iteration: 4373 Loss: 1.7428529262542725 | haaaarasaas|u \n",
            "r\\ Iteration: 4374 Loss: 1.8874781131744385 | haraoaasasaususu \n",
            "r\\ Iteration: 4375 Loss: 1.8754174709320068 | haarasarssasas|u \n",
            "r\\ Iteration: 4376 Loss: 1.9332184791564941 | haaoorausus|u \n",
            "r\\ Iteration: 4377 Loss: 1.7062759399414062 | haaaasasos|u \n",
            "r\\ Iteration: 4378 Loss: 1.847762107849121 | naarosassas|u \n",
            "r\\ Iteration: 4379 Loss: 1.8871586322784424 | naaossausus|u \n",
            "r\\ Iteration: 4380 Loss: 1.5727827548980713 | naararusossau \n",
            "r\\ Iteration: 4381 Loss: 1.8413763046264648 | naaasus|usus|u \n",
            "r\\ Iteration: 4382 Loss: 1.576688528060913 | naarsas|usus|u \n",
            "r\\ Iteration: 4383 Loss: 1.669050931930542 | naaaosus|usus|u \n",
            "r\\ Iteration: 4384 Loss: 1.664790391921997 | naaaaa|ususu \n",
            "r\\ Iteration: 4385 Loss: 1.697587013244629 | naaaasasu|u|u \n",
            "r\\ Iteration: 4386 Loss: 1.9947965145111084 | naaaasos|u \n",
            "r\\ Iteration: 4387 Loss: 1.8492469787597656 | naaanarusoss|u \n",
            "r\\ Iteration: 4388 Loss: 1.7448573112487793 | naaaasaoss|u \n",
            "r\\ Iteration: 4389 Loss: 1.7793362140655518 | naaaas|s|usus|u \n",
            "r\\ Iteration: 4390 Loss: 1.666943073272705 | naaanarusoss|u \n",
            "r\\ Iteration: 4391 Loss: 1.812209129333496 | naaaaasas|usus|u \n",
            "r\\ Iteration: 4392 Loss: 1.7091355323791504 | naararaas|u \n",
            "r\\ Iteration: 4393 Loss: 1.8706984519958496 | naaaaanos|usus|u \n",
            "r\\ Iteration: 4394 Loss: 1.6136054992675781 | naaaaasssos|usus|u \n",
            "r\\ Iteration: 4395 Loss: 1.6730473041534424 | naaoasasaua|u \n",
            "r\\ Iteration: 4396 Loss: 1.9935522079467773 | naaaoosos|u \n",
            "r\\ Iteration: 4397 Loss: 1.952451467514038 | naaaaraa|usus|u \n",
            "r\\ Iteration: 4398 Loss: 1.7909371852874756 | naaaaaousas|u \n",
            "r\\ Iteration: 4399 Loss: 1.9303481578826904 | naaasss|u \n",
            "r\\ Iteration: 4400 Loss: 1.7700741291046143 | naaoossaaaasos|u \n",
            "r\\ Iteration: 4401 Loss: 1.7899436950683594 | naaaanousass|u \n",
            "r\\ Iteration: 4402 Loss: 1.943652629852295 | naoasarusoss|u \n",
            "r\\ Iteration: 4403 Loss: 1.7336349487304688 | naaoasanaous|usus|u \n",
            "r\\ Iteration: 4404 Loss: 1.714580774307251 | naaoranos|u \n",
            "r\\ Iteration: 4405 Loss: 1.9111847877502441 | naaroauausus|u \n",
            "r\\ Iteration: 4406 Loss: 1.7857780456542969 | naraasarusoss|u \n",
            "r\\ Iteration: 4407 Loss: 1.7170872688293457 | naaaaaosos|usus|u \n",
            "r\\ Iteration: 4408 Loss: 1.7657878398895264 | naraosus|shus|u \n",
            "r\\ Iteration: 4409 Loss: 1.83176589012146 | narrnausus|u \n",
            "r\\ Iteration: 4410 Loss: 1.7152719497680664 | naaroausus|u \n",
            "r\\ Iteration: 4411 Loss: 1.7550930976867676 | naaronausus|u \n",
            "r\\ Iteration: 4412 Loss: 1.6673600673675537 | naaaonausus|es|u \n",
            "r\\ Iteration: 4413 Loss: 1.79653000831604 | nrarasos|u \n",
            "r\\ Iteration: 4414 Loss: 1.8947935104370117 | naaraaass|usus|u \n",
            "r\\ Iteration: 4415 Loss: 1.8293559551239014 | nananau \n",
            "r\\ Iteration: 4416 Loss: 1.693371057510376 | naroanas|usus|u \n",
            "r\\ Iteration: 4417 Loss: 1.7985153198242188 | noaraosss|u \n",
            "r\\ Iteration: 4418 Loss: 1.8792672157287598 | naroasasau \n",
            "r\\ Iteration: 4419 Loss: 1.8903133869171143 | nanoasaausus|u \n",
            "r\\ Iteration: 4420 Loss: 1.7337675094604492 | naaoas|usus|u \n",
            "r\\ Iteration: 4421 Loss: 1.757711410522461 | nanoasaausus|u \n",
            "r\\ Iteration: 4422 Loss: 1.7218129634857178 | nananss|usus|u \n",
            "r\\ Iteration: 4423 Loss: 1.7660040855407715 | haanaooss|os|os \n",
            "r\\ Iteration: 4424 Loss: 2.08170485496521 | hanaosas|usus|u \n",
            "r\\ Iteration: 4425 Loss: 1.5890867710113525 | hanruaaosas|usus|u \n",
            "r\\ Iteration: 4426 Loss: 1.7294578552246094 | honarososs|u \n",
            "r\\ Iteration: 4427 Loss: 1.691988229751587 | honoosasos||s|u \n",
            "r\\ Iteration: 4428 Loss: 1.9258854389190674 | hananasososs|u \n",
            "r\\ Iteration: 4429 Loss: 1.6925063133239746 | hanoaas|usus|u \n",
            "r\\ Iteration: 4430 Loss: 1.5822019577026367 | hanarasos|u \n",
            "r\\ Iteration: 4431 Loss: 1.8387279510498047 | hanaonossos|u \n",
            "r\\ Iteration: 4432 Loss: 1.6985673904418945 | hoaooosas|usus|u \n",
            "r\\ Iteration: 4433 Loss: 1.7339177131652832 | haoaooas|usus|u \n",
            "r\\ Iteration: 4434 Loss: 1.6771938800811768 | hononoas|u \n",
            "r\\ Iteration: 4435 Loss: 1.935784101486206 | hanaraos|usus|u \n",
            "r\\ Iteration: 4436 Loss: 1.6912987232208252 | hoononausus|u \n",
            "r\\ Iteration: 4437 Loss: 1.8353779315948486 | hoaaonos|o \n",
            "r\\ Iteration: 4438 Loss: 1.8148672580718994 | hanonast \n",
            "r\\ Iteration: 4439 Loss: 2.2672383785247803 | hononarososs|u \n",
            "r\\ Iteration: 4440 Loss: 1.7148184776306152 | haaoonas|usus|u \n",
            "r\\ Iteration: 4441 Loss: 1.7836940288543701 | hoaoonos|u \n",
            "r\\ Iteration: 4442 Loss: 1.784386396408081 | hanaraasausus|u \n",
            "r\\ Iteration: 4443 Loss: 1.7070574760437012 | hanonaos|usus|u \n",
            "r\\ Iteration: 4444 Loss: 1.733048677444458 | horosas|usus| \n",
            "r\\ Iteration: 4445 Loss: 1.8090579509735107 | hononaous|shos|u \n",
            "r\\ Iteration: 4446 Loss: 1.9133718013763428 | honoaosso \n",
            "r\\ Iteration: 4447 Loss: 1.8146693706512451 | haaosos|u \n",
            "r\\ Iteration: 4448 Loss: 1.9131982326507568 | hrrosasaos|os|u \n",
            "r\\ Iteration: 4449 Loss: 1.943272352218628 | honsaasoos|urur|u \n",
            "r\\ Iteration: 4450 Loss: 1.818666696548462 | haasasos|u \n",
            "r\\ Iteration: 4451 Loss: 1.8443231582641602 | honors|urur|u \n",
            "r\\ Iteration: 4452 Loss: 1.6026113033294678 | haooasaraos|u \n",
            "r\\ Iteration: 4453 Loss: 1.8963749408721924 | harosss|usos|u \n",
            "r\\ Iteration: 4454 Loss: 1.9536242485046387 | horashosoroos|o \n",
            "r\\ Iteration: 4455 Loss: 1.8989479541778564 | haaooroo|urur|u \n",
            "r\\ Iteration: 4456 Loss: 1.806387186050415 | hooasadhoaosau \n",
            "r\\ Iteration: 4457 Loss: 1.7438647747039795 | horosaraurur|u \n",
            "r\\ Iteration: 4458 Loss: 1.7128140926361084 | hoanasaator|u \n",
            "r\\ Iteration: 4459 Loss: 1.8095614910125732 | haaoaasaod|urur|u \n",
            "r\\ Iteration: 4460 Loss: 1.7219722270965576 | haaooasarotashao \n",
            "r\\ Iteration: 4461 Loss: 1.8645529747009277 | hoaotaronasoao \n",
            "r\\ Iteration: 4462 Loss: 1.7469313144683838 | hoaoaosorao \n",
            "r\\ Iteration: 4463 Loss: 1.8056178092956543 | haaaosonaurur|u \n",
            "r\\ Iteration: 4464 Loss: 1.6697704792022705 | hoaosasor|o \n",
            "r\\ Iteration: 4465 Loss: 2.010586738586426 | hoaaasas|urur|u \n",
            "r\\ Iteration: 4466 Loss: 1.7307777404785156 | hoaaosas|usus|u \n",
            "r\\ Iteration: 4467 Loss: 1.7645847797393799 | haanaoosaod|usus|u \n",
            "r\\ Iteration: 4468 Loss: 1.762674331665039 | hoaaoas|usus|u \n",
            "r\\ Iteration: 4469 Loss: 1.7481489181518555 | haoosausussonos|u \n",
            "r\\ Iteration: 4470 Loss: 1.7733285427093506 | horooaossossus|o \n",
            "r\\ Iteration: 4471 Loss: 1.9860198497772217 | hraonausus|u \n",
            "r\\ Iteration: 4472 Loss: 1.7032597064971924 | hraoos||usus|u \n",
            "r\\ Iteration: 4473 Loss: 1.8070220947265625 | honoosos|usus|u \n",
            "r\\ Iteration: 4474 Loss: 1.7284808158874512 | hraonoosos|u \n",
            "r\\ Iteration: 4475 Loss: 1.9397718906402588 | hraass|u \n",
            "r\\ Iteration: 4476 Loss: 2.049739122390747 | honoruaurur|u \n",
            "r\\ Iteration: 4477 Loss: 1.8102858066558838 | haaonos||o \n",
            "r\\ Iteration: 4478 Loss: 1.881533145904541 | haaoosoros|u \n",
            "r\\ Iteration: 4479 Loss: 1.8587491512298584 | hononooooo|oo \n",
            "r\\ Iteration: 4480 Loss: 1.7458422183990479 | haoonsosousor|u \n",
            "r\\ Iteration: 4481 Loss: 1.9805335998535156 | haososs|u \n",
            "r\\ Iteration: 4482 Loss: 1.7910819053649902 | honoroo||urur|u \n",
            "r\\ Iteration: 4483 Loss: 1.727238416671753 | hoarosooasoo|our|u \n",
            "r\\ Iteration: 4484 Loss: 1.9405269622802734 | honoroossuoo \n",
            "r\\ Iteration: 4485 Loss: 1.9145514965057373 | hoaoos|s|usus|u \n",
            "r\\ Iteration: 4486 Loss: 1.685244083404541 | hraoosos|ossus|u \n",
            "r\\ Iteration: 4487 Loss: 1.7087478637695312 | horntososo \n",
            "r\\ Iteration: 4488 Loss: 2.1116130352020264 | horosoas|u \n",
            "r\\ Iteration: 4489 Loss: 1.8366913795471191 | hronoosoa||u \n",
            "r\\ Iteration: 4490 Loss: 1.7930934429168701 | harooos|||u \n",
            "r\\ Iteration: 4491 Loss: 2.024484634399414 | hoanoosoa|o \n",
            "r\\ Iteration: 4492 Loss: 1.9025545120239258 | haarassosonoa|o \n",
            "r\\ Iteration: 4493 Loss: 1.9347584247589111 | haaaaaoos|urur|u \n",
            "r\\ Iteration: 4494 Loss: 1.7440896034240723 | haraarus|urur|u \n",
            "r\\ Iteration: 4495 Loss: 1.6402525901794434 | hraraurur|u \n",
            "r\\ Iteration: 4496 Loss: 1.795790195465088 | haarana|urur|u \n",
            "r\\ Iteration: 4497 Loss: 1.9053609371185303 | hararsonoraono \n",
            "r\\ Iteration: 4498 Loss: 2.052964925765991 | haroaros|onau \n",
            "r\\ Iteration: 4499 Loss: 1.9637768268585205 | hararas|urur|u \n",
            "r\\ Iteration: 4500 Loss: 1.667917013168335 | haaooanas|urur|u \n",
            "r\\ Iteration: 4501 Loss: 1.7196276187896729 | hrraoanasoranosoo \n",
            "r\\ Iteration: 4502 Loss: 1.8616538047790527 | haaooroonaso \n",
            "r\\ Iteration: 4503 Loss: 1.9629602432250977 | haraanas|urur|u \n",
            "r\\ Iteration: 4504 Loss: 1.670715570449829 | hararanaurur|u \n",
            "r\\ Iteration: 4505 Loss: 1.6176722049713135 | haaaraurur|u \n",
            "r\\ Iteration: 4506 Loss: 1.7051360607147217 | haranararau \n",
            "r\\ Iteration: 4507 Loss: 1.9561781883239746 | hararrr|urur|u \n",
            "r\\ Iteration: 4508 Loss: 1.7202553749084473 | harraurur|u \n",
            "r\\ Iteration: 4509 Loss: 1.6287693977355957 | hararnonaurur|u \n",
            "r\\ Iteration: 4510 Loss: 1.6791679859161377 | haaanornosonaa \n",
            "r\\ Iteration: 4511 Loss: 1.8865282535552979 | hoarrurarsar|u \n",
            "r\\ Iteration: 4512 Loss: 1.8503344058990479 | hoaaaanas|urur|u \n",
            "r\\ Iteration: 4513 Loss: 1.7298333644866943 | haraaruaarusosh|u \n",
            "r\\ Iteration: 4514 Loss: 1.7776899337768555 | hararaurur|u \n",
            "r\\ Iteration: 4515 Loss: 1.5975172519683838 | haranausarhisar|u \n",
            "r\\ Iteration: 4516 Loss: 1.7858943939208984 | hraaosrsaoa|u \n",
            "r\\ Iteration: 4517 Loss: 1.8662643432617188 | haaaaosas| \n",
            "r\\ Iteration: 4518 Loss: 1.7951972484588623 | harasaar|urur|u \n",
            "r\\ Iteration: 4519 Loss: 1.7430377006530762 | hararaurur|u \n",
            "r\\ Iteration: 4520 Loss: 1.619476079940796 | haaaauausus|u \n",
            "r\\ Iteration: 4521 Loss: 1.7477657794952393 | hrarsausus|u \n",
            "r\\ Iteration: 4522 Loss: 1.7169182300567627 | harsaaars|u|his|u \n",
            "r\\ Iteration: 4523 Loss: 1.9600841999053955 | harasashr|sass|u \n",
            "r\\ Iteration: 4524 Loss: 1.6588032245635986 | hraassos|u \n",
            "r\\ Iteration: 4525 Loss: 1.9154338836669922 | haaassa|is||s|u \n",
            "r\\ Iteration: 4526 Loss: 1.9302239418029785 | hraararu \n",
            "r\\ Iteration: 4527 Loss: 2.118558883666992 | haaaarrs||usus|u \n",
            "r\\ Iteration: 4528 Loss: 1.9096486568450928 | hararaas|usus|u \n",
            "r\\ Iteration: 4529 Loss: 1.7623603343963623 | haasasssaa|| \n",
            "r\\ Iteration: 4530 Loss: 1.8463623523712158 | hacosasas|| \n",
            "r\\ Iteration: 4531 Loss: 1.8321986198425293 | haraas|usus|u \n",
            "r\\ Iteration: 4532 Loss: 1.7581653594970703 | haraasasasaa \n",
            "r\\ Iteration: 4533 Loss: 1.8969147205352783 | haraaaaaausus|u \n",
            "r\\ Iteration: 4534 Loss: 1.820042371749878 | haarsaaaoausus|u \n",
            "r\\ Iteration: 4535 Loss: 1.7616660594940186 | haraasarasass|u \n",
            "r\\ Iteration: 4536 Loss: 1.6870601177215576 | haraaoaausus|u \n",
            "r\\ Iteration: 4537 Loss: 1.8044817447662354 | harrasaaaaasas|u \n",
            "r\\ Iteration: 4538 Loss: 1.7901077270507812 | hraaaaasausus|u \n",
            "r\\ Iteration: 4539 Loss: 1.7658390998840332 | haraasaaasaass|u \n",
            "r\\ Iteration: 4540 Loss: 1.8178353309631348 | haraaaasausus|u \n",
            "r\\ Iteration: 4541 Loss: 1.782278299331665 | harsarsasassuaas|u \n",
            "r\\ Iteration: 4542 Loss: 1.9658875465393066 | haaasasaaas|u \n",
            "r\\ Iteration: 4543 Loss: 1.93711256980896 | haasrasassas|u \n",
            "r\\ Iteration: 4544 Loss: 1.849304437637329 | haasasasausus|u \n",
            "r\\ Iteration: 4545 Loss: 1.6076347827911377 | harasasaas|usus|u \n",
            "r\\ Iteration: 4546 Loss: 1.6478517055511475 | haaasasasu|uaaa|u \n",
            "r\\ Iteration: 4547 Loss: 1.9827840328216553 | haraaasassas|u \n",
            "r\\ Iteration: 4548 Loss: 1.765174388885498 | hraaaaasassaaassus|| \n",
            "r\\ Iteration: 4549 Loss: 2.0035934448242188 | haaaasausus|u \n",
            "r\\ Iteration: 4550 Loss: 1.6759002208709717 | haraasas|usus|u \n",
            "r\\ Iteration: 4551 Loss: 1.7186825275421143 | hrraaaaaaas|aa \n",
            "r\\ Iteration: 4552 Loss: 2.1616594791412354 | haraaaasas|usus|u \n",
            "r\\ Iteration: 4553 Loss: 1.7251214981079102 | haaars|usus|u \n",
            "r\\ Iteration: 4554 Loss: 1.727656602859497 | haaaasaes|asas|u \n",
            "r\\ Iteration: 4555 Loss: 1.95436429977417 | haraasausaus|u \n",
            "r\\ Iteration: 4556 Loss: 1.8445849418640137 | haaasaaaausaaus|u \n",
            "r\\ Iteration: 4557 Loss: 1.9039230346679688 | haaar|usus|u \n",
            "r\\ Iteration: 4558 Loss: 1.5859169960021973 | hanaasaas|saus|u \n",
            "r\\ Iteration: 4559 Loss: 1.9754812717437744 | hranaausus|u \n",
            "r\\ Iteration: 4560 Loss: 1.8786334991455078 | haaaoasas|assnaan| \n",
            "r\\ Iteration: 4561 Loss: 1.9425795078277588 | haranaas|as|u \n",
            "r\\ Iteration: 4562 Loss: 1.8170254230499268 | hanronsanas|u \n",
            "r\\ Iteration: 4563 Loss: 2.012746572494507 | hoaoanarunass|u \n",
            "r\\ Iteration: 4564 Loss: 1.661973476409912 | harrornaansas|u \n",
            "r\\ Iteration: 4565 Loss: 1.9066874980926514 | horanainr|u \n",
            "r\\ Iteration: 4566 Loss: 1.8972232341766357 | haaaoonaurur|u \n",
            "r\\ Iteration: 4567 Loss: 1.8355391025543213 | haraoananau \n",
            "r\\ Iteration: 4568 Loss: 2.0160257816314697 | hroarnaas|urur|u \n",
            "r\\ Iteration: 4569 Loss: 1.9087462425231934 | hoonaanos|u \n",
            "r\\ Iteration: 4570 Loss: 1.7339568138122559 | haoaroins|urur|u \n",
            "r\\ Iteration: 4571 Loss: 1.8128316402435303 | hanoanan|urur|u \n",
            "r\\ Iteration: 4572 Loss: 1.6087696552276611 | haoaoanaat|u \n",
            "r\\ Iteration: 4573 Loss: 1.808929443359375 | horaonaurur|u \n",
            "r\\ Iteration: 4574 Loss: 1.6588003635406494 | haraanas|urur|u \n",
            "r\\ Iteration: 4575 Loss: 1.74375319480896 | hraonaptip|urur|u \n",
            "r\\ Iteration: 4576 Loss: 1.6719675064086914 | hanronaap|urur|u \n",
            "r\\ Iteration: 4577 Loss: 1.75862717628479 | hararaap|ar|u \n",
            "r\\ Iteration: 4578 Loss: 1.8001708984375 | hrraarar|urur|u \n",
            "r\\ Iteration: 4579 Loss: 1.768657922744751 | haranataanaurur|u \n",
            "r\\ Iteration: 4580 Loss: 1.6967756748199463 | horarsap|urur|u \n",
            "r\\ Iteration: 4581 Loss: 1.62668776512146 | horaraaurur|u \n",
            "r\\ Iteration: 4582 Loss: 1.7154150009155273 | horoonap|urur|u \n",
            "r\\ Iteration: 4583 Loss: 1.7594068050384521 | hororur|urur|u \n",
            "r\\ Iteration: 4584 Loss: 1.7062313556671143 | haraaaissa \n",
            "r\\ Iteration: 4585 Loss: 1.8754818439483643 | horanain|urur|u \n",
            "r\\ Iteration: 4586 Loss: 1.6781153678894043 | haronaranasau \n",
            "r\\ Iteration: 4587 Loss: 1.8613789081573486 | hraoanaslaa||u \n",
            "r\\ Iteration: 4588 Loss: 1.8557963371276855 | haraanasasau \n",
            "r\\ Iteration: 4589 Loss: 1.8723855018615723 | haaranar|u \n",
            "r\\ Iteration: 4590 Loss: 1.9400107860565186 | horarapaalr|u \n",
            "r\\ Iteration: 4591 Loss: 1.7818820476531982 | hraaapaasaurur|u \n",
            "r\\ Iteration: 4592 Loss: 1.7048871517181396 | horanassasalr|u \n",
            "r\\ Iteration: 4593 Loss: 1.730567455291748 | haarnanalaau \n",
            "r\\ Iteration: 4594 Loss: 1.9370405673980713 | hararraurur|u \n",
            "r\\ Iteration: 4595 Loss: 1.6160051822662354 | haaaaaaauasaurur|u \n",
            "r\\ Iteration: 4596 Loss: 1.8497157096862793 | hraraaaurur|u \n",
            "r\\ Iteration: 4597 Loss: 1.6975648403167725 | hararaaaasaurur|u \n",
            "r\\ Iteration: 4598 Loss: 1.6927752494812012 | hraoasassaa|au \n",
            "r\\ Iteration: 4599 Loss: 1.8294754028320312 | hrraaarapsasau \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa10cf98748>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NH2JgE-eBm0",
        "outputId": "19cbbfc8-d125-4a54-dbca-c43d353f7734"
      },
      "source": [
        "for i in range(100):\n",
        "  print(Decode(lstm.Generate(Process('{')[[1]],Process('')[[1]],1     )))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{oraasaus|\n",
            "{oranasaus|\n",
            "{araasaus|\n",
            "{harapsaus|\n",
            "{anananasaus|\n",
            "{aranasaus|\n",
            "{ranasaus|\n",
            "{arasaus|\n",
            "{harapsaus|\n",
            "{arapsaus|\n",
            "{aranasaus|\n",
            "{harasaus|\n",
            "{darapsaus|\n",
            "{saurus|\n",
            "{darapsaus|\n",
            "{sarasaus|\n",
            "{haaasaus|\n",
            "{ranasaus|\n",
            "{haranasaus|\n",
            "{aasaus|\n",
            "{harapsaus|\n",
            "{hararapsaus|\n",
            "{araasaus|\n",
            "{aranasaus|\n",
            "{harapsaus|\n",
            "{darasaus|\n",
            "{daranasaus|\n",
            "{horasaus|\n",
            "{haranasaus|\n",
            "{aaasaus|\n",
            "{hananasaus|\n",
            "{arapsaus|\n",
            "{asaus|\n",
            "{harapsaus|\n",
            "{tarasaus|\n",
            "{aranasaus|\n",
            "{rurorapsaus|\n",
            "{darasaus|\n",
            "{harapsaus|\n",
            "{aranasaus|\n",
            "{harapsaus|\n",
            "{arapsaus|\n",
            "{darapsaus|\n",
            "{hararapsaus|\n",
            "{orapsaus|\n",
            "{eraasaus|\n",
            "{saranasaus|\n",
            "{araasaus|\n",
            "{urorapsaus|\n",
            "{rurururus|\n",
            "{daranasaus|\n",
            "{anapsaus|\n",
            "{araasaus|\n",
            "{ararapsaus|\n",
            "{larapsaus|\n",
            "{orapsaus|\n",
            "{anapasaus|\n",
            "{eraasaus|\n",
            "{haaasaus|\n",
            "{aasaus|\n",
            "{harapsaus|\n",
            "{aaasaus|\n",
            "{asaurus|\n",
            "{harapsaus|\n",
            "{araasaus|\n",
            "{darasaus|\n",
            "{darapsaus|\n",
            "{rananasaus|\n",
            "{horarapsaus|\n",
            "{aururus|\n",
            "{hananasaus|\n",
            "{aranasaus|\n",
            "{harasaus|\n",
            "{harapsaus|\n",
            "{haasaus|\n",
            "{ururus|\n",
            "{harapsaus|\n",
            "{hararapsaus|\n",
            "{harasaus|\n",
            "{harapsaus|\n",
            "{anasaus|\n",
            "{aranasaus|\n",
            "{rorapsaus|\n",
            "{urasaurus|\n",
            "{darasaus|\n",
            "{aaaasaus|\n",
            "{araasaus|\n",
            "{darapsaus|\n",
            "{orarapsaus|\n",
            "{orapsaus|\n",
            "{urururus|\n",
            "{harapsaus|\n",
            "{haasaus|\n",
            "{aaasaus|\n",
            "{harasaus|\n",
            "{saurus|\n",
            "{urorapsaus|\n",
            "{larapsaus|\n",
            "{asaus|\n",
            "{dananasaus|\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhhqO2_aeBm1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}