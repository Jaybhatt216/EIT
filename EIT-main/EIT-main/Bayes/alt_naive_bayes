import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from scipy.stats import norm
from scipy.stats import multivariate_normal as mvn









def get_data(x):
    width = 8
    height = 8
    N = width * height
    X = np.zeros((N, 2))
    Y = np.zeros(N)
    n = 0
    start_t = 0
    for i in range(width):
        t = start_t
        for j in range(height):
            X[n] = [i, j]
            Y[n] = t
            n += 1
            t = (t + 1) % 2 # alternate between 0 and 1
            start_t = (start_t + 1) % 2
        return X, Y    
 
        
       

       

class NaiveBayes(object):
    def fit(self, X, Y, smoothing=1e-2):
        self.gaussians = dict()
        self.priors = dict()
        labels = set(Y.astype(int))
        for c in labels:
            current_x = X[Y == c]
            self.gaussians[c] = {
                'mean': current_x.mean(axis=0),
                'var': current_x.var(axis=0) + smoothing,
            }
            self.priors[c] = float(len(Y[Y == c])) / len(Y)

    def score(self, X, Y):
        P = self.predict(X)
        return np.mean(P == Y)

    def predict(self, X):
        N, D = X.shape
        K = len(self.gaussians)
        P = np.zeros((N, K))
        for c, g in self.gaussians.items():
            mean, var = g['mean'], g['var']
            P[:,c] = mvn.logpdf(X, mean=mean, cov=var) + np.log(self.priors[c])
        return np.argmax(P, axis=1)


if __name__ == '__main__':
    X, Y = get_data(10000)
    Ntrain = len(Y) // 2
    Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]
    Xtest, Ytest = X[Ntrain:], Y[Ntrain:]

    model = NaiveBayes()
    t0 = datetime.now()
    model.fit(Xtrain, Ytrain)
    print("Training time:", (datetime.now() - t0))

    t0 = datetime.now()
    print("Train accuracy:", model.score(Xtrain, Ytrain))
    print("Time to compute train accuracy:", (datetime.now() - t0), "Train size:", len(Ytrain))

    t0 = datetime.now()
    print("Test accuracy:", model.score(Xtest, Ytest))
    print("Time to compute test accuracy:", (datetime.now() - t0), "Test size:", len(Ytest))
    
    
    
    
    
    
    
    
    
    
    
    
    print('--------------------------------------------------------NAIVE ENDS-------------------------------------------------')



class Bayes():
    def fit(self, X,Y,epsilon=1e-3):
        N, D = X.shape
        self.likelihood = dict()
        self.priors = dict()
        lables = set(Y.astype(int))
        for k in lables:
            current_x = X[Y == k]
            self.likelihood[k] = {'mean':current_x.mean(axis=0),
                                  'cov':np.cov(current_x.T)+np.eye(D)*epsilon}
            self.priors[k] = len(Y[Y == k]) / len(Y)
    
    def score(self, X,Y):
        P = self.predict(X)
        return np.mean(P==Y)
    
    def predict(self,X):
        N, D = X.shape
        K = len(self.likelihood)
        P = np.zeros((N,K))
        for k,l in self.likelihood.items():
            mean,cov = l['mean'],l['cov']
            P[:,k] = mvn.logpdf(X, mean=mean, cov=cov) + np.log(self.priors[k])
        return np.argmax(P, axis=1)

if __name__ == '__main__':
    X, Y = get_data(10000)
    Ntrain = len(Y) // 2
    Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]
    Xtest, Ytest = X[Ntrain:], Y[Ntrain:]

    model = Bayes()
    t0 = datetime.now()
    model.fit(Xtrain, Ytrain)
    print("Training time:", (datetime.now() - t0))

    t0 = datetime.now()
    print("Train accuracy:", model.score(Xtrain, Ytrain))
    print("Time to compute train accuracy:", (datetime.now() - t0), "Train size:", len(Ytrain))

    t0 = datetime.now()
    print("Test accuracy:", model.score(Xtest, Ytest))
    print("Time to compute test accuracy:", (datetime.now() - t0), "Test size:", len(Ytest))

    # plot the mean of each class
    #for k, l in model.likelihood.items():
    #    plt.imshow(l['mean'].reshape(28, 28))
    #    plt.title(k)
    #    plt.show()

    
